{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4e8ba4",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "--------------------------------\n",
    "\n",
    "* ## [1 - Introduction](#1)\n",
    "    + ### [1.1 - A Note on Metrics](#1.1)\n",
    "    + ### [1.2 - Data Collection](#1.2)\n",
    "    + ### [1.3 - Importing Necessary Packages](#1.3)  \n",
    "\n",
    "\n",
    "* ## [2 - Predicting Ball and Strike Calls Using Only Pitch Location and Umpire Information](#2)\n",
    "    + ### [2.1 - Early Data Analysis](#2.1)\n",
    "    + ### [2.2 - Modeling with Horizontal Location: Predicting Called Balls and Strikes](#2.2)\n",
    "        * #### [2.2.1 - Train-Test Splits - Horizontal, No Umpires](#2.2.1)\n",
    "        * #### [2.2.2 - Baseline Model for `Horizontal` Data Frame](#2.2.2)\n",
    "        * #### [2.2.3 - Logistic Regression - Horizontal, No Umpires](#2.2.3)\n",
    "        * #### [2.2.4 - Support Vector Machines - Horizontal, No Umpires](#2.2.4)\n",
    "    + ### [2.3 - Modeling with Horizontal Location: Comparing with True Balls and Strikes](#2.3)\n",
    "    + ### [2.4 - Investigating Vertical Location](#2.4)\n",
    "    + ### [2.5 - Modeling with Added Vertical Location: Predicting Called Balls and Strikes](#2.5)\n",
    "        * #### [2.5.1 - Train-Test Splits - Vertical, No Umpires](#2.5.1)\n",
    "        * #### [2.5.2 - Baseline Model for `Vertical` Data Frame](#2.5.2)\n",
    "        * #### [2.5.3 - Logistic Regression - Vertical, No Umpires](#2.5.3)\n",
    "        * #### [2.5.4 - Support Vector Machines - Vertical, No Umpires](#2.5.4)\n",
    "    + ### [2.6 - Modeling with Added Vertical Location: Comparing with True Balls and Strikes](#2.6)\n",
    "    + ### [2.7 - Modeling with Horizontal Location and Umpires: Predicting Called Balls and Strikes](#2.7)\n",
    "        * #### [2.7.1 - Train-Test Splits - Horizontal with Umpires](#2.7.1)\n",
    "        * #### [2.7.2 - Logistic Regression - Horizontal with Umpires](#2.7.2)\n",
    "        * #### [2.7.3 - Support Vector Machines - Horizontal with Umpires](#2.7.3)\n",
    "    + ### [2.8 - Modeling with Horizontal Location and Umpires: Comparing with True Balls and Strikes](#2.8)\n",
    "    + ### [2.9 - Modeling with Added Vertical Location and Umpires: Predicting Called Balls and Strikes](#2.9)\n",
    "        * #### [2.9.1 - Train-Test Splits - Vertical with Umpires](#2.9.1)\n",
    "        * #### [2.9.2 - Logistic Regression - Vertical with Umpires](#2.9.2)\n",
    "        * #### [2.9.3 - Support Vector Machines - Vertical with Umpires](#2.9.3)\n",
    "    + ### [2.10 - Modeling with Added Vertical Location and Umpires: Comparing with True Balls and Strikes](#2.10)\n",
    "    + ### [2.11 - Summary of Results](#2.11)  \n",
    "        * #### [2.11.1 - Addressing Question 1](#2.11.1)\n",
    "        * #### [2.11.2 - Addressing Question 2](#2.11.2)\n",
    "            + ##### [2.11.2.1 - Comparing the Effect of Umpires on Logistic Regression Models using the `Horizontal` Data Frame](#2.11.2.1)\n",
    "            + ##### [2.11.2.2 - Comparing the Effect of Umpires on SVM Models using the `Horizontal` Data Frame](#2.11.2.2)\n",
    "            + ##### [2.11.2.3 - Comparing the Effect of Umpires on Logistic Regression Models using the `Vertical` Data Frame](#2.11.2.3)\n",
    "            + ##### [2.11.2.4 - Comparing the Effect of Umpires on SVM Models using the `Vertical` Data Frame](#2.11.2.4)\n",
    "        * #### [2.11.3 - Additional Reference Tables](#2.11.3)\n",
    "            + ##### [2.11.3.1 - Accuracy Tables](#2.11.3.1)\n",
    "            + ##### [2.11.3.2 - F1-Score Tables](#2.11.3.2)\n",
    "            + ##### [2.11.3.3 - PR-AUC Tables](#2.11.3.3)\n",
    "            + ##### [2.11.3.4 - Correct Calls and Correct Predictions Tables](#2.11.3.4)\n",
    " \n",
    "\n",
    "\n",
    "* ## [3 - Non-Location Factors: Visualizations and Feature Selection](#3)\n",
    "    + ### [3.1 - Visualizations](#3.1)\n",
    "        * #### [3.1.1 - Regions](#3.1.1)\n",
    "            + ##### [3.1.1.1 - `zone`](#3.1.1.1)\n",
    "        * #### [3.1.2 - Boundaries](#3.1.2)\n",
    "            + ##### [3.1.2.1 - `sz_top`](#3.1.2.1)\n",
    "            + ##### [3.1.2.2 - `sz_bot`](#3.1.2.2)\n",
    "        * #### [3.1.3 - Release](#3.1.3)\n",
    "            + ##### [3.1.3.1 - `effective_speed`](#3.1.3.1)\n",
    "            + ##### [3.1.3.2 - `release_pos_x` (RHP)](#3.1.3.2)\n",
    "            + ##### [3.1.3.3 - `release_pos_x` (LHP)](#3.1.3.3)\n",
    "            + ##### [3.1.3.4 - `release_pos_y`](#3.1.3.4)\n",
    "            + ##### [3.1.3.5 - `release_spin_rate`](#3.1.3.5)\n",
    "        * #### [3.1.4 - Plate Appearance](#3.1.4)\n",
    "            + ##### [3.1.4.1 - `pitch_number`](#3.1.4.1)\n",
    "            + ##### [3.1.4.2 - Count (`balls` and `strikes`)](#3.1.4.2)\n",
    "        * #### [3.1.5 - Game State](#3.1.5)\n",
    "            + ##### [3.1.5.1 - Place in Game (`inning` and `outs_when_up`)](#3.1.5.1)\n",
    "            + ##### [3.1.5.2 - `at_bat_number`](#3.1.5.2)\n",
    "            + ##### [3.1.5.3 - Score Difference (`home_score` - `away_score`)](#3.1.5.3)\n",
    "        * #### [3.1.6 - Movement](#3.1.6)\n",
    "            + ##### [3.1.6.1 - `pfx_x`](#3.1.6.1)\n",
    "            + ##### [3.1.6.2 - `pfx_z`](#3.1.6.2)\n",
    "        * #### [3.1.7 - Velocity](#3.1.7)\n",
    "            + ##### [3.1.7.1 - `vx0`](#3.1.7.1)\n",
    "            + ##### [3.1.7.2 - `vy0`](#3.1.7.2)\n",
    "            + ##### [3.1.7.3 - `vz0`](#3.1.7.3)\n",
    "        * #### [3.1.8 - Acceleration](#3.1.8)\n",
    "            + ##### [3.1.8.1 - `ax`](#3.1.8.1)\n",
    "            + ##### [3.1.8.2 - `ay`](#3.1.8.2)\n",
    "            + ##### [3.1.8.3 - `az`](#3.1.8.3)\n",
    "    + ### [3.2 - Feature Refinement](#3.2)\n",
    "    + ### [3.3 - Baseline Models](#3.3)\n",
    "    + ### [3.4 - Feature Selection via Forward Selection](#3.4)\n",
    "        * #### [3.4.1 - Predicting Ball/Strike Calls, Including `zone` Feature](#3.4.1)\n",
    "        * #### [3.4.2 - Predicting Ball/Strike Calls, Not Including `zone` Feature](#3.4.2)\n",
    "        * #### [3.4.3 - Updating `forward_selection_round`](#3.4.3)\n",
    "        * #### [3.4.4 - Predicting Correct Calls, Including `zone` Feature](#3.4.4)\n",
    "        * #### [3.4.5 - Predicting Correct Calls, Not Including `zone` Feature](#3.4.5)\n",
    "        * #### [3.4.6 - Summary](#3.4.6)\n",
    "    + ### [3.5 - Feature Selection via L^1 Regularization](#3.5)\n",
    "        * #### [3.5.1 - Predicting Ball/Strike Calls](#3.5.1)\n",
    "        * #### [3.5.2 - Predicting Correct Calls](#3.5.2)\n",
    "        * #### [3.5.3 - Summary](#3.5.3)\n",
    "        \n",
    "* ## [Appendix A - Data Collection, Cleaning, and Processing](#A)\n",
    "    + ### [A.1 - Accessing Raw Pitch Data](#A.1)\n",
    "    + ### [A.2 - Merging, Cleaning, and Processing Pitch Data I](#A.2)\n",
    "    + ### [A.3 - Accessing Umpire Data I](#A.3)\n",
    "    + ### [A.4 - Merging, Cleaning, and Processing Pitch Data II](#A.4)\n",
    "    + ### [A.5 - Accessing Umpire Data II](#A.5)\n",
    "    + ### [A.6 - Merging, Cleaning, and Processing Pitch Data III](#A.6)  \n",
    "   \n",
    "--------------------------------\n",
    "  \n",
    "<a id='1'></a>\n",
    "# 1 - Introduction\n",
    "\n",
    "In this project, we seek to investigate the efficacy of umpires in calling balls and strikes. Given that there is an easily-defined regulation strike zone, it is trivial to take the measured location data of a pitch and directly determine if that measurement is within the regluation strike zone. Consequently, we take a slightly different focus in `Section 2`, centering two questions:\n",
    "\n",
    "#### Question 1: Would a pseudo-robo-umpire (i.e. a model trained on real umpire data) be more or less accurate than an actual umpire?  \n",
    "\n",
    "#### Question 2: How large of an overall impact does an individual umpire have on training a pseudo-robo-umpire?\n",
    "\n",
    "Note that in `Section 2`, each model will consider at most three pieces of information for each pitch: the horizontal pitch location, the vertical pitch location, and/or the umpire making the call.  \n",
    "   \n",
    "Given the expectation that no human umpire will be perfect at calling balls and strikes, the following is a natural follow-up question:\n",
    "\n",
    "#### Question 3: What factors (beyond pitch location) most impact an umpire making an incorrect ball/strike call?\n",
    "\n",
    "We investigate `Question 3` in `Section 3`, where we will consider many more features than the two (non-`umpire`) features of `Section 2`.\n",
    "\n",
    "<a id='1.1'></a>\n",
    "## 1.1 - A Note on Metrics\n",
    "\n",
    "In this case, our primary metric of interest will be accuracy, as incorrectly predicting a called ball as a called strike is similar to incorrectly predicting a called strike as a called ball.\n",
    "\n",
    "Beyond accuracy, we will also track F1-score (the mean of recall and precision) and PR-AUC (area under the precision-recall curve).\n",
    "\n",
    "<a id='1.2'></a>\n",
    "## 1.2 - Data Collection\n",
    "\n",
    "We will be looking at pitches from the entirety of the 2023 season that were called balls or strikes by an umpire (this does not include swinging strikes, for example). Our source of pitch data is [Baseball Savant](https://baseballsavant.mlb.com/statcast_search), via [pybaseball](https://github.com/jldbc/pybaseball). Since Baseball Savant no longer provides umpire information, we used boxscores on [Baseball Reference](www.baseball-reference.com) to compile data on home plate umpires for every game, which we then joined to the Baseball Savant pitch data.  \n",
    "  \n",
    "We go into further details in Appendix A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e687c1",
   "metadata": {},
   "source": [
    "<a id='1.3'></a>\n",
    "\n",
    "## 1.3 - Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936e57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Early Data Analysis\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Images\n",
    "from IPython.display import Image\n",
    "\n",
    "# General Modeling\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, auc, f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Specific Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e9c916",
   "metadata": {},
   "source": [
    "--------------------------------  \n",
    "  \n",
    "<a id='2'></a>\n",
    "# 2 - Predicting Ball and Strike Calls Using Only Pitch Location and Umpire Information\n",
    "\n",
    "Recall that in this section, we focus on the following two questions from `Section 1`:\n",
    "\n",
    "#### Question 1: Would a pseudo-robo-umpire (i.e. a model trained on real umpire data) be more or less accurate than an actual umpire?  \n",
    "\n",
    "#### Question 2: How large of an overall impact does an individual umpire have on training a pseudo-robo-umpire?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e975b98b",
   "metadata": {},
   "source": [
    "We begin by reading in the data for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1446d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "core = pd.read_csv('small_model_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa42f9e4",
   "metadata": {},
   "source": [
    "The columns of this data set are:  \n",
    "\n",
    "* `ball/strike` - the umpire's call on the field of if that pitch was a ball or strike ^  \n",
    "* `binary_bs` - a binary version of `ball/strike`  \n",
    "* `true_ball/strike` - an assessment of if the pitch was a ball or called strike based on the regulation strike zone  \n",
    "* `correct_call` - checks if the umpire's call matches the correct call according to the regulation strike zone  \n",
    "* `zone` - the Gameday Zone of the pitch ^  \n",
    "* `hscw` - records if the pitch was in the heart, shadow, chase, or waste region of the strike zone  \n",
    "* `plate_x` - the horizontal location of the pitch (relative to the middle of home plate) as the pitch crossed home plate ^  \n",
    "* `plate_x_mag` - absolute value of `plate_x`  \n",
    "* `plate_x_dir` - sign of `plate_x`  \n",
    "* `plate_z` - the height of the pitch ^  \n",
    "* `sz_top` - the top height of the regulation strike zone (changes per batter) ^  \n",
    "* `sz_bot` - the bottom height of the regulation strike zone (changes per batter) ^  \n",
    "* `umpire` - identity of home plate umpire, as scraped from Baseball Reference\n",
    "\n",
    "^ as provided by Baseball Savant, see the [documentation](https://baseballsavant.mlb.com/csv-docs) for more details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db79a91",
   "metadata": {},
   "source": [
    "<a id='2.1'></a>\n",
    "## 2.1 - Early Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2495e399",
   "metadata": {},
   "source": [
    "We begin at the most basic level: what percentage of calls are made correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeae10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "core.correct_call.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a782d3",
   "metadata": {},
   "source": [
    "We see that approximately 91.7% of ball/strike calls were made correctly. Let's now visualize the pitches in terms of where they crossed the plate, with the blue dots representing pitches that umpires called correctly and orange dots representing pitches that were called incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f304851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,12))\n",
    "sns.scatterplot(x='plate_x', y='plate_z', data=core, hue='correct_call')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfe21bb",
   "metadata": {},
   "source": [
    "This plot is consistent with the fact that about 91.7% of calls were made correctly.  \n",
    "  \n",
    "We now re-create this picture, but more centered on the strike zone. As a reminder, the width of the regulation stike zone is constant (it goes from -0.833 ft to 0.833 ft); the height of the strike zone depends on the batter. We will restrict to pitches with a `plate_x` value between -1.5 and 1.5 and with a `plate_z` value between 0.5 and 4.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c252960",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom = core[(-1.5 < core['plate_x']) & (1.5 > core['plate_x']) & (0.5 < core['plate_z']) & (4.5 > core['plate_z'])]\n",
    "\n",
    "plt.figure(figsize=(6,12))\n",
    "sns.scatterplot(x='plate_x', y='plate_z', data=zoom, hue='correct_call')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddea889e",
   "metadata": {},
   "source": [
    "We now recreate this picture with lines defining the strike zone width and (average) strike zone height to highlight common knowledge: most missed calls occur near the boundary of the strike zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56824499",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,12))\n",
    "sns.scatterplot(x='plate_x', y='plate_z', data=zoom, hue='correct_call')\n",
    "plt.legend(loc='upper right')\n",
    "avg_top = core.sz_top.mean()\n",
    "avg_bot = core.sz_bot.mean()\n",
    "plt.plot([-1, 1], [avg_top, avg_top], color='black', linewidth=2)\n",
    "plt.plot([-1, 1], [avg_bot, avg_bot], color='black', linewidth=2)\n",
    "plt.plot([-1, -1], [avg_bot, avg_top], color='black', linewidth=2)\n",
    "plt.plot([1, 1], [avg_bot, avg_top], color='black', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4c21e1",
   "metadata": {},
   "source": [
    "<a id='2.1.1'></a>\n",
    "### 2.1.1 - Four Regions of the Zones: Heart, Shadow, Chase, Waste (HSCW)\n",
    "\n",
    "Given that most missed calls happen near the edge of the zone, we will take note of a standard method of breaking the pitching plane into four zones: the heart, shadow, chase, and waste zones. This is given concretely in the picture below (originally found at [https://tangotiger.net/strikezone/zone%20chart.png](https://tangotiger.net/strikezone/zone%20chart.png), which was linked to from Baseball Savant), but we give a short written description as well. \n",
    "\n",
    "- Pitches in the heart of the strike zone are always regulation strikes; it is the dead center of the strike zone.  \n",
    "- Pitches in the shadow zone are close to the border of the regulation zone; this region incorporates both true strikes and true balls.  \n",
    "- Pitches in the chase portion of the zone are all true balls, but pitches that a hitter may still reasonably swing at (such as a curveball with a large break on an 0-2 count).  \n",
    "- Finally, pitches in the waste zone are balls that are not close at all to being strikes. \n",
    "\n",
    "We also include the following video clips from Baseball Savant as specific examples:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22513efb",
   "metadata": {},
   "source": [
    "Heart Example\n",
    "\n",
    "<video src=\"heart_video.mp4\" width=\"960\" height=\"540\" controls></video>\n",
    "\n",
    "[Heart Video Source](https://baseballsavant.mlb.com/sporty-videos?playId=2e34bcf8-81f1-4ad5-8776-7f05db2be8b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ace5df",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63800b20",
   "metadata": {},
   "source": [
    "Shadow Example\n",
    "\n",
    "<video src=\"shadow_video.mp4\" width=\"960\" height=\"540\" controls></video>\n",
    "\n",
    "[Shadow Video Source](https://baseballsavant.mlb.com/sporty-videos?playId=1770656d-f215-4cc5-b08a-ca67f64f61c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ce9b1a",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af7a51a",
   "metadata": {},
   "source": [
    "Chase Example\n",
    "\n",
    "<video src=\"chase_video.mp4\" width=\"960\" height=\"540\" controls></video>\n",
    "\n",
    "[Chase Video Source](https://baseballsavant.mlb.com/sporty-videos?playId=794ad28a-c7ab-4c5f-8c68-d8625c7b4ef2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fbf2a7",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713ad99d",
   "metadata": {},
   "source": [
    "Waste Example\n",
    "\n",
    "<video src=\"waste_video.mp4\" width=\"960\" height=\"540\" controls></video>\n",
    "\n",
    "[Waste Video Source](https://baseballsavant.mlb.com/sporty-videos?playId=6c80268f-9e1d-45a1-a809-a13f24a87d2f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d0d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"heart_shadow_chase_waste.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7756b3",
   "metadata": {},
   "source": [
    "Now, let's examine umpire accuracy in these four regions. As can be seen below, umpire accuracy is fairly high overall, but is very high in the heart, chase, and waste zones. The shadow of the zone is the most difficult region for umpires to call correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1f3369",
   "metadata": {},
   "outputs": [],
   "source": [
    "hscw_names = ['heart', 'shadow', 'chase', 'waste']\n",
    "hscw_correct = []\n",
    "hscw_incorrect = []\n",
    "\n",
    "for string in hscw_names:\n",
    "    acc_list = core[core['hscw']==string].correct_call.value_counts(normalize=True).to_list()\n",
    "    hscw_correct.append(acc_list[0])\n",
    "    hscw_incorrect.append(acc_list[1])\n",
    "    \n",
    "hscw_eda = pd.DataFrame({\n",
    "    'heart_shadow_chase_waste':hscw_names,\n",
    "    'correct_call_percentage':hscw_correct,\n",
    "    'incorrect_per':hscw_incorrect\n",
    "    }\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(hscw_eda, x='heart_shadow_chase_waste', y='correct_call_percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb8e8d8",
   "metadata": {},
   "source": [
    "<a id='2.1.2'></a>\n",
    "### 2.1.2 - Accuracy By Umpire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eda6c84",
   "metadata": {},
   "source": [
    "We will also look at some of these metrics by umpire. In the bar plot below, we see that umpire accuracy on these pitches is fairly uniform - most are above 90%, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca6f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "umpire_list = list(core.umpire.unique())\n",
    "\n",
    "umpire_list.sort()\n",
    "\n",
    "umpires_correct = []\n",
    "umpires_incorrect = []\n",
    "\n",
    "for umpire in umpire_list:\n",
    "    acc_list = core[core['umpire']==umpire].correct_call.value_counts(normalize=True).to_list()\n",
    "    umpires_correct.append(acc_list[0])\n",
    "    umpires_incorrect.append(acc_list[1])\n",
    "\n",
    "umpires_eda = pd.DataFrame({'umpire':umpire_list, 'correct_per':umpires_correct, 'incorrect_per':umpires_incorrect})\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "sns.barplot(umpires_eda, x='umpire', y='correct_per')\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.gca().set_yticks([0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "plt.gca().set_yticklabels([0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "plt.plot([-1, 94], [0.9, 0.9], color='black', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34223327",
   "metadata": {},
   "source": [
    "Nonetheless, we can use a `pointplot` to zoom in on the the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13729e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.pointplot(umpires_eda, x='umpire', y='correct_per')\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc1a94a",
   "metadata": {},
   "source": [
    "We can sort `umpires_eda` by correct call percentage to highlight the range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5c23b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "umpires_eda.sort_values(by='correct_per', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac9f183",
   "metadata": {},
   "source": [
    "Notably, Pat Hoberg has the highest percentage of correct calls (approximately 94.3%) and Doug Eddings has the lowest percentage of correct calls (approximately 89.4%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35494098",
   "metadata": {},
   "source": [
    "<a id='2.1.3'></a>\n",
    "### 2.1.3 - Heart, Shadow, Chase, Waste Accuracy By Umpire\n",
    "\n",
    "We will also examine individual umpire performance in the heart, shadow, chase, and waste zones. We will first look at a `pointplot` of the accuracy in the heart of the zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc14620",
   "metadata": {},
   "outputs": [],
   "source": [
    "uhcc = core.groupby(['umpire', 'hscw']).correct_call.value_counts().unstack(fill_value=0).stack().to_frame().rename(\n",
    "    columns={0:'count'}\n",
    ")\n",
    "\n",
    "umpires_heart = []\n",
    "umpires_shadow = []\n",
    "umpires_chase = []\n",
    "umpires_waste = []\n",
    "\n",
    "for umpire in umpire_list:\n",
    "    h_cor = uhcc.at[(umpire, 'heart', 'correct_call'), 'count']\n",
    "    h_inc = uhcc.at[(umpire, 'heart', 'incorrect_call'), 'count']\n",
    "    umpires_heart.append( h_cor / (h_cor + h_inc) )\n",
    "    s_cor = uhcc.at[(umpire, 'shadow', 'correct_call'), 'count']\n",
    "    s_inc = uhcc.at[(umpire, 'shadow', 'incorrect_call'), 'count']\n",
    "    umpires_shadow.append( s_cor / (s_cor + s_inc) )\n",
    "    c_cor = uhcc.at[(umpire, 'chase', 'correct_call'), 'count']\n",
    "    c_inc = uhcc.at[(umpire, 'chase', 'incorrect_call'), 'count']\n",
    "    umpires_chase.append( c_cor / (c_cor + c_inc) )\n",
    "    w_cor = uhcc.at[(umpire, 'waste', 'correct_call'), 'count']\n",
    "    w_inc = uhcc.at[(umpire, 'waste', 'incorrect_call'), 'count']\n",
    "    umpires_waste.append( w_cor / (w_cor + w_inc) )        \n",
    "\n",
    "umpires_heart_df = pd.DataFrame({'umpire':umpire_list, 'correct_per':umpires_heart})\n",
    "umpires_shadow_df = pd.DataFrame({'umpire':umpire_list, 'correct_per':umpires_shadow})\n",
    "umpires_chase_df = pd.DataFrame({'umpire':umpire_list, 'correct_per':umpires_chase})\n",
    "umpires_waste_df = pd.DataFrame({'umpire':umpire_list, 'correct_per':umpires_waste})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f1adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.pointplot(umpires_heart_df, x='umpire', y='correct_per').set_title('Heart Accuracy')\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45a33f4",
   "metadata": {},
   "source": [
    "In the heart of the zone, everyone does well; umpires called pitches correctly between 97% and 100% of the time. As noted earlier, the lowest levels of accuracy occur in the shadow zone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd27ab4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.pointplot(umpires_shadow_df, x='umpire', y='correct_per').set_title('Shadow Accuracy')\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275b61ae",
   "metadata": {},
   "source": [
    "Accuracy in the chase zone is similar to in the heart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212e1540",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.pointplot(umpires_chase_df, x='umpire', y='correct_per').set_title('Chase Accuracy')\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d4d017",
   "metadata": {},
   "source": [
    "In the waste zone, we see almost perfect accuracy, as would be expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ed8c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.pointplot(umpires_waste_df, x='umpire', y='correct_per').set_title('Waste Accuracy')\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed25f12",
   "metadata": {},
   "source": [
    "Upon inspection, one can see that the only umpires who missed calls in the waste zone are Jordan Baker (3 missed calls) and John Tumpane (1 missed call)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bde3fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "umpires_waste_df.sort_values('correct_per')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e66b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "core[(core['umpire']=='Jordan Baker') & (core['hscw']=='waste') & (core['correct_call']=='incorrect_call')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01dbc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "core[(core['umpire']=='John Tumpane') & (core['hscw']=='waste') & (core['correct_call']=='incorrect_call')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b1a4e",
   "metadata": {},
   "source": [
    "These are irregular pitches, as can be seen from the following videos (provided by Baseball Savant). In each case, it is a position player lobbing a slow, looping pitch which drops drastically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b1d16",
   "metadata": {},
   "source": [
    "For Jordan Baker, these three pitches are by Ryan McKenna (primarily an outfielder): \n",
    "\n",
    "<video src=\"baker_video_1.mp4\" width=\"960\" height=\"540\" controls></video>\n",
    "\n",
    "[Baker Video 1 Source](https://baseballsavant.mlb.com/sporty-videos?playId=279a3317-485e-42a3-a7ea-294e63d5fb3b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9061f4",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ce0b93",
   "metadata": {},
   "source": [
    "<video src=\"baker_video_2.mp4\" width=\"960\" height=\"540\" controls></video>\n",
    "\n",
    "[Baker Video 2 Source](https://baseballsavant.mlb.com/sporty-videos?playId=cf0af812-7bc2-4fed-90c1-3fb38d970c8d)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59208327",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515a2f57",
   "metadata": {},
   "source": [
    "<video src=\"baker_video_3.mp4\" width=\"960\" height=\"540\" controls></video>\n",
    "\n",
    "[Baker Video 3 Source](https://baseballsavant.mlb.com/sporty-videos?playId=45b98f56-94a6-4647-9285-d57184547b09) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f007bc9f",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a7a91b",
   "metadata": {},
   "source": [
    "For John Tumpane, this pitch is by Tucker Barnhart (primarily a catcher): \n",
    "\n",
    "<video src=\"tumpane_video_1.mp4\" width=\"960\" height=\"540\" controls></video>\n",
    "\n",
    "[Tumpane Video Source](https://baseballsavant.mlb.com/sporty-videos?playId=85df8889-22a2-4040-89bb-d9cf18b8d5d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2f26e4",
   "metadata": {},
   "source": [
    "<a id='2.2'></a>\n",
    "## 2.2 - Modeling with Horizontal Location Only: Predicting Called Balls and Strikes\n",
    "\n",
    "Having examined the relevant features for this section, we proceed to modeling.  \n",
    "  \n",
    "As we will address later, there are subtleties in dealing with vertical pitch location (the `plate_z` feature), as the strike zone height varies by batter. As such, we will begin by only considering horizontal pitch location. Further, instead of using the standard `plate_x` feature directly, we will instead use `plate_x_mag`. While `plate_x` records the signed distance from the plate (with one direction being positive and the other negative), `plate_x_mag` is the absolute value of `plate_x` (with sign recorded in the `plate_x_dir` feature).\n",
    "\n",
    "Since we will not yet be using the height for any pitches, we will create the `horizontal` data frame that contains only pitches that are either:\n",
    "1) true strikes (pitches with both `plate_x` and `plate_z` values within the regulation zone), or\n",
    "2) true balls with both `plate_x` and `plate_z` values outside of the regulation zone range.\n",
    "\n",
    "Otherwise, we would be including information which umpires would be able to differentiate that this model cannot.  \n",
    "  \n",
    "Finally, recall that `plate_x` and `plate_z` are given in feet; the width of the regulation strike zone is from -10in to 10in, which is -0.83ft to 0.83 ft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e324e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_strikes = core[core['true_ball/strike']=='true_strike']\n",
    "\n",
    "left_down = core[ (core['plate_x'] < -0.83) & (core['plate_z'] < core['sz_bot']) ]\n",
    "right_down = core[ (core['plate_x'] > 0.83) & (core['plate_z'] < core['sz_bot']) ]\n",
    "\n",
    "left_up = core[ (core['plate_x'] < -0.83) & (core['plate_z'] > core['sz_top']) ]\n",
    "right_up = core[ (core['plate_x'] > 0.83) & (core['plate_z'] > core['sz_top']) ]\n",
    "\n",
    "merge_list = [true_strikes, left_down, right_down, left_up, right_up]\n",
    "\n",
    "horizontal = pd.concat(merge_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c80ebf",
   "metadata": {},
   "source": [
    "<a id='2.2.1'></a>\n",
    "### 2.2.1 - Train-Test Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14076d36",
   "metadata": {},
   "source": [
    "We begin by separating into training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b8f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_train, hor_test = train_test_split(horizontal,\n",
    "                                        test_size=0.2,\n",
    "                                        shuffle=True,\n",
    "                                        random_state=630,\n",
    "                                        stratify=horizontal['ball/strike'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac5a2f6",
   "metadata": {},
   "source": [
    "We stratify based on balls and strikes see similar percentages for called balls and called strikes in both `horizontal` and `hor_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605b0904",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal['ball/strike'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4998c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_train['ball/strike'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73f257b",
   "metadata": {},
   "source": [
    "<a id='2.2.2'></a>\n",
    "### 2.2.2 - Baseline Model for `Horizontal` Data Frame\n",
    "\n",
    "For our baseline model with the `horizontal` data frame, we randomly predict balls and strikes according to the overall distribution in the data frame (i.e. with a 44% chance of a given pitch being called a strike). We will use 1000 random samples in our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d67fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_baseline_accs = []\n",
    "hor_baseline_f1s = []\n",
    "hor_baseline_praucs = []\n",
    "\n",
    "np.random.seed(329)\n",
    "\n",
    "for obs in range(1000):\n",
    "    rand_draw = np.random.binomial(n=1, p=0.44, size=len(hor_train))\n",
    "    hor_baseline_accs.append( accuracy_score(hor_train.binary_bs.values, rand_draw) )\n",
    "    precision, recall, _ = precision_recall_curve(hor_train.binary_bs.values, rand_draw)\n",
    "    hor_baseline_praucs.append( auc(recall, precision) )\n",
    "    hor_baseline_f1s.append( f1_score(hor_train.binary_bs.values, rand_draw) )\n",
    "\n",
    "hor_baseline_stats = pd.DataFrame(data={\n",
    "                                'hor_baseline_accuracy':hor_baseline_accs,\n",
    "                                'hor_baseline_f1':hor_baseline_f1s,\n",
    "                                'hor_baseline_pr_auc':hor_baseline_praucs\n",
    "                                })\n",
    "\n",
    "hor_baseline_stats.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937a5ba5",
   "metadata": {},
   "source": [
    "<a id='2.2.3'></a>\n",
    "### 2.2.3 - Logistic Regression - Horizontal, No Umpires\n",
    "\n",
    "We begin in the simplest case, using only `plate_x_mag` as a predictor. The first step is setting up k-fold cross validation. We will always use k=10 in our k-fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc312c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_splits = 10\n",
    "\n",
    "hor_no_ump_log_reg_kfold_rand_state = 721\n",
    "\n",
    "hor_no_ump_log_reg_kfold = StratifiedKFold(kfold_splits, shuffle=True, random_state=hor_no_ump_log_reg_kfold_rand_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c0c798",
   "metadata": {},
   "source": [
    "Our logistic regression model object requires uses both a penalty (either l2 or none) and a maximum number of iterations. The following code uses `GridSearchCV` to determine optimal choices for both of these options. Given the run time, we provide commented-out code to run the search, export the results as a CSV, and read-in the results as a data frame. \n",
    "\n",
    "There are several options which seem to provide the best test score. Given the similarity in scores, we pick no penalty and a maximum of 10,000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb38c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hor_no_ump_log_reg_preprocessor = ColumnTransformer(\n",
    "#    transformers=[\n",
    "#            ('continuous', StandardScaler(), ['plate_x_mag'])\n",
    "#        ],\n",
    "#    remainder='passthrough')\n",
    "    \n",
    "## Setting up the normalization pipeline\n",
    "#hor_no_ump_log_reg_pipeline = Pipeline([\n",
    "#    ('log_reg_preprocessor', hor_no_ump_log_reg_preprocessor),\n",
    "#    ('log_reg', LogisticRegression())\n",
    "#])\n",
    "\n",
    "## Creating the grid\n",
    "#hor_no_ump_log_reg_grid = GridSearchCV(\n",
    "#    hor_no_ump_log_reg_pipeline,\n",
    "#    param_grid={\n",
    "#        'log_reg__penalty':['l2', None],\n",
    "#        'log_reg__max_iter':[100, 500, 1000, 5000, 10000, 50000, 100000, 500000, 1000000, 5000000]\n",
    "#    },\n",
    "#    scoring='accuracy',\n",
    "#    cv=5\n",
    "#)\n",
    "    \n",
    "## Fitting the grid\n",
    "#hor_no_ump_log_reg_grid.fit(hor_train[['plate_x_mag']], hor_train.binary_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b974c251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hor_no_ump_log_reg_grid_results = pd.DataFrame(data=hor_no_ump_log_reg_grid.cv_results_)\n",
    "\n",
    "#hor_no_ump_log_reg_grid_results_order = ['rank_test_score', 'std_test_score', 'param_log_reg__penalty']\n",
    "#hor_no_ump_log_reg_grid_results_order.extend(['param_log_reg__max_iter', 'mean_fit_time', 'std_fit_time', 'mean_score_time'])\n",
    "#hor_no_ump_log_reg_grid_results_order.extend(['std_score_time', 'split0_test_score', 'split1_test_score'])\n",
    "#hor_no_ump_log_reg_grid_results_order.extend(['split2_test_score', 'split3_test_score', 'split4_test_score'])\n",
    "\n",
    "#hor_no_ump_log_reg_grid_results = hor_no_ump_log_reg_grid_results[hor_no_ump_log_reg_grid_results_order].sort_values(['rank_test_score', 'std_test_score', 'mean_fit_time'])\n",
    "\n",
    "#hor_no_ump_log_reg_grid_results.to_csv('hor_no_ump_log_reg_grid_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3c6d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hor_no_ump_log_reg_grid_results_csv = pd.read_csv('hor_no_ump_log_reg_grid_results.csv')\n",
    "\n",
    "#hor_no_ump_log_reg_grid_results_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044c4d35",
   "metadata": {},
   "source": [
    "Having determined our parameters for the model, we now run the model and observe the relevant metrics. As mentioned above, our primary metric is accuracy, with F1-score and PR-AUC serving as additional metrics. We also record the number of pitches being predicted as strikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d114d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_no_ump_log_reg_accs = []\n",
    "hor_no_ump_log_reg_f1s = []\n",
    "hor_no_ump_log_reg_praucs = []\n",
    "\n",
    "hor_no_ump_log_reg_preds = []\n",
    "hor_no_ump_log_reg_pred_strikes = []\n",
    "\n",
    "feat = ['plate_x_mag']\n",
    "\n",
    "hor_no_ump_log_reg_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('continuous', StandardScaler(), ['plate_x_mag'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "for train_index, test_index in hor_no_ump_log_reg_kfold.split(hor_train, hor_train.binary_bs):\n",
    "    # Splitting up our data using the indices from our kfold split\n",
    "    split_train = hor_train.iloc[train_index]\n",
    "    split_test = hor_train.iloc[test_index]\n",
    "    \n",
    "    # Setting up the normalization pipeline\n",
    "    hor_no_ump_log_reg_pipeline = Pipeline([\n",
    "        ('hor_no_ump_log_reg_preprocessor', hor_no_ump_log_reg_preprocessor),\n",
    "        ('hor_no_ump_log_reg', LogisticRegression(penalty=None, max_iter=10000))\n",
    "    ])\n",
    "    \n",
    "    # Fitting the pipeline\n",
    "    hor_no_ump_log_reg_pipeline.fit(split_train[feat], split_train.binary_bs)\n",
    "    \n",
    "    # Predictions\n",
    "    split_pred = hor_no_ump_log_reg_pipeline.predict(split_test[feat])\n",
    "    hor_no_ump_log_reg_preds.append(split_pred)\n",
    "    split_pred_dict = {1:0}\n",
    "    for entry in split_pred:\n",
    "        if entry==1:\n",
    "            split_pred_dict[1] += 1\n",
    "    hor_no_ump_log_reg_pred_strikes.append(split_pred_dict[1])\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    hor_no_ump_log_reg_accs.append( accuracy_score(split_test.binary_bs, split_pred) )\n",
    "    hor_no_ump_log_reg_f1s.append( f1_score(split_test.binary_bs, split_pred) )\n",
    "    hor_no_ump_log_reg_prec, hor_no_ump_log_reg_rec, _ = precision_recall_curve(split_test.binary_bs, split_pred)\n",
    "    hor_no_ump_log_reg_praucs.append(auc(hor_no_ump_log_reg_rec, hor_no_ump_log_reg_prec))\n",
    "\n",
    "hor_no_ump_log_reg_stats = pd.DataFrame(data={\n",
    "    'hor_no_ump_pred_strikes':hor_no_ump_log_reg_pred_strikes,\n",
    "    'hor_no_ump_log_reg_accuracy':hor_no_ump_log_reg_accs,\n",
    "    'hor_no_ump_log_reg_f1':hor_no_ump_log_reg_f1s,\n",
    "    'hor_no_ump_log_reg_pr_auc':hor_no_ump_log_reg_praucs\n",
    "    })\n",
    "\n",
    "hor_no_ump_log_reg_stats.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5190f9",
   "metadata": {},
   "source": [
    "We now compare metrics between this model and the baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b365b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_no_ump_log_reg_combo_stats = pd.concat([hor_baseline_stats.describe(), hor_no_ump_log_reg_stats.describe()], axis=1)\n",
    "\n",
    "hor_no_ump_log_reg_combo_stats_order = ['hor_baseline_accuracy', 'hor_no_ump_log_reg_accuracy', 'hor_baseline_f1']\n",
    "hor_no_ump_log_reg_combo_stats_order.extend(['hor_no_ump_log_reg_f1', 'hor_baseline_pr_auc', 'hor_no_ump_log_reg_pr_auc'])\n",
    "hor_no_ump_log_reg_combo_stats = hor_no_ump_log_reg_combo_stats[hor_no_ump_log_reg_combo_stats_order]\n",
    "\n",
    "hor_no_ump_log_reg_combo_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488523e7",
   "metadata": {},
   "source": [
    "We see a vast increase in accuracy for predicting umpire calls of balls and strikes using only the magnitude of the horizontal distance from the middle of the plate over the baseline model, as expected. These increases also occur for F1-score and PR-AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e609941e",
   "metadata": {},
   "source": [
    "<a id='2.2.4'></a>\n",
    "### 2.2.4 - Support Vector Machines - Horizontal, No Umpires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88560d7f",
   "metadata": {},
   "source": [
    "For another point of comparison, we will use a `LinearSVC` model which also only inputs `plate_x_mag` as a feature. Again, we start with setting up our cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe1765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_splits = 10\n",
    "\n",
    "hor_no_ump_svm_kfold_rand_state = 722\n",
    "\n",
    "hor_no_ump_svm_kfold = StratifiedKFold(kfold_splits, shuffle=True, random_state=hor_no_ump_svm_kfold_rand_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebba3c86",
   "metadata": {},
   "source": [
    "Our `LinearSVC` model object requires a hyperparameter `C` and a maximum number of iterations. The following code uses `GridSearchCV` to determine optimal choices for both of these options. Given the run time, we provide commented-out code to run the search, export the results as a CSV, and read-in the results as a data fra,e. \n",
    "\n",
    "There are several options which seem to provide the best test score. Given the similarity in scores, we pick `C=0.0001` and a maximum of 5,000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7a51a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat = ['plate_x_mag']\n",
    "\n",
    "#hor_no_ump_svm_preprocessor = ColumnTransformer(\n",
    "#    transformers=[\n",
    "#            ('continuous', StandardScaler(), ['plate_x_mag'])\n",
    "#        ],\n",
    "#    remainder='passthrough')\n",
    "    \n",
    "## Setting up the normalization pipeline\n",
    "#hor_no_ump_svm_pipeline = Pipeline([\n",
    "#    ('svm_preprocessor', hor_no_ump_svm_preprocessor),\n",
    "#    ('svm', LinearSVC())\n",
    "#])\n",
    "\n",
    "## Creating the grid\n",
    "#hor_no_ump_grid = GridSearchCV(\n",
    "#    hor_no_ump_svm_pipeline,\n",
    "#    param_grid={\n",
    "#        'svm__C':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "#        'svm__max_iter':[1000, 5000, 10000, 50000, 100000, 500000, 1000000, 5000000]\n",
    "#    },\n",
    "#    scoring='accuracy',\n",
    "#    cv=5\n",
    "#)\n",
    "    \n",
    "## Fitting the grid\n",
    "#hor_no_ump_grid.fit(hor_train[feat], hor_train.binary_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df790bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hor_no_ump_grid_results = pd.DataFrame(data=hor_no_ump_grid.cv_results_)\n",
    "\n",
    "#hor_no_ump_grid_results_order = ['rank_test_score', 'std_test_score', 'param_svm__C', 'param_svm__max_iter']\n",
    "#hor_no_ump_grid_results_order.extend(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'split0_test_score'])\n",
    "#hor_no_ump_grid_results_order.extend(['split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score'])\n",
    "\n",
    "#hor_no_ump_grid_results = hor_no_ump_grid_results[hor_no_ump_grid_results_order].sort_values(['rank_test_score', 'std_test_score', 'mean_fit_time'])\n",
    "\n",
    "#hor_no_ump_grid_results.to_csv('hor_no_ump_svm_grid_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8204f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hor_no_ump_grid_results_csv = pd.read_csv('hor_no_ump_svm_grid_results.csv')\n",
    "\n",
    "#hor_no_ump_grid_results_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49449d14",
   "metadata": {},
   "source": [
    "We now run the model with our chosen parameters and observe the relevant metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35227d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_no_ump_svm_accs = []\n",
    "hor_no_ump_svm_f1s = []\n",
    "hor_no_ump_svm_praucs = []\n",
    "hor_no_ump_svm_pred_strikes = []\n",
    "\n",
    "feat = ['plate_x_mag']\n",
    "\n",
    "hor_no_ump_svm_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('continuous', StandardScaler(), ['plate_x_mag'])\n",
    "        ],\n",
    "    remainder='passthrough')\n",
    "\n",
    "\n",
    "for train_index, test_index in hor_no_ump_svm_kfold.split(hor_train, hor_train.binary_bs):\n",
    "    # Splitting up our data using the indices from our kfold split\n",
    "    split_train = hor_train.iloc[train_index]\n",
    "    split_test = hor_train.iloc[test_index]\n",
    "    \n",
    "    # Setting up the normalization pipeline\n",
    "    svm_pipeline = Pipeline([\n",
    "        ('svm_preprocessor', hor_no_ump_svm_preprocessor),\n",
    "        ('svm', LinearSVC(C=0.0001, max_iter=5000))\n",
    "    ])\n",
    "    \n",
    "    # Fitting the pipeline\n",
    "    svm_pipeline.fit(split_train[feat], split_train.binary_bs)\n",
    "    \n",
    "    # Predictions\n",
    "    split_pred = svm_pipeline.predict(split_test[feat])\n",
    "    split_pred_dict = {1:0}\n",
    "    for entry in split_pred:\n",
    "        if entry==1:\n",
    "            split_pred_dict[1] += 1\n",
    "    hor_no_ump_svm_pred_strikes.append(split_pred_dict[1])\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    hor_no_ump_svm_accs.append( accuracy_score(split_test.binary_bs, split_pred) )\n",
    "    hor_no_ump_svm_f1s.append( f1_score(split_test.binary_bs, split_pred) )\n",
    "    hor_no_ump_svm_prec, hor_no_ump_svm_rec, _ = precision_recall_curve(split_test.binary_bs, split_pred)\n",
    "    hor_no_ump_svm_praucs.append(auc(hor_no_ump_svm_rec, hor_no_ump_svm_prec))\n",
    "\n",
    "hor_no_ump_svm_stats = pd.DataFrame(data={\n",
    "    'hor_no_ump_svm_pred_strikes':hor_no_ump_svm_pred_strikes,\n",
    "    'hor_no_ump_svm_accuracy':hor_no_ump_svm_accs,\n",
    "    'hor_no_ump_svm_f1':hor_no_ump_svm_f1s,\n",
    "    'hor_no_ump_svm_pr_auc':hor_no_ump_svm_praucs\n",
    "    })\n",
    "\n",
    "hor_no_ump_svm_stats.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ef7ba9",
   "metadata": {},
   "source": [
    "Next, we compare metrics between this model and the baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd085fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_no_ump_svm_combo_stats = pd.concat([hor_baseline_stats.describe(), hor_no_ump_svm_stats.describe()], axis=1)\n",
    "\n",
    "hor_no_ump_svm_combo_stats_order = ['hor_baseline_accuracy', 'hor_no_ump_svm_accuracy', 'hor_baseline_f1']\n",
    "hor_no_ump_svm_combo_stats_order.extend(['hor_no_ump_svm_f1', 'hor_baseline_pr_auc', 'hor_no_ump_svm_pr_auc'])\n",
    "hor_no_ump_svm_combo_stats = hor_no_ump_svm_combo_stats[hor_no_ump_svm_combo_stats_order]\n",
    "\n",
    "hor_no_ump_svm_combo_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b31b6a",
   "metadata": {},
   "source": [
    "This `LinearSVC` model using only `plate_x_mag` performs slightly better than the `LogisiticRegression` model using only `plate_x_mag`, but the gains relative to the baseline model are very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c42cd8f",
   "metadata": {},
   "source": [
    "<a id='2.3'></a>\n",
    "## 2.3 - Modeling with Horizontal Location Only: Comparing True Balls and Strikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a82e60",
   "metadata": {},
   "source": [
    "Recall that we are training our models to predict whether an umpire will call a given pitch a ball or a strike, not if the pitch actually is a ball or a strike.  \n",
    "  \n",
    "As another point of comparison, we will now examine how often the model predictions for pitches match the regulation strike zone compared to the umpire's call. We do this now by comparing the percentage of correct predictions (percent of model predictions that match the regulation strike zone) with the percentage of correct calls (percent of umpire calls that match the regulation strike zone). \n",
    "\n",
    "Given the similarity in accuracy between our two models, we only do this comparison for the `LogisticRegression` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d3b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this requires hor_no_ump_log_reg_kfold, which is created and run in Section 2.2.3\n",
    "# The code below requires that code to be run first anyway, so there should be no issue\n",
    "# We reference the call in 2.2.3 so that the random states are always the same\n",
    "\n",
    "hor_split_data_frames = []\n",
    "\n",
    "# This fills the list created above with the split data frames\n",
    "for train_index, test_index in hor_no_ump_log_reg_kfold.split(hor_train, hor_train.binary_bs):\n",
    "    hor_split_data_frames.append(hor_train.iloc[test_index])\n",
    "\n",
    "\n",
    "# Next, we go through the split data frames, add the predictions, and reduce to the relevant features\n",
    "for counter in range(len(hor_split_data_frames)):\n",
    "    temp_df = hor_split_data_frames[counter]\n",
    "    temp_df = temp_df.assign(pred_bs=hor_no_ump_log_reg_preds[counter])\n",
    "    temp_df = temp_df[['true_ball/strike', 'pred_bs', 'binary_bs', 'correct_call']]\n",
    "    hor_split_data_frames[counter] = temp_df\n",
    "\n",
    "\n",
    "    \n",
    "# We again go through the split data frames, check whether the predictions were correct or incorrect,\n",
    "# and store that information\n",
    "for counter in range(len(hor_split_data_frames)):\n",
    "    correct_preds = []\n",
    "    temp_df = hor_split_data_frames[counter]\n",
    "    for ind in temp_df.index:\n",
    "        pred = temp_df.at[ind, 'pred_bs']\n",
    "        ump_call = temp_df.at[ind, 'binary_bs']\n",
    "        cor_incorr = temp_df.at[ind, 'correct_call']\n",
    "        if pred == ump_call:\n",
    "            if cor_incorr == 'correct_call':\n",
    "                correct_preds.append('correct_pred')\n",
    "            else:\n",
    "                correct_preds.append('incorrect_pred')\n",
    "        else:\n",
    "            if cor_incorr == 'correct_call':\n",
    "                correct_preds.append('incorrect_pred')\n",
    "            else:\n",
    "                correct_preds.append('correct_pred')\n",
    "    temp_df = temp_df.assign(correct_pred=correct_preds)\n",
    "    hor_split_data_frames[counter] = temp_df\n",
    "\n",
    "# Finally, we make a data frame comparing the umpire calls to the predicted calls\n",
    "correct_call_test_list = []\n",
    "correct_pred_test_list = []\n",
    "\n",
    "for counter in range(len(hor_split_data_frames)):\n",
    "    correct_call_test_list.append(hor_split_data_frames[counter].correct_call.value_counts(normalize=True)[0])\n",
    "    correct_pred_test_list.append(hor_split_data_frames[counter].correct_pred.value_counts(normalize=True)[0])\n",
    "\n",
    "hor_no_ump_log_reg_call_pred_stats = pd.DataFrame(data={\n",
    "        'hor_no_ump_correct_call_percent':correct_call_test_list,\n",
    "        'hor_no_ump_correct_pred_percent':correct_pred_test_list\n",
    "        }\n",
    "    ).describe()\n",
    "\n",
    "hor_no_ump_log_reg_call_pred_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af636fd7",
   "metadata": {},
   "source": [
    "Despite being trained on umpire's calls, we see that the `LogisiticRegression` model predicts balls and strikes more accurately than the umpires call balls and strikes.  \n",
    "  \n",
    "Additionally, we note that the umpires correct call percentage in the `horizontal` data frame (95.1%) is higher than in the `core` data frame (91.7%). Recall that we obtained the `horizontal` data frame from the `core` data frame by dropping pitches with exactly one of their `plate_x` values and `plate_z` values within the regulation strike zone, which explains why the correct call percentage is noticeably higher.  \n",
    "  \n",
    "In the next subsection, we will create a data frame that does not throw out these pitches and tackles the problem associated to a varying strike zone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbf48d2",
   "metadata": {},
   "source": [
    "<a id='2.4'></a>\n",
    "## 2.4 - Investigating Vertical Location\n",
    "\n",
    "Recall that the height of the regulation strike zone (and thus whether a pitch is truly a ball or strike) depends on the height of the batter, whereas the width of the strike zone does not. As a result, the `plate_z` feature is the height of the pitch from the ground and is not a suitable feature for our purposes.  \n",
    "\n",
    "One approach would be to mimic the `plate_x_mag` feature by computing the mean of the middle of the regulation strike zone and recording the distance of the pitch from this mean. However, the distance from the middle of the regulation strike zone to the edge varies as well. \n",
    "\n",
    "Instead, we use the breakdown of the regulation zone into the heart, shadow, chase, and waste regions for each pitch (see early data analysis above for a visual description), which are based on percentiles, rather than absolute measurements. The shadow region of the zone is the only region which incorporates both balls and strikes, so we split it into two subregions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a8d016",
   "metadata": {},
   "source": [
    "<a id='2.5'></a>\n",
    "## 2.5 - Modeling with Added Vertical Location: Predicting Called Balls and Strikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b0b57",
   "metadata": {},
   "source": [
    "Instead of considering `plate_z` as a continuous variable, we will determine if the height of the pitch is in the vertical heart, vertical shadow, vertical chase, or vertical waste portion of the zone. However, the shadow zone incorporates both balls and strikes. For this purpose, we will split the shadow zone into two parts.\n",
    "\n",
    "We begin by recalling the heart / shadow / chase / waste breakdown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f55ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"heart_shadow_chase_waste.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be6b173",
   "metadata": {},
   "source": [
    "Now, we create the feature `plate_z_hscw` to record whether the pitch was in the heart portion of the zone, a strike in the shadow portion of the zone, a ball in the shadow portion of the zone, a ball in the chase portion of the zone, or a ball in the waste portion of the zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3746e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_cat_list = []\n",
    "\n",
    "for counter in core.index:\n",
    "    z = core.at[counter, 'plate_z']\n",
    "    top = core.at[counter, 'sz_top']\n",
    "    bot = core.at[counter, 'sz_bot']\n",
    "    mid = (top+bot)/2\n",
    "    unit = top-mid\n",
    "    heart_adj = (2/3)*unit\n",
    "    shadow_adj = (4/3)*unit\n",
    "    chase_adj = 2*unit\n",
    "    if (mid-heart_adj <= z <= mid+heart_adj):\n",
    "        vert_cat_list.append('vertical_heart')\n",
    "    elif (mid-unit <= z <= mid+unit):\n",
    "        vert_cat_list.append('vertical_shadow_strike')\n",
    "    elif (mid-shadow_adj <= z <= mid+shadow_adj):\n",
    "        vert_cat_list.append('vertical_shadow_ball')\n",
    "    elif (mid-chase_adj <= z <= mid+chase_adj):\n",
    "        vert_cat_list.append('vertical_chase')\n",
    "    else:\n",
    "        vert_cat_list.append('vertical_waste')\n",
    "\n",
    "vertical = core.assign(plate_z_hscw=vert_cat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105b95b0",
   "metadata": {},
   "source": [
    "Note that in the `horizontal` data frame, we restricted to pitches that were either 1) true strikes, or 2) both the horizontal and vertical pitch location are outside of the strike zone. Since we now have a categorical version of the `plate_z` feature, we do not need to use the pitch location restrictions used in creating the `horizontal` data frame for the `vertical` data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ca89a2",
   "metadata": {},
   "source": [
    "<a id='2.5.1'></a>\n",
    "### 2.5.1 - Train-Test Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2394c90",
   "metadata": {},
   "source": [
    "We stratify by balls and strikes and verify the similar perecentages between the full data frame and the test data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bc93d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_train, vert_test = train_test_split(vertical,\n",
    "                                         test_size=0.2,\n",
    "                                         shuffle=True,\n",
    "                                         random_state=530,\n",
    "                                         stratify=vertical['ball/strike'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9fd7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical['ball/strike'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2306d4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_train['ball/strike'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690a37fa",
   "metadata": {},
   "source": [
    "<a id='2.5.2'></a>\n",
    "### 2.5.2 - Baseline Model for `Vertical` Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb93c452",
   "metadata": {},
   "source": [
    "Given the difference in balls and strikes between the `horizontal` and `vertical` data frames, we will create a separate baseline model, now using a 33% chance of a random pitch being a strike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a5dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_baseline_accs = []\n",
    "vert_baseline_f1s = []\n",
    "vert_baseline_praucs = []\n",
    "\n",
    "np.random.seed(923)\n",
    "\n",
    "for obs in range(1000):\n",
    "    rand_draw = np.random.binomial(n=1, p=0.33, size=len(vert_train))\n",
    "    vert_baseline_accs.append( accuracy_score(vert_train.binary_bs.values, rand_draw) )\n",
    "    precision, recall, _ = precision_recall_curve(vert_train.binary_bs.values, rand_draw)\n",
    "    vert_baseline_praucs.append( auc(recall, precision) )\n",
    "    vert_baseline_f1s.append( f1_score(vert_train.binary_bs.values, rand_draw) )\n",
    "\n",
    "vert_baseline_stats = pd.DataFrame(data={\n",
    "    'vert_baseline_accuracy':vert_baseline_accs,\n",
    "    'vert_baseline_f1':vert_baseline_f1s,\n",
    "    'vert_baseline_pr_auc':vert_baseline_praucs\n",
    "    }\n",
    ")\n",
    "\n",
    "vert_baseline_stats.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f1dff",
   "metadata": {},
   "source": [
    "<a id='2.5.3'></a>\n",
    "### 2.5.3 - Logistic Regression - Vertical, No Umpires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fde878",
   "metadata": {},
   "source": [
    "We begin by setting up our cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31ca2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_splits = 10\n",
    "\n",
    "vert_no_ump_log_reg_kfold_rand_state = 412\n",
    "\n",
    "vert_no_ump_log_reg_kfold = StratifiedKFold(kfold_splits, shuffle=True, random_state=vert_no_ump_log_reg_kfold_rand_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571d9565",
   "metadata": {},
   "source": [
    "Next, we again use `GridSearchCV` to determine our penalty and maximum number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c62d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vert_no_ump_log_reg_feat = ['plate_x_mag', 'plate_z_hscw']\n",
    "\n",
    "#vert_no_ump_log_reg_preprocessor = ColumnTransformer(\n",
    "#    transformers=[\n",
    "#            ('categorical', OneHotEncoder(), ['plate_z_hscw']),\n",
    "#            ('continuous', StandardScaler(), ['plate_x_mag'])\n",
    "#        ],\n",
    "#    remainder='passthrough')\n",
    "    \n",
    "## Setting up the normalization pipeline\n",
    "#vert_no_ump_log_reg_pipeline = Pipeline([\n",
    "#    ('log_reg_preprocessor', vert_no_ump_log_reg_preprocessor),\n",
    "#    ('log_reg', LogisticRegression())\n",
    "#])\n",
    "\n",
    "## Creating the grid\n",
    "#vert_no_ump_log_reg_grid = GridSearchCV(\n",
    "#    vert_no_ump_log_reg_pipeline,\n",
    "#    param_grid={\n",
    "#        'log_reg__penalty':['l2', None],\n",
    "#        'log_reg__max_iter':[1000, 5000, 10000, 50000, 100000, 500000, 1000000, 5000000]\n",
    "#    },\n",
    "#    scoring='accuracy',\n",
    "#    cv=5\n",
    "#)\n",
    "    \n",
    "## Fitting the grid\n",
    "#vert_no_ump_log_reg_grid.fit(vert_train[vert_no_ump_log_reg_feat], vert_train.binary_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff4b428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vert_no_ump_log_reg_grid_results = pd.DataFrame(data=vert_no_ump_log_reg_grid.cv_results_)\n",
    "\n",
    "#vert_no_ump_log_reg_grid_results_order = ['rank_test_score', 'std_test_score', 'param_log_reg__penalty', 'param_log_reg__max_iter']\n",
    "#vert_no_ump_log_reg_grid_results_order.extend(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'split0_test_score'])\n",
    "#vert_no_ump_log_reg_grid_results_order.extend(['split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score'])\n",
    "\n",
    "#vert_no_ump_log_reg_grid_results = vert_no_ump_log_reg_grid_results[vert_no_ump_log_reg_grid_results_order].sort_values(['rank_test_score', 'std_test_score', 'mean_fit_time'])\n",
    "\n",
    "#vert_no_ump_log_reg_grid_results\n",
    "\n",
    "#vert_no_ump_log_reg_grid_results.to_csv('vert_no_ump_log_reg_grid_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd1c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vert_no_ump_log_reg_grid_results_csv = pd.read_csv('vert_no_ump_log_reg_grid_results.csv')\n",
    "\n",
    "#vert_no_ump_log_reg_grid_results_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9d7e9e",
   "metadata": {},
   "source": [
    "As can be verified above, there are several options which seem to provide the best test score. Given the similarity in scores, we pick 1000 iterations and no penalty for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5743ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_no_ump_log_reg_preds = []\n",
    "vert_no_ump_log_reg_pred_strikes = []\n",
    "\n",
    "vert_no_ump_log_reg_accs = []\n",
    "vert_no_ump_log_reg_f1s = []\n",
    "vert_no_ump_log_reg_praucs = []\n",
    "\n",
    "\n",
    "vert_no_ump_log_reg_feat = ['plate_x_mag', 'plate_z_hscw']\n",
    "\n",
    "vert_no_ump_log_reg_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('categorical', OneHotEncoder(), ['plate_z_hscw']),\n",
    "        ('continuous', StandardScaler(), ['plate_x_mag'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "for train_index, test_index in vert_no_ump_log_reg_kfold.split(vert_train, vert_train.binary_bs):\n",
    "    # Splitting up our data using the indices from our kfold split\n",
    "    split_train = vert_train.iloc[train_index]\n",
    "    split_test = vert_train.iloc[test_index]\n",
    "    \n",
    "    # Setting up the normalization pipeline\n",
    "    vert_no_ump_log_reg_pipeline = Pipeline([\n",
    "        ('log_reg_preprocessor', vert_no_ump_log_reg_preprocessor),\n",
    "        ('log_reg', LogisticRegression(penalty=None, max_iter=1000))\n",
    "    ])\n",
    "    \n",
    "    # Fitting the pipeline\n",
    "    vert_no_ump_log_reg_pipeline.fit(split_train[vert_no_ump_log_reg_feat], split_train.binary_bs)\n",
    "    \n",
    "    # Predictions\n",
    "    split_pred = vert_no_ump_log_reg_pipeline.predict(split_test[vert_no_ump_log_reg_feat])\n",
    "    vert_no_ump_log_reg_preds.append(split_pred)\n",
    "    split_pred_dict = {1:0}\n",
    "    for entry in split_pred:\n",
    "        if entry==1:\n",
    "            split_pred_dict[1] += 1\n",
    "    vert_no_ump_log_reg_pred_strikes.append(split_pred_dict[1])\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    vert_no_ump_log_reg_accs.append( accuracy_score(split_test.binary_bs, split_pred) )\n",
    "    vert_no_ump_log_reg_f1s.append( f1_score(split_test.binary_bs, split_pred) )\n",
    "    vert_no_ump_log_reg_prec, vert_no_ump_log_reg_rec, _ = precision_recall_curve(split_test.binary_bs, split_pred)\n",
    "    vert_no_ump_log_reg_praucs.append(auc(vert_no_ump_log_reg_rec, vert_no_ump_log_reg_prec))\n",
    "\n",
    "vert_no_ump_log_reg_stats = pd.DataFrame(data={\n",
    "    'vert_no_ump_pred_strikes':vert_no_ump_log_reg_pred_strikes,\n",
    "    'vert_no_ump_log_reg_accuracy':vert_no_ump_log_reg_accs,\n",
    "    'vert_no_ump_log_reg_f1':vert_no_ump_log_reg_f1s,\n",
    "    'vert_no_ump_log_reg_pr_auc':vert_no_ump_log_reg_praucs\n",
    "    }\n",
    ")\n",
    "\n",
    "vert_no_ump_log_reg_stats.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9274566f",
   "metadata": {},
   "source": [
    "We now compare these metrics with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e4e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_no_ump_log_reg_combo_stats = pd.concat([vert_baseline_stats.describe(), vert_no_ump_log_reg_stats.describe()], axis=1)\n",
    "\n",
    "vert_no_ump_log_reg_combo_stats_order = ['vert_baseline_accuracy', 'vert_no_ump_log_reg_accuracy', 'vert_baseline_f1']\n",
    "vert_no_ump_log_reg_combo_stats_order.extend(['vert_no_ump_log_reg_f1', 'vert_baseline_pr_auc', 'vert_no_ump_log_reg_pr_auc'])\n",
    "vert_no_ump_log_reg_combo_stats = vert_no_ump_log_reg_combo_stats[vert_no_ump_log_reg_combo_stats_order]\n",
    "\n",
    "vert_no_ump_log_reg_combo_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54464f89",
   "metadata": {},
   "source": [
    "Recall that in the `horizontal` data frame, we restricted to pitches that were either 1) true strikes, or 2) both the horizontal and vertical pitch location are outside of the strike zone.  \n",
    "\n",
    "In this model, we are using the `vertical` data frame which includes all pitches, as we now have categorical vertical pitch location data. Consequently, it is natural to see both \n",
    "* the increase in accuracy of the baseline model, as strike percentage has dropped from 0.44 to 0.33, and  \n",
    "* the slight decrease in mean accuracy from logistic regression model on the `horizontal` data frame to the logistic regression model on the `vertical` data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e0c57a",
   "metadata": {},
   "source": [
    "<a id='2.5.4'></a>\n",
    "### 2.5.4 - Support Vector Machines - Vertical, No Umpires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b3ac77",
   "metadata": {},
   "source": [
    "We start by preparing for cross validation for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203ab5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_splits = 10\n",
    "\n",
    "vert_no_ump_svm_kfold_rand_state = 462\n",
    "\n",
    "vert_no_ump_svm_kfold = StratifiedKFold(kfold_splits, shuffle=True, random_state=vert_no_ump_svm_kfold_rand_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8732dc91",
   "metadata": {},
   "source": [
    "For `LinearSVC`, we have used `GridSearchCV` for tuning the hyperparameter `C` and considering the number of max iterations. This will also use cross validation on `core_train`.\n",
    "\n",
    "Given the run time, we have commented out the code below and saved the results as a CSV, which we import for verification. We pick `C=0.0001` and 500,000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fed76b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vert_no_ump_svm_feat = ['plate_x_mag', 'plate_z_hscw']\n",
    "\n",
    "#vert_no_ump_svm_preprocessor = ColumnTransformer(\n",
    "#    transformers=[\n",
    "#            ('categorical', OneHotEncoder(), ['plate_z_hscw']),\n",
    "#            ('continuous', StandardScaler(), ['plate_x_mag'])\n",
    "#        ],\n",
    "#    remainder='passthrough')\n",
    "    \n",
    "## Setting up the normalization pipeline\n",
    "#vert_no_ump_svm_pipeline = Pipeline([\n",
    "#    ('svm_preprocessor', vert_no_ump_svm_preprocessor),\n",
    "#    ('svm', LinearSVC())\n",
    "#])\n",
    "\n",
    "## Creating the grid\n",
    "#vert_no_ump_svm_grid = GridSearchCV(\n",
    "#    vert_no_ump_svm_pipeline,\n",
    "#    param_grid={\n",
    "#        'svm__C':[0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "#        'svm__max_iter':[1000, 5000, 10000, 50000, 100000, 500000, 1000000, 5000000]\n",
    "#    },\n",
    "#    scoring='accuracy',\n",
    "#    cv=5\n",
    "#)\n",
    "    \n",
    "## Fitting the grid\n",
    "#vert_no_ump_svm_grid.fit(vert_train[vert_no_ump_svm_feat], vert_train.binary_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c989e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vert_no_ump_svm_grid_results = pd.DataFrame(data=vert_no_ump_svm_grid.cv_results_)\n",
    "\n",
    "#vert_no_ump_svm_grid_results_order = ['rank_test_score', 'std_test_score', 'param_svm__C', 'param_svm__max_iter']\n",
    "#vert_no_ump_svm_grid_results_order.extend(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'split0_test_score'])\n",
    "#vert_no_ump_svm_grid_results_order.extend(['split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score'])\n",
    "\n",
    "#vert_no_ump_svm_grid_results = vert_no_ump_svm_grid_results[vert_no_ump_svm_grid_results_order].sort_values(['rank_test_score', 'std_test_score', 'mean_fit_time'])\n",
    "\n",
    "#vert_no_ump_svm_grid_results\n",
    "\n",
    "#vert_no_ump_svm_grid_results.to_csv('vert_no_ump_svm_grid_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd24fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vert_no_ump_svm_grid_results_csv = pd.read_csv('vert_no_ump_svm_grid_results.csv')\n",
    "\n",
    "#vert_no_ump_svm_grid_results_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e32e21c",
   "metadata": {},
   "source": [
    "We now run the model with the chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a64c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_no_ump_svm_preds = []\n",
    "vert_no_ump_svm_pred_strikes = []\n",
    "\n",
    "vert_no_ump_svm_accs = []\n",
    "vert_no_ump_svm_f1s = []\n",
    "vert_no_ump_svm_praucs = []\n",
    "\n",
    "vert_no_ump_svm_feat = ['plate_x_mag', 'plate_z_hscw']\n",
    "\n",
    "vert_no_ump_svm_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('categorical', OneHotEncoder(), ['plate_z_hscw']),\n",
    "        ('continuous', StandardScaler(), ['plate_x_mag'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "for train_index, test_index in vert_no_ump_svm_kfold.split(vert_train, vert_train.binary_bs):\n",
    "    # Splitting up our data using the indices from our kfold split\n",
    "    split_train = vert_train.iloc[train_index]\n",
    "    split_test = vert_train.iloc[test_index]\n",
    "    \n",
    "    # Setting up the normalization pipeline\n",
    "    vert_no_ump_svm_pipeline = Pipeline([\n",
    "        ('svm_preprocessor', vert_no_ump_svm_preprocessor),\n",
    "        ('svm', LinearSVC(C=0.0001, max_iter=500000))\n",
    "    ])\n",
    "    \n",
    "    # Fitting the pipeline\n",
    "    vert_no_ump_svm_pipeline.fit(split_train[vert_no_ump_svm_feat], split_train.binary_bs)\n",
    "    \n",
    "    # Predictions\n",
    "    split_pred = vert_no_ump_svm_pipeline.predict(split_test[vert_no_ump_svm_feat])\n",
    "    vert_no_ump_svm_preds.append(split_pred)\n",
    "    split_pred_dict = {1:0}\n",
    "    for entry in split_pred:\n",
    "        if entry==1:\n",
    "            split_pred_dict[1] += 1\n",
    "    vert_no_ump_svm_pred_strikes.append(split_pred_dict[1])\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    vert_no_ump_svm_accs.append( accuracy_score(split_test.binary_bs, split_pred) )\n",
    "    vert_no_ump_svm_f1s.append( f1_score(split_test.binary_bs, split_pred) )\n",
    "    vert_no_ump_svm_prec, vert_no_ump_svm_rec, _ = precision_recall_curve(split_test.binary_bs, split_pred)\n",
    "    vert_no_ump_svm_praucs.append(auc(vert_no_ump_svm_rec, vert_no_ump_svm_prec))\n",
    "\n",
    "vert_no_ump_svm_stats = pd.DataFrame(data={\n",
    "    'vert_no_ump_pred_strikes':vert_no_ump_svm_pred_strikes,\n",
    "    'vert_no_ump_svm_accuracy':vert_no_ump_svm_accs,\n",
    "    'vert_no_ump_svm_f1':vert_no_ump_svm_f1s,\n",
    "    'vert_no_ump_svm_pr_auc':vert_no_ump_svm_praucs\n",
    "    }\n",
    ")\n",
    "\n",
    "vert_no_ump_svm_stats.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c8aa1",
   "metadata": {},
   "source": [
    "As always, we compare the metrics for this model with the relevant baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62d2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_no_ump_svm_combo_stats = pd.concat([vert_baseline_stats.describe(), vert_no_ump_svm_stats.describe()], axis=1)\n",
    "\n",
    "vert_no_ump_svm_combo_stats_order = ['vert_baseline_accuracy', 'vert_no_ump_svm_accuracy', 'vert_baseline_f1']\n",
    "vert_no_ump_svm_combo_stats_order.extend(['vert_no_ump_svm_f1', 'vert_baseline_pr_auc', 'vert_no_ump_svm_pr_auc'])\n",
    "vert_no_ump_svm_combo_stats = vert_no_ump_svm_combo_stats[vert_no_ump_svm_combo_stats_order]\n",
    "\n",
    "vert_no_ump_svm_combo_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3655df40",
   "metadata": {},
   "source": [
    "We see similar performance between the `LinearSVC` model and the `LogisticRegression` model compared to the `vertical` baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b061a0ff",
   "metadata": {},
   "source": [
    "<a id='2.6'></a>\n",
    "## 2.6 - Modeling with Added Vertical Location: Comparing with True Balls and Strikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a965c209",
   "metadata": {},
   "source": [
    "Just as in `Section 2.3`, we compare the correct call percentage with the correct prediction percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c90a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this requires vert_no_ump_log_reg_kfold, which is created and run in Section 2.5.2\n",
    "# The code below requires that code to be run first anyway, so there should be no issue\n",
    "# We reference the call in 2.5.2 so that the random states are always the same\n",
    "\n",
    "vert_split_data_frames = []\n",
    "\n",
    "# This fills the list created above with the split data frames\n",
    "for train_index, test_index in vert_no_ump_log_reg_kfold.split(vert_train, vert_train.binary_bs):\n",
    "    vert_split_data_frames.append(vert_train.iloc[test_index])\n",
    "\n",
    "\n",
    "# Next, we go through the split data frames, add the predictions, and reduce to the relevant features\n",
    "for counter in range(len(vert_split_data_frames)):\n",
    "    temp_df = vert_split_data_frames[counter]\n",
    "    temp_df = temp_df.assign(pred_bs=vert_no_ump_log_reg_preds[counter])\n",
    "    temp_df = temp_df[['true_ball/strike', 'pred_bs', 'binary_bs', 'correct_call']]\n",
    "    vert_split_data_frames[counter] = temp_df\n",
    "\n",
    "# We again go through the split data frames, check whether the predictions were correct or incorrect,\n",
    "# and store that information\n",
    "for counter in range(len(vert_split_data_frames)):\n",
    "    correct_preds = []\n",
    "    temp_df = vert_split_data_frames[counter]\n",
    "    for ind in temp_df.index:\n",
    "        pred = temp_df.at[ind, 'pred_bs']\n",
    "        ump_call = temp_df.at[ind, 'binary_bs']\n",
    "        cor_incorr = temp_df.at[ind, 'correct_call']\n",
    "        if pred == ump_call:\n",
    "            if cor_incorr == 'correct_call':\n",
    "                correct_preds.append('correct_pred')\n",
    "            else:\n",
    "                correct_preds.append('incorrect_pred')\n",
    "        else:\n",
    "            if cor_incorr == 'correct_call':\n",
    "                correct_preds.append('incorrect_pred')\n",
    "            else:\n",
    "                correct_preds.append('correct_pred')\n",
    "    temp_df = temp_df.assign(correct_pred=correct_preds)\n",
    "    vert_split_data_frames[counter] = temp_df\n",
    "\n",
    "# Finally, we make a data frame comparing the umpire calls to the predicted calls\n",
    "correct_call_test_list = []\n",
    "correct_pred_test_list = []\n",
    "\n",
    "for counter in range(len(vert_split_data_frames)):\n",
    "    correct_call_test_list.append(vert_split_data_frames[counter].correct_call.value_counts(normalize=True)[0])\n",
    "    correct_pred_test_list.append(vert_split_data_frames[counter].correct_pred.value_counts(normalize=True)[0])\n",
    "\n",
    "vert_no_ump_log_reg_call_pred_stats = pd.DataFrame(data={\n",
    "    'vert_no_ump_correct_call_percent':correct_call_test_list,\n",
    "    'vert_no_ump_correct_pred_percent':correct_pred_test_list\n",
    "    }\n",
    "    ).describe()\n",
    "\n",
    "vert_no_ump_log_reg_call_pred_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25667c1",
   "metadata": {},
   "source": [
    "We see that for the `vertical` data frame and the `plate_x_mag` feature, our `LogisticRegression` model correctly predicts balls and strikes at a better rate than umpires. Furthermore, the difference correct prediction percentage and correct call percentage for the `vertical` data frame (about 3%) is larger than for the `horizontal` data frame (about 1.2%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf05797",
   "metadata": {},
   "source": [
    "<a id='2.7'></a>\n",
    "## 2.7 - Modeling with Horizontal Location and Umpires: Predicting Called Balls and Strikes\n",
    "\n",
    "In `Section 2.2`, the models only used the feature `plate_x_mag` with the horizontal data frame. We will now re-create all of the models in `Section 2.2` with `umpire` as an additional feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882bfa1a",
   "metadata": {},
   "source": [
    "<a id='2.7.1'></a>\n",
    "### 2.7.1 - Train-Test Splits - Horizontal with Umpires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f58147",
   "metadata": {},
   "source": [
    "Now that we will be including the `umpire` feature, we will create new training and test datasets so that we can stratify by this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00851dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_ump_train, hor_ump_test = train_test_split(horizontal,\n",
    "                                        test_size=0.2,\n",
    "                                        shuffle=True,\n",
    "                                        random_state=543,\n",
    "                                        stratify=horizontal['umpire'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aa5e36",
   "metadata": {},
   "source": [
    "Note that despite stratifying by `umpire`, we have very similar proportions of balls and strikes in our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0612eb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal['ball/strike'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d2022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_ump_train['ball/strike'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94795047",
   "metadata": {},
   "source": [
    "<a id='2.7.2'></a>\n",
    "### 2.7.2 - Logistic Regression - Horizontal with Umpires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403dcade",
   "metadata": {},
   "source": [
    "We start by preparing our cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a902681",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_splits = 10\n",
    "\n",
    "hor_ump_log_reg_kfold_rand_state = 620\n",
    "\n",
    "hor_ump_log_reg_kfold = StratifiedKFold(kfold_splits, shuffle=True, random_state=hor_ump_log_reg_kfold_rand_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc070237",
   "metadata": {},
   "source": [
    "Once again, we use `GridSearchCV` to determine our penalty and maximum number of iterations for our logistic regression. We will use no penalty and a maximum of 1000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce29091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hor_ump_log_reg_feat = ['plate_x_mag', 'umpire']\n",
    "\n",
    "#hor_ump_log_reg_preprocessor = ColumnTransformer(\n",
    "#    transformers=[\n",
    "#            ('categorical', OneHotEncoder(), ['umpire']),\n",
    "#            ('continuous', StandardScaler(), ['plate_x_mag'])\n",
    "#        ],\n",
    "#    remainder='passthrough')\n",
    "    \n",
    "## Setting up the normalization pipeline\n",
    "#hor_ump_log_reg_pipeline = Pipeline([\n",
    "#    ('log_reg_preprocessor', hor_ump_log_reg_preprocessor),\n",
    "#    ('log_reg', LogisticRegression())\n",
    "#])\n",
    "\n",
    "## Creating the grid\n",
    "#hor_ump_log_reg_grid = GridSearchCV(\n",
    "#    hor_ump_log_reg_pipeline,\n",
    "#    param_grid={\n",
    "#        'log_reg__penalty':['l2', None],\n",
    "#        'log_reg__max_iter':[100, 500, 1000, 5000, 10000, 50000, 100000, 500000, 1000000, 5000000]\n",
    "#    },\n",
    "#    scoring='accuracy',\n",
    "#    cv=5\n",
    "#)\n",
    "    \n",
    "## Fitting the grid\n",
    "#hor_ump_log_reg_grid.fit(hor_ump_train[hor_ump_log_reg_feat], hor_train.binary_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1132fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hor_ump_log_reg_grid_results = pd.DataFrame(data=hor_ump_log_reg_grid.cv_results_)\n",
    "\n",
    "#hor_ump_log_reg_grid_results_order = ['rank_test_score', 'std_test_score', 'param_log_reg__penalty']\n",
    "#hor_ump_log_reg_grid_results_order.extend(['param_log_reg__max_iter', 'mean_fit_time', 'std_fit_time', 'mean_score_time'])\n",
    "#hor_ump_log_reg_grid_results_order.extend(['std_score_time', 'split0_test_score', 'split1_test_score'])\n",
    "#hor_ump_log_reg_grid_results_order.extend(['split2_test_score', 'split3_test_score', 'split4_test_score'])\n",
    "\n",
    "#hor_ump_log_reg_grid_results = hor_ump_log_reg_grid_results[hor_ump_log_reg_grid_results_order].sort_values(['rank_test_score', 'std_test_score', 'mean_fit_time'])\n",
    "\n",
    "#hor_ump_log_reg_grid_results.to_csv('hor_ump_log_reg_grid_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1db0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hor_ump_log_reg_grid_results_csv = pd.read_csv('hor_ump_log_reg_grid_results.csv')\n",
    "\n",
    "#hor_ump_log_reg_grid_results_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6caa323",
   "metadata": {},
   "source": [
    "We now run the model with our chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb2bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_ump_log_reg_accs = []\n",
    "hor_ump_log_reg_f1s = []\n",
    "hor_ump_log_reg_praucs = []\n",
    "\n",
    "hor_ump_log_reg_preds = []\n",
    "hor_ump_log_reg_pred_strikes = []\n",
    "\n",
    "hor_ump_log_reg_feat = ['plate_x_mag', 'umpire']\n",
    "\n",
    "hor_ump_log_reg_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('categorical', OneHotEncoder(), ['umpire']),\n",
    "        ('continuous', StandardScaler(), ['plate_x_mag'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "for train_index, test_index in hor_ump_log_reg_kfold.split(hor_ump_train, hor_ump_train.binary_bs):\n",
    "    # Splitting up our data using the indices from our kfold split\n",
    "    split_train = hor_ump_train.iloc[train_index]\n",
    "    split_test = hor_ump_train.iloc[test_index]\n",
    "    \n",
    "    # Setting up the normalization pipeline\n",
    "    hor_ump_log_reg_pipeline = Pipeline([\n",
    "        ('log_reg_preprocessor', hor_ump_log_reg_preprocessor),\n",
    "        ('log_reg', LogisticRegression(penalty=None, max_iter=1000))\n",
    "    ])\n",
    "    \n",
    "    # Fitting the pipeline\n",
    "    hor_ump_log_reg_pipeline.fit(split_train[hor_ump_log_reg_feat], split_train.binary_bs)\n",
    "    \n",
    "    # Predictions\n",
    "    split_pred = hor_ump_log_reg_pipeline.predict(split_test[hor_ump_log_reg_feat])\n",
    "    hor_ump_log_reg_preds.append(split_pred)\n",
    "    split_pred_dict = {1:0}\n",
    "    for entry in split_pred:\n",
    "        if entry==1:\n",
    "            split_pred_dict[1] += 1\n",
    "    hor_ump_log_reg_pred_strikes.append(split_pred_dict[1])\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    hor_ump_log_reg_accs.append( accuracy_score(split_test.binary_bs, split_pred) )\n",
    "    hor_ump_log_reg_f1s.append( f1_score(split_test.binary_bs, split_pred) )\n",
    "    hor_ump_log_reg_prec, hor_ump_log_reg_rec, _ = precision_recall_curve(split_test.binary_bs, split_pred)\n",
    "    hor_ump_log_reg_praucs.append(auc(hor_ump_log_reg_rec, hor_ump_log_reg_prec))\n",
    "\n",
    "hor_ump_log_reg_stats = pd.DataFrame(data={\n",
    "    'hor_ump_pred_strikes':hor_ump_log_reg_pred_strikes,\n",
    "    'hor_ump_log_reg_accuracy':hor_ump_log_reg_accs,\n",
    "    'hor_ump_log_reg_f1':hor_ump_log_reg_f1s,\n",
    "    'hor_ump_log_reg_pr_auc':hor_ump_log_reg_praucs\n",
    "    })\n",
    "\n",
    "hor_ump_log_reg_stats.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7791cf48",
   "metadata": {},
   "source": [
    "We compare these metrics with the baseline model for the `horizontal` data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e384d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_ump_log_reg_combo_stats = pd.concat([hor_baseline_stats.describe(), hor_ump_log_reg_stats.describe()], axis=1)\n",
    "\n",
    "hor_ump_log_reg_combo_stats_order = ['hor_baseline_accuracy', 'hor_ump_log_reg_accuracy', 'hor_baseline_f1']\n",
    "hor_ump_log_reg_combo_stats_order.extend(['hor_ump_log_reg_f1', 'hor_baseline_pr_auc', 'hor_ump_log_reg_pr_auc'])\n",
    "hor_ump_log_reg_combo_stats = hor_ump_log_reg_combo_stats[hor_ump_log_reg_combo_stats_order]\n",
    "\n",
    "hor_ump_log_reg_combo_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98e880c",
   "metadata": {},
   "source": [
    "We see greatly increased accuracy over the `horizontal` baseline, but very little improvement over only using the `plate_x_mag` feature (with respective mean accuracies of 93.9% and 93.8%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c12a67e",
   "metadata": {},
   "source": [
    "<a id='2.7.3'></a>\n",
    "### 2.7.3 - Support Vector Machines - Horizontal with Umpires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b56cdb",
   "metadata": {},
   "source": [
    "We begin by preparing the cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a85cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_splits = 10\n",
    "\n",
    "hor_ump_svm_kfold_rand_state = 622\n",
    "\n",
    "hor_ump_svm_kfold = StratifiedKFold(kfold_splits, shuffle=True, random_state=hor_ump_svm_kfold_rand_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c6503c",
   "metadata": {},
   "source": [
    "We use `GridSearchCV` to determine our parameters. We will set `C=0.0001` and a maximum of 5000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5934516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hor_ump_svm_feat = ['plate_x_mag', 'umpire']\n",
    "\n",
    "#hor_ump_svm_preprocessor = ColumnTransformer(\n",
    "#    transformers=[\n",
    "#            ('categorical', OneHotEncoder(), ['umpire']),\n",
    "#            ('continuous', StandardScaler(), ['plate_x_mag'])\n",
    "#        ],\n",
    "#    remainder='passthrough')\n",
    "    \n",
    "## Setting up the normalization pipeline\n",
    "#hor_ump_svm_pipeline = Pipeline([\n",
    "#    ('svm_preprocessor', hor_ump_svm_preprocessor),\n",
    "#    ('svm', LinearSVC())\n",
    "#])\n",
    "\n",
    "## Creating the grid\n",
    "#hor_ump_svm_grid = GridSearchCV(\n",
    "#    hor_ump_svm_pipeline,\n",
    "#    param_grid={\n",
    "#        'svm__C':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "#        'svm__max_iter':[1000, 5000, 10000, 50000, 100000, 500000, 1000000, 5000000]\n",
    "#    },\n",
    "#    scoring='accuracy',\n",
    "#    cv=5\n",
    "#)\n",
    "    \n",
    "## Fitting the grid\n",
    "#hor_ump_svm_grid.fit(hor_ump_train[hor_ump_svm_feat], hor_ump_train.binary_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b91b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hor_ump_svm_grid_results = pd.DataFrame(data=hor_ump_svm_grid.cv_results_)\n",
    "\n",
    "#hor_ump_svm_grid_results_order = ['rank_test_score', 'std_test_score', 'param_svm__C', 'param_svm__max_iter']\n",
    "#hor_ump_svm_grid_results_order.extend(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'split0_test_score'])\n",
    "#hor_ump_svm_grid_results_order.extend(['split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score'])\n",
    "\n",
    "#hor_ump_svm_grid_results = hor_ump_svm_grid_results[hor_ump_svm_grid_results_order].sort_values(['rank_test_score', 'std_test_score', 'mean_fit_time'])\n",
    "\n",
    "#hor_ump_svm_grid_results.to_csv('hor_ump_svm_grid_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ade53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hor_ump_svm_grid_results_csv = pd.read_csv('hor_ump_svm_grid_results.csv')\n",
    "\n",
    "#hor_ump_svm_grid_results_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1d33d1",
   "metadata": {},
   "source": [
    "We now run our model with the chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_ump_svm_accs = []\n",
    "hor_ump_svm_f1s = []\n",
    "hor_ump_svm_praucs = []\n",
    "hor_ump_svm_pred_strikes = []\n",
    "\n",
    "hor_ump_svm_feat = ['plate_x_mag', 'umpire']\n",
    "\n",
    "hor_ump_svm_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('categorical', OneHotEncoder(), ['umpire']),\n",
    "        ('continuous', StandardScaler(), ['plate_x_mag'])\n",
    "        ],\n",
    "    remainder='passthrough')\n",
    "\n",
    "\n",
    "for train_index, test_index in hor_ump_svm_kfold.split(hor_ump_train, hor_ump_train.binary_bs):\n",
    "    # Splitting up our data using the indices from our kfold split\n",
    "    split_train = hor_train.iloc[train_index]\n",
    "    split_test = hor_train.iloc[test_index]\n",
    "    \n",
    "    # Setting up the normalization pipeline\n",
    "    hor_ump_svm_pipeline = Pipeline([\n",
    "        ('svm_preprocessor', hor_ump_svm_preprocessor),\n",
    "        ('svm', LinearSVC(C=0.0001, max_iter=5000))\n",
    "    ])\n",
    "    \n",
    "    # Fitting the pipeline\n",
    "    hor_ump_svm_pipeline.fit(split_train[hor_ump_svm_feat], split_train.binary_bs)\n",
    "    \n",
    "    # Predictions\n",
    "    split_pred = hor_ump_svm_pipeline.predict(split_test[hor_ump_svm_feat])\n",
    "    split_pred_dict = {1:0}\n",
    "    for entry in split_pred:\n",
    "        if entry==1:\n",
    "            split_pred_dict[1] += 1\n",
    "    hor_ump_svm_pred_strikes.append(split_pred_dict[1])\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    hor_ump_svm_accs.append( accuracy_score(split_test.binary_bs, split_pred) )\n",
    "    hor_ump_svm_f1s.append( f1_score(split_test.binary_bs, split_pred) )\n",
    "    hor_ump_svm_prec, hor_ump_svm_rec, _ = precision_recall_curve(split_test.binary_bs, split_pred)\n",
    "    hor_ump_svm_praucs.append(auc(hor_ump_svm_rec, hor_ump_svm_prec))\n",
    "\n",
    "hor_ump_svm_stats = pd.DataFrame(data={\n",
    "    'hor_ump_svm_pred_strikes':hor_ump_svm_pred_strikes,\n",
    "    'hor_ump_svm_accuracy':hor_ump_svm_accs,\n",
    "    'hor_ump_svm_f1':hor_ump_svm_f1s,\n",
    "    'hor_ump_svm_pr_auc':hor_ump_svm_praucs\n",
    "    })\n",
    "\n",
    "hor_ump_svm_stats.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f08d91",
   "metadata": {},
   "source": [
    "Finally, we compare the metrics for this model with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a215b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_ump_svm_combo_stats = pd.concat([hor_baseline_stats.describe(), hor_ump_svm_stats.describe()], axis=1)\n",
    "\n",
    "hor_ump_svm_combo_stats_order = ['hor_baseline_accuracy', 'hor_ump_svm_accuracy', 'hor_baseline_f1']\n",
    "hor_ump_svm_combo_stats_order.extend(['hor_ump_svm_f1', 'hor_baseline_pr_auc', 'hor_ump_svm_pr_auc'])\n",
    "hor_ump_svm_combo_stats = hor_ump_svm_combo_stats[hor_ump_svm_combo_stats_order]\n",
    "\n",
    "hor_ump_svm_combo_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c855bac0",
   "metadata": {},
   "source": [
    "Similarly to the `LogisiticRegression` case, we see large improvements over the `horizontal` baseline and minimal improvements over the `LinearSVC` model using only `plate_x_mag`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6630bf7",
   "metadata": {},
   "source": [
    "<a id='2.8'></a>\n",
    "## 2.8 - Modeling with Horizontal Location and Umpires: Comparing with True Balls and Strikes\n",
    "\n",
    "We proceed similarly to `Sections 2.3, 2.6` by comparing correct prediction percentages and correct call percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caef1f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this requires hor_ump_log_reg_kfold, which is created and run in Section 2.7.2\n",
    "# The code below requires that code to be run first anyway, so there should be no issue\n",
    "# We reference the call in 2.7.2 so that the random states are always the same\n",
    "\n",
    "hor_ump_split_data_frames = []\n",
    "\n",
    "# This fills the list created above with the split data frames\n",
    "for train_index, test_index in hor_ump_log_reg_kfold.split(hor_ump_train, hor_ump_train.binary_bs):\n",
    "    hor_ump_split_data_frames.append(hor_ump_train.iloc[test_index])\n",
    "\n",
    "\n",
    "# Next, we go through the split data frames, add the predictions, and reduce to the relevant features\n",
    "for counter in range(len(hor_ump_split_data_frames)):\n",
    "    temp_df = hor_ump_split_data_frames[counter]\n",
    "    temp_df = temp_df.assign(pred_bs=hor_ump_log_reg_preds[counter])\n",
    "    temp_df = temp_df[['true_ball/strike', 'pred_bs', 'binary_bs', 'correct_call']]\n",
    "    hor_ump_split_data_frames[counter] = temp_df\n",
    "\n",
    "\n",
    "    \n",
    "# We again go through the split data frames, check whether the predictions were correct or incorrect,\n",
    "# and store that information\n",
    "for counter in range(len(hor_ump_split_data_frames)):\n",
    "    correct_preds = []\n",
    "    temp_df = hor_ump_split_data_frames[counter]\n",
    "    for ind in temp_df.index:\n",
    "        pred = temp_df.at[ind, 'pred_bs']\n",
    "        ump_call = temp_df.at[ind, 'binary_bs']\n",
    "        cor_incorr = temp_df.at[ind, 'correct_call']\n",
    "        if pred == ump_call:\n",
    "            if cor_incorr == 'correct_call':\n",
    "                correct_preds.append('correct_pred')\n",
    "            else:\n",
    "                correct_preds.append('incorrect_pred')\n",
    "        else:\n",
    "            if cor_incorr == 'correct_call':\n",
    "                correct_preds.append('incorrect_pred')\n",
    "            else:\n",
    "                correct_preds.append('correct_pred')\n",
    "    temp_df = temp_df.assign(correct_pred=correct_preds)\n",
    "    hor_ump_split_data_frames[counter] = temp_df\n",
    "\n",
    "# Finally, we make a data frame comparing the umpire calls to the predicted calls\n",
    "correct_call_test_list = []\n",
    "correct_pred_test_list = []\n",
    "\n",
    "for counter in range(len(hor_ump_split_data_frames)):\n",
    "    correct_call_test_list.append(hor_ump_split_data_frames[counter].correct_call.value_counts(normalize=True)[0])\n",
    "    correct_pred_test_list.append(hor_ump_split_data_frames[counter].correct_pred.value_counts(normalize=True)[0])\n",
    "\n",
    "hor_ump_log_reg_call_pred_stats = pd.DataFrame(data={\n",
    "    'hor_ump_correct_call_percent':correct_call_test_list,\n",
    "    'hor_ump_correct_pred_percent':correct_pred_test_list\n",
    "    }\n",
    ").describe()\n",
    "\n",
    "hor_ump_log_reg_call_pred_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3ea751",
   "metadata": {},
   "source": [
    "Similarly to `Subsection 2.3`, we have a correct prediction percentage higher than the correct call percentage. The difference when including the `umpire` feature is 1.4%, while the difference with only the `plate_x_mag` feature is 1.2%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7f3f1d",
   "metadata": {},
   "source": [
    "<a id='2.9'></a>\n",
    "## 2.9 - Modeling with Added Vertical Location and Umpires: Predicting Called Balls and Strikes\n",
    "\n",
    "Similarly to `Section 2.7`, we now re-create the models of `Section 2.5` using the features `plate_x_mag, plate_z_hscw, umpire` instead of only `plate_x_mag, plate_z_hscw`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7befcd2f",
   "metadata": {},
   "source": [
    "<a id='2.9.1'></a>\n",
    "### 2.9.1 - Train-Test Splits - Vertical with Umpires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191af2e6",
   "metadata": {},
   "source": [
    "As in `Section 2.7`, we create new training and test data sets stratified by umpire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bece7165",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_ump_train, vert_ump_test = train_test_split(vertical,\n",
    "                                                 test_size=0.2,\n",
    "                                                 shuffle=True,\n",
    "                                                 random_state=546,\n",
    "                                                 stratify=vertical['umpire'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aedb99",
   "metadata": {},
   "source": [
    "We again verify that we have similar percentages of balls and strikes in both the original data set and the training data set. Note, however, that there is a much larger percentage of balls present in the `vertical` data set because of the pitches that needed to be thrown out when constructing the `horizontal` data set; see the beginning of `Section 2.2` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059ea241",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical['ball/strike'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9505b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_ump_train['ball/strike'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713189a0",
   "metadata": {},
   "source": [
    "<a id='2.9.2'></a>\n",
    "### 2.9.2 - Logistic Regression - Vertical with Umpires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b77d32",
   "metadata": {},
   "source": [
    "We prepare for cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c8915",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_splits = 10\n",
    "\n",
    "vert_ump_log_reg_kfold_rand_state = 820\n",
    "\n",
    "vert_ump_log_reg_kfold = StratifiedKFold(kfold_splits, shuffle=True, random_state=vert_ump_log_reg_kfold_rand_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fc7d48",
   "metadata": {},
   "source": [
    "After recording the results of using `GridSearchCV` for hyperparameter tuning, we will use no penalty and a maximum of 1000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vert_ump_log_reg_feat = ['plate_x_mag', 'plate_z_hscw', 'umpire']\n",
    "\n",
    "#vert_ump_log_reg_preprocessor = ColumnTransformer(\n",
    "#    transformers=[\n",
    "#            ('categorical', OneHotEncoder(), ['umpire', 'plate_z_hscw']),\n",
    "#            ('continuous', StandardScaler(), ['plate_x_mag'])\n",
    "#        ],\n",
    "#    remainder='passthrough')\n",
    "    \n",
    "## Setting up the normalization pipeline\n",
    "#vert_ump_log_reg_pipeline = Pipeline([\n",
    "#    ('log_reg_preprocessor', vert_ump_log_reg_preprocessor),\n",
    "#    ('log_reg', LogisticRegression())\n",
    "#])\n",
    "\n",
    "## Creating the grid\n",
    "#vert_ump_log_reg_grid = GridSearchCV(\n",
    "#    vert_ump_log_reg_pipeline,\n",
    "#    param_grid={\n",
    "#        'log_reg__penalty':['l2', None],\n",
    "#        'log_reg__max_iter':[100, 500, 1000, 5000, 10000, 50000, 100000, 500000, 1000000, 5000000]\n",
    "#    },\n",
    "#    scoring='accuracy',\n",
    "#    cv=5\n",
    "#)\n",
    "    \n",
    "## Fitting the grid\n",
    "#vert_ump_log_reg_grid.fit(vert_ump_train[vert_ump_log_reg_feat], vert_train.binary_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda526da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vert_ump_log_reg_grid_results = pd.DataFrame(data=vert_ump_log_reg_grid.cv_results_)\n",
    "\n",
    "#vert_ump_log_reg_grid_results_order = ['rank_test_score', 'std_test_score', 'param_log_reg__penalty']\n",
    "#vert_ump_log_reg_grid_results_order.extend(['param_log_reg__max_iter', 'mean_fit_time', 'std_fit_time', 'mean_score_time'])\n",
    "#vert_ump_log_reg_grid_results_order.extend(['std_score_time', 'split0_test_score', 'split1_test_score'])\n",
    "#vert_ump_log_reg_grid_results_order.extend(['split2_test_score', 'split3_test_score', 'split4_test_score'])\n",
    "\n",
    "#vert_ump_log_reg_grid_results = vert_ump_log_reg_grid_results[vert_ump_log_reg_grid_results_order].sort_values(['rank_test_score', 'std_test_score', 'mean_fit_time'])\n",
    "\n",
    "#vert_ump_log_reg_grid_results.to_csv('vert_ump_log_reg_grid_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aa643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vert_ump_log_reg_grid_results_csv = pd.read_csv('vert_ump_log_reg_grid_results.csv')\n",
    "\n",
    "#vert_ump_log_reg_grid_results_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a6e55",
   "metadata": {},
   "source": [
    "We now run the model with our chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_ump_log_reg_accs = []\n",
    "vert_ump_log_reg_f1s = []\n",
    "vert_ump_log_reg_praucs = []\n",
    "\n",
    "vert_ump_log_reg_preds = []\n",
    "vert_ump_log_reg_pred_strikes = []\n",
    "\n",
    "vert_ump_log_reg_feat = ['plate_x_mag', 'plate_z_hscw', 'umpire']\n",
    "\n",
    "vert_ump_log_reg_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('categorical', OneHotEncoder(), ['umpire', 'plate_z_hscw']),\n",
    "        ('continuous', StandardScaler(), ['plate_x_mag'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "for train_index, test_index in vert_ump_log_reg_kfold.split(vert_ump_train, vert_ump_train.binary_bs):\n",
    "    # Splitting up our data using the indices from our kfold split\n",
    "    split_train = vert_ump_train.iloc[train_index]\n",
    "    split_test = vert_ump_train.iloc[test_index]\n",
    "    \n",
    "    # Setting up the normalization pipeline\n",
    "    vert_ump_log_reg_pipeline = Pipeline([\n",
    "        ('log_reg_preprocessor', vert_ump_log_reg_preprocessor),\n",
    "        ('log_reg', LogisticRegression(penalty=None, max_iter=1000))\n",
    "    ])\n",
    "    \n",
    "    # Fitting the pipeline\n",
    "    vert_ump_log_reg_pipeline.fit(split_train[vert_ump_log_reg_feat], split_train.binary_bs)\n",
    "    \n",
    "    # Predictions\n",
    "    split_pred = vert_ump_log_reg_pipeline.predict(split_test[vert_ump_log_reg_feat])\n",
    "    vert_ump_log_reg_preds.append(split_pred)\n",
    "    split_pred_dict = {1:0}\n",
    "    for entry in split_pred:\n",
    "        if entry==1:\n",
    "            split_pred_dict[1] += 1\n",
    "    vert_ump_log_reg_pred_strikes.append(split_pred_dict[1])\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    vert_ump_log_reg_accs.append( accuracy_score(split_test.binary_bs, split_pred) )\n",
    "    vert_ump_log_reg_f1s.append( f1_score(split_test.binary_bs, split_pred) )\n",
    "    vert_ump_log_reg_prec, vert_ump_log_reg_rec, _ = precision_recall_curve(split_test.binary_bs, split_pred)\n",
    "    vert_ump_log_reg_praucs.append(auc(vert_ump_log_reg_rec, vert_ump_log_reg_prec))\n",
    "\n",
    "vert_ump_log_reg_stats = pd.DataFrame(data={\n",
    "    'vert_ump_pred_strikes':vert_ump_log_reg_pred_strikes,\n",
    "    'vert_ump_log_reg_accuracy':vert_ump_log_reg_accs,\n",
    "    'vert_ump_log_reg_f1':vert_ump_log_reg_f1s,\n",
    "    'vert_ump_log_reg_pr_auc':vert_ump_log_reg_praucs\n",
    "    })\n",
    "\n",
    "vert_ump_log_reg_stats.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944387d4",
   "metadata": {},
   "source": [
    "We now compare the metrics for this model with the baseline model for the `vertical` data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5182f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_ump_log_reg_combo_stats = pd.concat([vert_baseline_stats.describe(), vert_ump_log_reg_stats.describe()], axis=1)\n",
    "\n",
    "vert_ump_log_reg_combo_stats_order = ['vert_baseline_accuracy', 'vert_ump_log_reg_accuracy', 'vert_baseline_f1']\n",
    "vert_ump_log_reg_combo_stats_order.extend(['vert_ump_log_reg_f1', 'vert_baseline_pr_auc', 'vert_ump_log_reg_pr_auc'])\n",
    "vert_ump_log_reg_combo_stats = vert_ump_log_reg_combo_stats[vert_ump_log_reg_combo_stats_order]\n",
    "\n",
    "vert_ump_log_reg_combo_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6955d140",
   "metadata": {},
   "source": [
    "This model's performance is comparable to what we have seen previously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1e6607",
   "metadata": {},
   "source": [
    "<a id='2.9.3'></a>\n",
    "### 2.9.3 - Support Vector Machines - Vertical with Umpires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94d9a4b",
   "metadata": {},
   "source": [
    "We begin by preparing the cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d202b87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_splits = 10\n",
    "\n",
    "vert_ump_svm_kfold_rand_state = 825\n",
    "\n",
    "vert_ump_svm_kfold = StratifiedKFold(kfold_splits, shuffle=True, random_state=vert_ump_svm_kfold_rand_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cf74c7",
   "metadata": {},
   "source": [
    "After observing the following hyperparameter tuning, we take `C=0.001` with a maximum of 5000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dbf447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vert_ump_svm_feat = ['plate_x_mag', 'plate_z_hscw', 'umpire']\n",
    "\n",
    "#vert_ump_svm_preprocessor = ColumnTransformer(\n",
    "#    transformers=[\n",
    "#            ('categorical', OneHotEncoder(), ['umpire', 'plate_z_hscw']),\n",
    "#            ('continuous', StandardScaler(), ['plate_x_mag'])\n",
    "#        ],\n",
    "#    remainder='passthrough')\n",
    "    \n",
    "## Setting up the normalization pipeline\n",
    "#vert_ump_svm_pipeline = Pipeline([\n",
    "#    ('svm_preprocessor', vert_ump_svm_preprocessor),\n",
    "#    ('svm', LinearSVC())\n",
    "#])\n",
    "\n",
    "## Creating the grid\n",
    "#vert_ump_svm_grid = GridSearchCV(\n",
    "#    vert_ump_svm_pipeline,\n",
    "#    param_grid={\n",
    "#        'svm__C':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "#        'svm__max_iter':[1000, 5000, 10000, 50000, 100000, 500000, 1000000, 5000000]\n",
    "#    },\n",
    "#    scoring='accuracy',\n",
    "#    cv=5\n",
    "#)\n",
    "    \n",
    "## Fitting the grid\n",
    "#vert_ump_svm_grid.fit(vert_ump_train[vert_ump_svm_feat], vert_ump_train.binary_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321a5bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vert_ump_svm_grid_results = pd.DataFrame(data=vert_ump_svm_grid.cv_results_)\n",
    "\n",
    "#vert_ump_svm_grid_results_order = ['rank_test_score', 'std_test_score', 'param_svm__C', 'param_svm__max_iter']\n",
    "#vert_ump_svm_grid_results_order.extend(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'split0_test_score'])\n",
    "#vert_ump_svm_grid_results_order.extend(['split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score'])\n",
    "\n",
    "#vert_ump_svm_grid_results = vert_ump_svm_grid_results[vert_ump_svm_grid_results_order].sort_values(['rank_test_score', 'std_test_score', 'mean_fit_time'])\n",
    "\n",
    "#vert_ump_svm_grid_results.to_csv('vert_ump_svm_grid_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8622d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vert_ump_svm_grid_results_csv = pd.read_csv('vert_ump_svm_grid_results.csv')\n",
    "\n",
    "#vert_ump_svm_grid_results_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08810506",
   "metadata": {},
   "source": [
    "We now run our model with the chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703da9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_ump_svm_accs = []\n",
    "vert_ump_svm_f1s = []\n",
    "vert_ump_svm_praucs = []\n",
    "vert_ump_svm_pred_strikes = []\n",
    "\n",
    "vert_ump_svm_feat = ['plate_x_mag', 'plate_z_hscw', 'umpire']\n",
    "\n",
    "vert_ump_svm_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('categorical', OneHotEncoder(), ['umpire', 'plate_z_hscw']),\n",
    "        ('continuous', StandardScaler(), ['plate_x_mag'])\n",
    "        ],\n",
    "    remainder='passthrough')\n",
    "\n",
    "\n",
    "for train_index, test_index in vert_ump_svm_kfold.split(vert_ump_train, vert_ump_train.binary_bs):\n",
    "    # Splitting up our data using the indices from our kfold split\n",
    "    split_train = vert_train.iloc[train_index]\n",
    "    split_test = vert_train.iloc[test_index]\n",
    "    \n",
    "    # Setting up the normalization pipeline\n",
    "    vert_ump_svm_pipeline = Pipeline([\n",
    "        ('svm_preprocessor', vert_ump_svm_preprocessor),\n",
    "        ('svm', LinearSVC(C=0.01, max_iter=5000))\n",
    "    ])\n",
    "    \n",
    "    # Fitting the pipeline\n",
    "    vert_ump_svm_pipeline.fit(split_train[vert_ump_svm_feat], split_train.binary_bs)\n",
    "    \n",
    "    # Predictions\n",
    "    split_pred = vert_ump_svm_pipeline.predict(split_test[vert_ump_svm_feat])\n",
    "    split_pred_dict = {1:0}\n",
    "    for entry in split_pred:\n",
    "        if entry==1:\n",
    "            split_pred_dict[1] += 1\n",
    "    vert_ump_svm_pred_strikes.append(split_pred_dict[1])\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    vert_ump_svm_accs.append( accuracy_score(split_test.binary_bs, split_pred) )\n",
    "    vert_ump_svm_f1s.append( f1_score(split_test.binary_bs, split_pred) )\n",
    "    vert_ump_svm_prec, vert_ump_svm_rec, _ = precision_recall_curve(split_test.binary_bs, split_pred)\n",
    "    vert_ump_svm_praucs.append(auc(vert_ump_svm_rec, vert_ump_svm_prec))\n",
    "\n",
    "vert_ump_svm_stats = pd.DataFrame(data={\n",
    "    'vert_ump_svm_pred_strikes':vert_ump_svm_pred_strikes,\n",
    "    'vert_ump_svm_accuracy':vert_ump_svm_accs,\n",
    "    'vert_ump_svm_f1':vert_ump_svm_f1s,\n",
    "    'vert_ump_svm_pr_auc':vert_ump_svm_praucs\n",
    "    })\n",
    "\n",
    "vert_ump_svm_stats.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2929e4",
   "metadata": {},
   "source": [
    "We again compare the metrics for this model with the metrics from the relevant baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_ump_svm_combo_stats = pd.concat([vert_baseline_stats.describe(), vert_ump_svm_stats.describe()], axis=1)\n",
    "\n",
    "vert_ump_svm_combo_stats_order = ['vert_baseline_accuracy', 'vert_ump_svm_accuracy', 'vert_baseline_f1']\n",
    "vert_ump_svm_combo_stats_order.extend(['vert_ump_svm_f1', 'vert_baseline_pr_auc', 'vert_ump_svm_pr_auc'])\n",
    "vert_ump_svm_combo_stats = vert_ump_svm_combo_stats[vert_ump_svm_combo_stats_order]\n",
    "\n",
    "vert_ump_svm_combo_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e09781",
   "metadata": {},
   "source": [
    "We again see similar model performance despite adding the `umpire` feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcfb101",
   "metadata": {},
   "source": [
    "<a id='2.10'></a>\n",
    "## 2.10 - Modeling with Added Vertical Location and Umpires: Predicting True Balls and Strikes\n",
    "\n",
    "We proceed similarly to `Sections 2.3, 2.6, 2.8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this requires vert_ump_log_reg_kfold, which is created and run in Section 2.9.2\n",
    "# The code below requires that code to be run first anyway, so there should be no issue\n",
    "# We reference the call in 2.9.2 so that the random states are always the same\n",
    "\n",
    "vert_ump_split_data_frames = []\n",
    "\n",
    "# This fills the list created above with the split data frames\n",
    "for train_index, test_index in vert_ump_log_reg_kfold.split(vert_ump_train, vert_ump_train.binary_bs):\n",
    "    vert_ump_split_data_frames.append(vert_ump_train.iloc[test_index])\n",
    "\n",
    "\n",
    "# Next, we go through the split data frames, add the predictions, and reduce to the relevant features\n",
    "for counter in range(len(vert_ump_split_data_frames)):\n",
    "    temp_df = vert_ump_split_data_frames[counter]\n",
    "    temp_df = temp_df.assign(pred_bs=vert_ump_log_reg_preds[counter])\n",
    "    temp_df = temp_df[['true_ball/strike', 'pred_bs', 'binary_bs', 'correct_call']]\n",
    "    vert_ump_split_data_frames[counter] = temp_df\n",
    "\n",
    "    \n",
    "# We again go through the split data frames, check whether the predictions were correct or incorrect,\n",
    "# and store that information\n",
    "for counter in range(len(vert_ump_split_data_frames)):\n",
    "    correct_preds = []\n",
    "    temp_df = vert_ump_split_data_frames[counter]\n",
    "    for ind in temp_df.index:\n",
    "        pred = temp_df.at[ind, 'pred_bs']\n",
    "        ump_call = temp_df.at[ind, 'binary_bs']\n",
    "        cor_incorr = temp_df.at[ind, 'correct_call']\n",
    "        if pred == ump_call:\n",
    "            if cor_incorr == 'correct_call':\n",
    "                correct_preds.append('correct_pred')\n",
    "            else:\n",
    "                correct_preds.append('incorrect_pred')\n",
    "        else:\n",
    "            if cor_incorr == 'correct_call':\n",
    "                correct_preds.append('incorrect_pred')\n",
    "            else:\n",
    "                correct_preds.append('correct_pred')\n",
    "    temp_df = temp_df.assign(correct_pred=correct_preds)\n",
    "    vert_ump_split_data_frames[counter] = temp_df\n",
    "\n",
    "# Finally, we make a data frame comparing the umpire calls to the predicted calls\n",
    "correct_call_test_list = []\n",
    "correct_pred_test_list = []\n",
    "\n",
    "for counter in range(len(vert_ump_split_data_frames)):\n",
    "    correct_call_test_list.append(hor_ump_split_data_frames[counter].correct_call.value_counts(normalize=True)[0])\n",
    "    correct_pred_test_list.append(hor_ump_split_data_frames[counter].correct_pred.value_counts(normalize=True)[0])\n",
    "\n",
    "vert_ump_log_reg_call_pred_stats = pd.DataFrame(data={\n",
    "    'vert_ump_correct_call_percent':correct_call_test_list,\n",
    "    'vert_ump_correct_pred_percent':correct_pred_test_list\n",
    "    }\n",
    ").describe()\n",
    "\n",
    "vert_ump_log_reg_call_pred_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0abe3f",
   "metadata": {},
   "source": [
    "<a id='2.11'></a>\n",
    "## 2.11 - Summary of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfd6198",
   "metadata": {},
   "source": [
    "Let us recall the two primary questions introduced in `Section 1` that we seek to answer in this section:\n",
    "\n",
    "#### Question 1: Would a pseudo-robo-umpire (i.e. a model trained on real umpire data) be more or less accurate than an actual umpire?  \n",
    "\n",
    "#### Question 2: How large of an overall impact does an individual umpire have on training a pseudo-robo-umpire?   \n",
    "  \n",
    "We address each of these questions in turn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfefec6",
   "metadata": {},
   "source": [
    "<a id='2.11.1'></a>\n",
    "### 2.11.1 - Addressing Question 1\n",
    "\n",
    "To begin, we simply recall the comparisons of correct call percentage against correct prediction percentage for the `LogisticRegression` models in `Subsections 2.3, 2.6`. We do not include the correct prediction percentages from `Subsections 2.8, 2.10`, as those models include `umpire` as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20656c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Section 2.3\n",
    "hor_no_ump_log_reg_call_pred_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35bfed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Section 2.6\n",
    "vert_no_ump_log_reg_call_pred_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15301205",
   "metadata": {},
   "source": [
    "We do see improvements in mean correct prediction percentage over mean correct call percentage, up from 95.1% to 96.3% when using the `horizontal` data frame and up from 91.7% to 94.7% when using the `vertical` data frame.  \n",
    "  \n",
    "The increase in the `vertical` case is more compelling because of both \n",
    "* the larger increase between correct call percentage and correct prediction percentage, and\n",
    "* the fact that the `vertical` data frame contains a more varied set of pitches than the `horizontal` data frame (revisit the beginning of `Section 2.2` for more details). \n",
    "\n",
    "According to [Umpire Scorecards](https://umpscorecards.com/umpires/), the least accurate umpire in the 2024 season has been James Jean (with an accuracy of 91.8%) and the most accuracte umpire has been Austin Jones (with an accuracy of 96%), as of the afternoon of 12 Aug 2024. While these aren't exactly comparable with the data we have been using -- our data only includes pitches that were called balls or strikes, so swinging strikes, balls in play, etc. are not considered -- it does provide a good reference point regarding the 3% difference between the correct call percentage and correct prediction percentage for the `vertical` data frame. Namely, the 3% difference is smaller than the difference between the best and worst pitch callers.  \n",
    "  \n",
    "In short, a pseudo-robo-umpire would be more accurate on average, but still within the range of expected outcomes by human umpires. The pseudo-robo-umpire's performance could potentially be raised further by restricting to training only on pitch data with umpires who's correct call percentage is better than average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494d3cbb",
   "metadata": {},
   "source": [
    "<a id='2.11.2'></a>\n",
    "### 2.11.2 - Addressing Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12ff8dc",
   "metadata": {},
   "source": [
    "We constructed models in `Sections 2.2, 2.5, 2.7, 2.9`; here is how they vary:\n",
    "* In `Section 2.2`, we use the `horizontal` data frame and only the `plate_x_mag` feature;\n",
    "* In `Section 2.7`, we use the `horizontal` data frame with both the `plate_x_mag` and `umpire` features;  \n",
    "  \n",
    "* In `Section 2.5`, we use the `vertical` data frame with the `plate_x_mag` and `plate_z_hscw` features;\n",
    "* In `Section 2.9`, we use the `vertical` data frame with the `plate_x_mag, plate_z_hscw`, and `umpire` features.  \n",
    "  \n",
    "Consequently, to measure the impact of individual umpires we will compare the metrics from the models in `Section 2.2` with those in `Section 2.7`, as well as the metrics from the models in `Sections 2.5` with those in `Section 2.9`.\n",
    "  \n",
    "As can be seen in the tables below, there are only negligible improvements among all metrics for the `LinearSVC` models (differences of approximately 0.0004, 0.0004, and 0.00001), only negligible improvements among accuracy and F1-score for the `LogisticRegression` models (differences of approximately 0.0008 and 0.0008), and a minor decrease in PR-AUC for the `LogisticRegression` models from `Section 2.2` to `Section 2.7`.  \n",
    "  \n",
    "In the case of the models from `Section 2.5` and `Section 2.9`, the improvements across all metrics for the `LinearSVC` models are minimal (with differences of approximately 0.0016, 0.0041, and 0.0011). It is similar for the `LogisiticRegression` models, with approximate increases of 0.000009 and 0.00014 for accuracy and F1-score, with a decrease of 0.000042 in PR-AUC. \n",
    "\n",
    "Given that any improvements in metrics for models which included the `umpire` feature we negligible (improvements around or less than 0.08%), this provides strong evidence that individual umpires do not have a large impact on incorrect calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0defbe6c",
   "metadata": {},
   "source": [
    "<a id='2.11.2.1'></a>\n",
    "#### 2.11.2.1 - Comparing the Effect of Umpires on Logistic Regression Models using the `Horizontal` Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bddb75",
   "metadata": {},
   "source": [
    "We begin by creating a data frame with all of the relevant metrics for the comparison. We will then restict to certain columns to clearly compare accuracy, F1-score, and PR-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a67fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_log_reg_comp = pd.concat([hor_no_ump_log_reg_stats.describe(), hor_ump_log_reg_stats.describe()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471de497",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46470fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_log_reg_acc = hor_log_reg_comp[['hor_no_ump_log_reg_accuracy', 'hor_ump_log_reg_accuracy']]\n",
    "\n",
    "hor_log_reg_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1866a92",
   "metadata": {},
   "source": [
    "##### F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35196223",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_log_reg_f1 = hor_log_reg_comp[['hor_no_ump_log_reg_f1', 'hor_ump_log_reg_f1']]\n",
    "\n",
    "hor_log_reg_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbbcca0",
   "metadata": {},
   "source": [
    "##### PR-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a30b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_log_reg_pr_auc = hor_log_reg_comp[['hor_no_ump_log_reg_pr_auc', 'hor_ump_log_reg_pr_auc']]\n",
    "\n",
    "hor_log_reg_pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be1fd2c",
   "metadata": {},
   "source": [
    "<a id='2.11.2.2'></a>\n",
    "#### 2.11.2.2 - Comparing the Effect of Umpires on SVM Models using the `Horizontal` Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a730e7",
   "metadata": {},
   "source": [
    "We begin by creating a data frame with all of the relevant metrics for the comparison. We will then restict to certain columns to clearly compare accuracy, F1-score, and PR-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657732ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_svm_comp = pd.concat([hor_no_ump_svm_stats.describe(), hor_ump_svm_stats.describe()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e150534d",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142ff987",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_svm_acc = hor_svm_comp[['hor_no_ump_svm_accuracy', 'hor_ump_svm_accuracy']]\n",
    "\n",
    "hor_svm_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf92c8a",
   "metadata": {},
   "source": [
    "##### F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff085a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_svm_f1 = hor_svm_comp[['hor_no_ump_svm_f1', 'hor_ump_svm_f1']]\n",
    "\n",
    "hor_svm_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13ba84a",
   "metadata": {},
   "source": [
    "##### PR-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a0de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_svm_pr_auc = hor_svm_comp[['hor_no_ump_svm_pr_auc', 'hor_ump_svm_pr_auc']]\n",
    "\n",
    "hor_svm_pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d1edb2",
   "metadata": {},
   "source": [
    "<a id='2.11.2.3'></a>\n",
    "#### 2.11.2.3 - Comparing the Effect of Umpires on Logistic Regression Models using the `Vertical` Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09caa3ec",
   "metadata": {},
   "source": [
    "We begin by creating a data frame with all of the relevant metrics for the comparison. We will then restict to certain columns to clearly compare accuracy, F1-score, and PR-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4461ac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_log_reg_comp = pd.concat([vert_no_ump_log_reg_stats.describe(), vert_ump_log_reg_stats.describe()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0623ac",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be85627",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_log_reg_acc = vert_log_reg_comp[['vert_no_ump_log_reg_accuracy', 'vert_ump_log_reg_accuracy']]\n",
    "\n",
    "vert_log_reg_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3320451",
   "metadata": {},
   "source": [
    "##### F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f384fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_log_reg_f1 = vert_log_reg_comp[['vert_no_ump_log_reg_f1', 'vert_ump_log_reg_f1']]\n",
    "\n",
    "vert_log_reg_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4ecce4",
   "metadata": {},
   "source": [
    "##### PR-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3f5050",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_log_reg_pr_auc = vert_log_reg_comp[['vert_no_ump_log_reg_pr_auc', 'vert_ump_log_reg_pr_auc']]\n",
    "\n",
    "vert_log_reg_pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24b0e04",
   "metadata": {},
   "source": [
    "<a id='2.11.2.4'></a>\n",
    "#### 2.11.2.4 - Comparing the Effect of Umpires on SVM Models using the `Vertical` Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abaf158",
   "metadata": {},
   "source": [
    "We begin by creating a data frame with all of the relevant metrics for the comparison. We will then restict to certain columns to clearly compare accuracy, F1-score, and PR-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b8fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_svm_comp = pd.concat([vert_no_ump_svm_stats.describe(), vert_ump_svm_stats.describe()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd2e7ba",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d368920",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_svm_acc = vert_svm_comp[['vert_no_ump_svm_accuracy', 'vert_ump_svm_accuracy']]\n",
    "\n",
    "vert_svm_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9c2575",
   "metadata": {},
   "source": [
    "##### F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6a8d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_svm_f1 = vert_svm_comp[['vert_no_ump_svm_f1', 'vert_ump_svm_f1']]\n",
    "\n",
    "vert_svm_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3201cc",
   "metadata": {},
   "source": [
    "##### PR-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ea92e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_svm_pr_auc = vert_svm_comp[['vert_no_ump_svm_pr_auc', 'vert_ump_svm_pr_auc']]\n",
    "\n",
    "vert_svm_pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee41dee",
   "metadata": {},
   "source": [
    "<a id='2.11.3'></a>\n",
    "### 2.11.3 - Additional Reference Tables\n",
    "\n",
    "The following code creates tables so that the interested reader can view the relevant metrics (accuracy, F1-score, PR-AUC), as well as information on correct call/prediction percentages.  \n",
    "  \n",
    "For viewing considerations, the tables are currently commented out by default in the sections below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c99eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_desc = [\n",
    "    hor_baseline_stats.describe(),\n",
    "    hor_no_ump_log_reg_stats.describe(),\n",
    "    hor_no_ump_svm_stats.describe(),\n",
    "    hor_ump_log_reg_stats.describe(),\n",
    "    hor_ump_svm_stats.describe(),\n",
    "    vert_baseline_stats.describe(),\n",
    "    vert_no_ump_log_reg_stats.describe(),\n",
    "    vert_no_ump_svm_stats.describe(),\n",
    "    vert_ump_log_reg_stats.describe(),\n",
    "    vert_ump_svm_stats.describe(),\n",
    "]\n",
    "\n",
    "all_combo_stats = pd.concat(all_desc, axis=1)\n",
    "\n",
    "# accuracy\n",
    "hor_acc_cols = [\n",
    "    'hor_baseline_accuracy',\n",
    "    'hor_no_ump_log_reg_accuracy',\n",
    "    'hor_no_ump_svm_accuracy',\n",
    "    'hor_ump_log_reg_accuracy',\n",
    "    'hor_ump_svm_accuracy',\n",
    "]\n",
    "\n",
    "hor_acc_stats = all_combo_stats[hor_acc_cols]\n",
    "\n",
    "vert_acc_cols = [\n",
    "    'vert_baseline_accuracy',\n",
    "    'vert_no_ump_log_reg_accuracy',\n",
    "    'vert_no_ump_svm_accuracy',\n",
    "    'vert_ump_log_reg_accuracy',\n",
    "    'vert_ump_svm_accuracy',\n",
    "]\n",
    "\n",
    "vert_acc_stats = all_combo_stats[vert_acc_cols]\n",
    "\n",
    "\n",
    "# F1-scores\n",
    "hor_f1_cols = [\n",
    "    'hor_baseline_f1',\n",
    "    'hor_no_ump_log_reg_f1',\n",
    "    'hor_no_ump_svm_f1',\n",
    "    'hor_ump_log_reg_f1',\n",
    "    'hor_ump_svm_f1',\n",
    "]\n",
    "\n",
    "hor_f1_stats = all_combo_stats[hor_f1_cols]\n",
    "\n",
    "vert_f1_cols = [\n",
    "    'vert_baseline_f1',\n",
    "    'vert_no_ump_log_reg_f1',\n",
    "    'vert_no_ump_svm_f1',\n",
    "    'vert_ump_log_reg_f1',\n",
    "    'vert_ump_svm_f1',\n",
    "]\n",
    "\n",
    "vert_f1_stats = all_combo_stats[vert_f1_cols]\n",
    "\n",
    "\n",
    "# PR-AUCs\n",
    "hor_pr_auc_cols = [\n",
    "    'hor_baseline_pr_auc',\n",
    "    'hor_no_ump_log_reg_pr_auc',\n",
    "    'hor_no_ump_svm_pr_auc',\n",
    "    'hor_ump_log_reg_pr_auc',\n",
    "    'hor_ump_svm_pr_auc',\n",
    "]\n",
    "\n",
    "hor_pr_auc_stats = all_combo_stats[hor_pr_auc_cols]\n",
    "\n",
    "vert_pr_auc_cols = [\n",
    "    'vert_baseline_pr_auc',\n",
    "    'vert_no_ump_log_reg_pr_auc',\n",
    "    'vert_no_ump_svm_pr_auc',\n",
    "    'vert_ump_log_reg_pr_auc',\n",
    "    'vert_ump_svm_pr_auc',\n",
    "]\n",
    "\n",
    "vert_pr_auc_stats = all_combo_stats[vert_pr_auc_cols]\n",
    "\n",
    "# Predictions vs. Umpires\n",
    "all_pred_list = [\n",
    "     hor_no_ump_log_reg_call_pred_stats,\n",
    "    vert_no_ump_log_reg_call_pred_stats,\n",
    "    hor_ump_log_reg_call_pred_stats,\n",
    "    vert_ump_log_reg_call_pred_stats\n",
    "]\n",
    "\n",
    "all_preds = pd.concat(all_pred_list, axis=1)\n",
    "\n",
    "hor_no_ump_pred_minus_call = all_preds.at['mean', 'hor_no_ump_correct_pred_percent'] - all_preds.at['mean', 'hor_no_ump_correct_call_percent']\n",
    "vert_no_ump_pred_minus_call = all_preds.at['mean', 'vert_no_ump_correct_pred_percent'] - all_preds.at['mean', 'vert_no_ump_correct_call_percent']\n",
    "hor_ump_pred_minus_call = all_preds.at['mean', 'hor_ump_correct_pred_percent'] - all_preds.at['mean', 'hor_ump_correct_call_percent']\n",
    "vert_ump_pred_minus_call = all_preds.at['mean', 'vert_ump_correct_pred_percent'] - all_preds.at['mean', 'vert_ump_correct_call_percent']\n",
    "\n",
    "preds_minus_calls_vals = [\n",
    "    hor_no_ump_pred_minus_call,\n",
    "    vert_no_ump_pred_minus_call,\n",
    "    hor_ump_pred_minus_call,\n",
    "    vert_ump_pred_minus_call\n",
    "]\n",
    "\n",
    "preds_minus_calls = pd.DataFrame(\n",
    "    {'Correct Prediction Rate - Correct Call Rate':preds_minus_calls_vals},\n",
    "    index = ['hor_no_ump', 'vert_no_ump', 'hor_ump', 'vert_ump']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f305a4",
   "metadata": {},
   "source": [
    "<a id='2.11.3.1'></a>\n",
    "#### 2.11.3.1 - Accuracy Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f000505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hor_acc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d888879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vert_acc_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affaf8df",
   "metadata": {},
   "source": [
    "<a id='2.11.3.2'></a>\n",
    "#### 2.11.3.2 - F1-Score Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74fee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hor_f1_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d11dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vert_f1_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be58a92",
   "metadata": {},
   "source": [
    "<a id='2.11.3.3'></a>\n",
    "#### 2.11.3.3 - PR-AUC Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60ae03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hor_pr_auc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4feb7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vert_pr_auc_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c450beb",
   "metadata": {},
   "source": [
    "<a id='2.11.3.4'></a>\n",
    "#### 2.11.3.4 - Correct Calls and Correct Predictions Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5789ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53886584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds_minus_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63652256",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea9131c",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "# 3 - Non-Location Factors: Visualizations and Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60224ba",
   "metadata": {},
   "source": [
    "Recall that in this section, we are focusing on the following questions:  \n",
    "#### Question 3: What factors (beyond pitch location) most impact an umpire making an incorrect ball/strike call?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7428250",
   "metadata": {},
   "source": [
    "We begin by reading in the data for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f82c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_df = pd.read_csv(\"large_model_data.csv\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "all_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c33ea0",
   "metadata": {},
   "source": [
    "The columns of this data set are:  \n",
    "\n",
    "* `ball/strike` - the umpire's call on the field of if that pitch was a ball or strike ^  \n",
    "* `binary_bs` - a binary version of `ball/strike`  \n",
    "* `true_ball/strike` - an assessment of if the pitch was a ball or called strike based on the regulation strike zone  \n",
    "* `correct_call` - checks if the umpire's call matches the correct call according to the regulation strike zone  \n",
    "* `zone` - the Gameday Zone of the pitch ^  \n",
    "* `hscw` - records if the pitch was in the heart, shadow, chase, or waste region of the strike zone  \n",
    "* `plate_x` - the horizontal location of the pitch (relative to the middle of home plate) as the pitch crossed home plate ^  \n",
    "* `plate_x_mag` - absolute value of `plate_x`  \n",
    "* `plate_x_dir` - sign of `plate_x`  \n",
    "* `plate_z` - the height of the pitch ^  \n",
    "* `sz_top` - the top height of the regulation strike zone (changes per batter) ^  \n",
    "* `sz_bot` - the bottom height of the regulation strike zone (changes per batter) ^  \n",
    "* `release_speed` - speed of pitch out-of-hand, as measured by Statcast (since data is from 2023) ^\n",
    "* `release_pos_x` - horizontal release position of the ball (relative to the middle of the plate) ^\n",
    "* `release_pos_y` - vertical release position of the ball (relative to the middle of the plate) ^\n",
    "* `balls` - number of balls in count before the pitch ^\n",
    "* `strikes` - number of strikes in count before the pitch ^\n",
    "* `pfx_x` - horizontal movement of the pitch ^ \n",
    "* `pfx_z` - vertical movement of the pitch ^\n",
    "* `outs_when_up` - number of out before the pitch ^\n",
    "* `inning` - inning number before the pitch ^\n",
    "* `vx0` - horizontal velocity of the pitch (measured at y=50) ^\n",
    "* `vy0` - depth velocity of the pitch (measured at y=50) ^\n",
    "* `vz0` - vertical velocity of the pitch (measured at y=50) ^\n",
    "* `ax` - horizontal acceleration of the pitch (measured at y=50) ^\n",
    "* `ay` - depth acceleration of the pitch (measured at y=50) ^\n",
    "* `az` - vertical acceleration of the pitch (measured at y=50) ^\n",
    "* `effective_speed` - adjusted speed based on pitcher's extension at release ^\n",
    "* `release_spin_rate` - spin rate of pitch, as measured by Statcast ^\n",
    "* `release_extension` - pitcher's extension at release, as measured by Statcast ^\n",
    "* `release_pos_y` - depth of release position, as measured from catcher's perspective ^\n",
    "* `at_bat_number` - plate appearance number for the game ^\n",
    "* `pitch_number` - number of pitch in the given plate appearance ^\n",
    "* `home_score` - score of the home team before the pitch ^\n",
    "* `away_score` - score of the away team before the pitch ^\n",
    "* `umpire` - identity of home plate umpire, as scraped from Baseball Reference\n",
    "\n",
    "^ as provided by Baseball Savant, see the [documentation](https://baseballsavant.mlb.com/csv-docs) for more details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0643d8",
   "metadata": {},
   "source": [
    "<a id='3.1'></a>\n",
    "## 3.1 - Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfacc901",
   "metadata": {},
   "source": [
    "We will soon visually examine how most of our non-location features impact the rate at which umpires correctly call pitches. However, we first categorize how and why the features present will or will not be used.  \n",
    "\n",
    "* Firstly, note that we are tracking correct call percentage across features, so we will not be using `correct_call` as its own feature.\n",
    "\n",
    "* Secondly, `ball/strike`, `binary_bs`, `true_ball/strike`, `plate_x`, `plate_x_mag`, `plate_x_dir`, and `plate_z` are all directly tied to pitch location, so we will not be using them as independent features in this section.\n",
    "\n",
    "* Thirdly, we will include the `zone` feature at times for completeness, but it is also based on pitch location and thus will not be a focus of this section. Additionally, we have already considered the `umpire` feature in `Section 2`, so we will not consider it here.\n",
    "\n",
    "* Finally, we note that `effective_speed` is an adjusted version of `release_speed` based on `release_extension`; as a result, we only use `effective_speed` in this section.\n",
    "\n",
    "For continuous features, we will indicate quartiles using red and black lines. For certain linear categorical features, we will also include relevant information about the distribution to indicate outliers (such as `pitch_number`). We will also include a purple line in our visualizations to represent the mean correct call percentage from across this dataset (91.27%) as a reference point.  \n",
    "  \n",
    "Note that certain data is collected at a level of granularity that would require a tremendous amount of data to have sufficiently many samples; for example, `sz_top` data is collected at a precision of 2 decimal places (e.g. 3.33). In cases like this, we will collect data points into large \"buckets\" for increase stability. In the case of `sz_top`, every pitch with an `sz_top` value between 3.3 and 3.4 will be collected into one group labeled \"3.35\". We then plot the correct call percentage for all of these groups instead of the original features. Whenever we use a bucket version of a feature, we will make explicit note of this process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9d6ff1",
   "metadata": {},
   "source": [
    "<a id='3.1.1'></a>\n",
    "### 3.1.1 - Regions\n",
    "\n",
    "<a id='3.1.1.1'></a>\n",
    "#### 3.1.1.1 - `zone`\n",
    "\n",
    "We begin by examining how correct call percentage varies by Statcast Gameday Zone. For reference, we include the following visual and note that zones 1-9 are within the regulation strike zone and that zones 11-14 are outside of the regulation strike zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e49fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"statcast-gameday-zones.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e4d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_percents_1 = []\n",
    "zone_index_1 = []\n",
    "\n",
    "zone_percents_2 = []\n",
    "zone_index_2 = []\n",
    "\n",
    "for index in range(1,10):\n",
    "    temp_list = all_features_df[all_features_df['zone'] == index].correct_call.value_counts(normalize=True).to_list()\n",
    "    zone_percents_1.append(temp_list[0])\n",
    "    zone_index_1.append(index)\n",
    "\n",
    "for index in range(11,15):\n",
    "    temp_list = all_features_df[all_features_df['zone'] == index].correct_call.value_counts(normalize=True).to_list()\n",
    "    zone_percents_2.append(temp_list[0])\n",
    "    zone_index_2.append(index)\n",
    "    \n",
    "zone_stats_1 = pd.DataFrame({'zone':zone_index_1, 'correct_call_percent':zone_percents_1})\n",
    "zone_stats_2 = pd.DataFrame({'zone':zone_index_2, 'correct_call_percent':zone_percents_2})\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=zone_stats_1, x='zone', y='correct_call_percent').set_xticks(range(1,15))\n",
    "sns.lineplot(data=zone_stats_2, x='zone', y='correct_call_percent').set_xticks(range(1,15))\n",
    "plt.plot([1, 14], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(1.1, 0.92, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a886e4",
   "metadata": {},
   "source": [
    "<a id='3.1.2'></a>\n",
    "### 3.1.2 - Boundaries (top and bottom of the strike zone)\n",
    "\n",
    "<a id='3.1.2.1'></a>\n",
    "#### 3.1.2.1 - `sz_top`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34fe915",
   "metadata": {},
   "source": [
    "For `sz_top`, we split our data into buckets with a constant width of 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5674e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_top_percents = []\n",
    "sz_top_index = []\n",
    "\n",
    "for index in range(25,44):\n",
    "    temp_list = all_features_df[\n",
    "        (index*0.1 <= all_features_df['sz_top']) & \n",
    "        (all_features_df['sz_top'] < (index*0.1)+0.1)].correct_call.value_counts(normalize=True).to_list()\n",
    "    sz_top_percents.append(temp_list[0])\n",
    "    sz_top_index.append(index*0.1+0.05)\n",
    "    \n",
    "sz_top_stats = pd.DataFrame({'sz_top':sz_top_index, 'correct_call_percent':sz_top_percents})\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=sz_top_stats, x='sz_top', y='correct_call_percent')\n",
    "plt.plot([3.22, 3.22], [0.87, 1], color='red', linewidth=2)\n",
    "plt.plot([3.36, 3.36], [0.87, 1], color='black', linewidth=2)\n",
    "plt.plot([3.5, 3.5], [0.87, 1], color='red', linewidth=2)\n",
    "plt.text(3.12, 0.99, '25%', color='red', fontsize='x-large')\n",
    "plt.text(3.38, 0.99, '50%', color='black', fontsize='x-large')\n",
    "plt.text(3.52, 0.99, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([2.5, 4.3], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(3.76, 0.923, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7e800d",
   "metadata": {},
   "source": [
    "Note that 50% of all pitches occur with a top height of the strike zone between 3.22 and 3.5, so we zoom in on that region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c6c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(\n",
    "    data=sz_top_stats[(2.95 <= sz_top_stats['sz_top']) & (sz_top_stats['sz_top'] < 3.75)],\n",
    "    x='sz_top',\n",
    "    y='correct_call_percent')\n",
    "plt.plot([3.22, 3.22], [0.9, 0.93], color='red', linewidth=2)\n",
    "plt.plot([3.36, 3.36], [0.9, 0.93], color='black', linewidth=2)\n",
    "plt.plot([3.5, 3.5], [0.9, 0.93], color='red', linewidth=2)\n",
    "plt.text(3.23, 0.928, '25%', color='red', fontsize='x-large')\n",
    "plt.text(3.365, 0.928, '50%', color='black', fontsize='x-large')\n",
    "plt.text(3.51, 0.928, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([2.95, 3.65], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(3.01, 0.918, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c042276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For summary statistics on sz_top, run the following:\n",
    "# all_features_df.sz_top.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ad581f",
   "metadata": {},
   "source": [
    "<a id='3.1.2.2'></a>\n",
    "#### 3.1.2.2 - `sz_bot`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434e20b",
   "metadata": {},
   "source": [
    "For `sz_bot`, we split our data into buckets with a constant width of 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_bot_percents = []\n",
    "sz_bot_index = []\n",
    "\n",
    "for index in range(7,25):\n",
    "    temp_list = all_features_df[\n",
    "        (index*0.1 <= all_features_df['sz_bot']) & \n",
    "        (all_features_df['sz_bot'] < (index*0.1)+0.1)].correct_call.value_counts(normalize=True).to_list()\n",
    "    sz_bot_percents.append(temp_list[0])\n",
    "    sz_bot_index.append(index*0.1+0.05)\n",
    "    \n",
    "sz_bot_stats = pd.DataFrame({'sz_bot':sz_bot_index, 'correct_call_percent':sz_bot_percents})\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=sz_bot_stats, x='sz_bot', y='correct_call_percent')\n",
    "plt.plot([1.51, 1.51], [0.85, 1], color='red', linewidth=2)\n",
    "plt.plot([1.59, 1.59], [0.85, 1], color='black', linewidth=2)\n",
    "plt.plot([1.68, 1.68], [0.85, 1], color='red', linewidth=2)\n",
    "plt.text(1.42, 0.99, '25%', color='red', fontsize='x-large')\n",
    "plt.text(1.595, 0.99, '50%', color='black', fontsize='x-large')\n",
    "plt.text(1.695, 0.99, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([0.75, 2.4], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(1.01, 0.923, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfe1f1e",
   "metadata": {},
   "source": [
    "Note that 50% of all pitches occur with a bottom height of the strike zone between 1.51 and 1.68, so we zoom in on that region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05142ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(\n",
    "    data=sz_bot_stats[(1.3 < sz_bot_stats['sz_bot']) & (sz_bot_stats['sz_bot'] < 1.9)],\n",
    "    x='sz_bot',\n",
    "    y='correct_call_percent')\n",
    "plt.plot([1.51, 1.51], [0.89, 0.925], color='red', linewidth=2)\n",
    "plt.plot([1.59, 1.59], [0.89, 0.925], color='black', linewidth=2)\n",
    "plt.plot([1.68, 1.68], [0.89, 0.925], color='red', linewidth=2)\n",
    "plt.text(1.515, 0.9235, '25%', color='red', fontsize='x-large')\n",
    "plt.text(1.565, 0.9235, '50%', color='black', fontsize='x-large')\n",
    "plt.text(1.655, 0.9235, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([1.35, 1.85], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(1.705, 0.918, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be0a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For summary statistics, run the following:\n",
    "# all_features_df.sz_bot.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1247501a",
   "metadata": {},
   "source": [
    "<a id='3.1.3'></a>\n",
    "### 3.1.3 - Release\n",
    "\n",
    "<a id='3.1.3.1'></a>\n",
    "#### 3.1.3.1 - `effective_speed`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf5a901",
   "metadata": {},
   "source": [
    "For `sz_bot`, we split our data into buckets with a constant width of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3693d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "effective_speed_percents = []\n",
    "effective_speed_index = []\n",
    "\n",
    "for index in range(70,100):\n",
    "    temp_list = all_features_df[\n",
    "        (index <= all_features_df['effective_speed']) & \n",
    "        (all_features_df['effective_speed'] < index+1)].correct_call.value_counts(normalize=True).to_list()\n",
    "    effective_speed_percents.append(temp_list[0])\n",
    "    effective_speed_index.append(index+0.5)\n",
    "    \n",
    "effective_speed_stats = pd.DataFrame({'effective_speed':effective_speed_index,\n",
    "                                      'correct_call_percent':effective_speed_percents})\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=effective_speed_stats, x='effective_speed', y='correct_call_percent')\n",
    "plt.plot([84.8, 84.8], [0.9, 0.93], color='red', linewidth=2)\n",
    "plt.plot([90.3, 90.3], [0.9, 0.93], color='black', linewidth=2)\n",
    "plt.plot([94.2, 94.2], [0.9, 0.93], color='red', linewidth=2)\n",
    "plt.text(85.0, 0.9285, '25%', color='red', fontsize='x-large')\n",
    "plt.text(90.5, 0.9285, '50%', color='black', fontsize='x-large')\n",
    "plt.text(94.4, 0.9285, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([70.5, 99.5], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(79.5, 0.9155, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d1284d",
   "metadata": {},
   "source": [
    "Note that 50% of all pitches occur with an effective speed between 84.8 and 94.2, so we zoom in on that region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66126d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(\n",
    "    data=effective_speed_stats[\n",
    "        (83 < effective_speed_stats['effective_speed']) &\n",
    "        (effective_speed_stats['effective_speed'] < 96)],\n",
    "    x='effective_speed',\n",
    "    y='correct_call_percent')\n",
    "plt.plot([84.8, 84.8], [0.905, 0.93], color='red', linewidth=2)\n",
    "plt.plot([90.3, 90.3], [0.905, 0.93], color='black', linewidth=2)\n",
    "plt.plot([94.2, 94.2], [0.905, 0.93], color='red', linewidth=2)\n",
    "plt.text(85.0, 0.9285, '25%', color='red', fontsize='x-large')\n",
    "plt.text(90.5, 0.9285, '50%', color='black', fontsize='x-large')\n",
    "plt.text(94.4, 0.9285, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([83.5, 95.5], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(86.1, 0.9155, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ec746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For summary statistics, run the following:\n",
    "# all_features_df.effective_speed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb223c19",
   "metadata": {},
   "source": [
    "<a id='3.1.3.2'></a>\n",
    "#### 3.1.3.2 - `release_pos_x` (RHP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ef5335",
   "metadata": {},
   "source": [
    "We split our data into buckets with a constant width of 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf0f0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_pos_x_rhp_percents = []\n",
    "release_pos_x_rhp_index = []\n",
    "\n",
    "for index in range(-49,0):\n",
    "    temp_list = all_features_df[\n",
    "        (index*0.1 <= all_features_df['release_pos_x']) &\n",
    "        (all_features_df['release_pos_x'] < (index*0.1)+0.1)].correct_call.value_counts(normalize=True).to_list()\n",
    "    release_pos_x_rhp_percents.append(temp_list[0])\n",
    "    release_pos_x_rhp_index.append(index*0.1+0.05)\n",
    "    \n",
    "release_pos_x_rhp_stats = pd.DataFrame({\n",
    "    'release_pos_x_rhp':release_pos_x_rhp_index,\n",
    "    'correct_call_percent':release_pos_x_rhp_percents\n",
    "    })\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=release_pos_x_rhp_stats, x='release_pos_x_rhp', y='correct_call_percent')\n",
    "plt.plot([-2.33, -2.33], [0.855, 1], color='red', linewidth=2)\n",
    "plt.plot([-1.86, -1.86], [0.855, 1], color='black', linewidth=2)\n",
    "plt.plot([-1.40, -1.40], [0.855, 1], color='red', linewidth=2)\n",
    "plt.text(-2.6, 0.993, '25%', color='red', fontsize='x-large')\n",
    "plt.text(-1.83, 0.993, '50%', color='black', fontsize='x-large')\n",
    "plt.text(-1.37, 0.993, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([-4.95, -0.05], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(-4.7, 0.922, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8c17b4",
   "metadata": {},
   "source": [
    "Note that 50% of all pitches (from right-handed pitchers) occur with a horizontal release position between -2.33 and -1.40, so we zoom in on that region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9382b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=release_pos_x_rhp_stats[\n",
    "    (-3 < release_pos_x_rhp_stats['release_pos_x_rhp']) &\n",
    "    (release_pos_x_rhp_stats['release_pos_x_rhp'] < -1)\n",
    "    ],\n",
    "    x='release_pos_x_rhp',\n",
    "    y='correct_call_percent')\n",
    "plt.plot([-2.33, -2.33], [0.9125, 0.9222], color='red', linewidth=2)\n",
    "plt.plot([-1.86, -1.86], [0.9125, 0.9222], color='black', linewidth=2)\n",
    "plt.plot([-1.40, -1.40], [0.9125, 0.9222], color='red', linewidth=2)\n",
    "plt.text(-2.43, 0.9215, '25%', color='red', fontsize='x-large')\n",
    "plt.text(-1.96, 0.9215, '50%', color='black', fontsize='x-large')\n",
    "plt.text(-1.38, 0.9215, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([-2.95, -1.1], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(-1.8, 0.9167, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30489b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For summary statistics, run the following:\n",
    "# all_features_df[all_features_df['release_pos_x'] < 0].release_pos_x.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79d676d",
   "metadata": {},
   "source": [
    "<a id='3.1.3.3'></a>\n",
    "#### 3.1.3.3 - `release_pos_x` (LHP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b8ae47",
   "metadata": {},
   "source": [
    "We split our data into buckets with a constant width of 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cfd622",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_pos_x_lhp_percents = []\n",
    "release_pos_x_lhp_index = []\n",
    "\n",
    "for index in range(0,48):\n",
    "    temp_list = all_features_df[\n",
    "        (index*0.1 <= all_features_df['release_pos_x']) &\n",
    "        (all_features_df['release_pos_x'] < (index*0.1)+0.1)].correct_call.value_counts(normalize=True).to_list()\n",
    "    release_pos_x_lhp_percents.append(temp_list[0])\n",
    "    release_pos_x_lhp_index.append(index*0.1+0.05)\n",
    "    \n",
    "release_pos_x_lhp_stats = pd.DataFrame({\n",
    "    'release_pos_x_lhp':release_pos_x_lhp_index,\n",
    "    'correct_call_percent':release_pos_x_lhp_percents\n",
    "    })\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=release_pos_x_lhp_stats, x='release_pos_x_lhp', y='correct_call_percent')\n",
    "plt.plot([1.42, 1.42], [0.825, 1], color='red', linewidth=2)\n",
    "plt.plot([1.90, 1.90], [0.825, 1], color='black', linewidth=2)\n",
    "plt.plot([2.43, 2.43], [0.825, 1], color='red', linewidth=2)\n",
    "plt.text(1.18, 0.99, '25%', color='red', fontsize='x-large')\n",
    "plt.text(1.65, 0.99, '50%', color='black', fontsize='x-large')\n",
    "plt.text(2.47, 0.99, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([0.05, 4.8], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(0.5, 0.903, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76abb984",
   "metadata": {},
   "source": [
    "Note that 50% of all pitches (from left-handed pitchers) occur with a horizontal release position between 1.42 and 2.43, so we zoom in on that region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb92e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=release_pos_x_lhp_stats[\n",
    "    (0.8 < release_pos_x_lhp_stats['release_pos_x_lhp']) &\n",
    "    (release_pos_x_lhp_stats['release_pos_x_lhp'] < 3)\n",
    "    ],\n",
    "    x='release_pos_x_lhp',\n",
    "    y='correct_call_percent')\n",
    "plt.plot([1.42, 1.42], [0.905, 0.93], color='red', linewidth=2)\n",
    "plt.plot([1.90, 1.90], [0.905, 0.93], color='black', linewidth=2)\n",
    "plt.plot([2.43, 2.43], [0.905, 0.93], color='red', linewidth=2)\n",
    "plt.text(1.29, 0.9285, '25%', color='red', fontsize='x-large')\n",
    "plt.text(1.78, 0.9285, '50%', color='black', fontsize='x-large')\n",
    "plt.text(2.3, 0.9285, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([0.85, 2.95], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(1.515, 0.918, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7219673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For summary statistics, run the following:\n",
    "# all_features_df[all_features_df['release_pos_x'] >= 0].release_pos_x.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c986cc",
   "metadata": {},
   "source": [
    "<a id='3.1.3.4'></a>\n",
    "#### 3.1.3.4 - `release_pos_y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a9cd4",
   "metadata": {},
   "source": [
    "We split our data into buckets with a constant width of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3845f1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_pos_y_percents = []\n",
    "release_pos_y_index = []\n",
    "\n",
    "for index in range(500,575):\n",
    "    temp_list = all_features_df[\n",
    "        (index*0.1 <= all_features_df['release_pos_y']) &\n",
    "        (all_features_df['release_pos_y'] < (index*0.1)+0.1)\n",
    "        ].correct_call.value_counts(normalize=True).to_list()\n",
    "    if temp_list != []:\n",
    "        release_pos_y_percents.append(temp_list[0])\n",
    "        release_pos_y_index.append(index*0.1+0.05)\n",
    "    \n",
    "release_pos_y_stats = pd.DataFrame({\n",
    "    'release_pos_y':release_pos_y_index,\n",
    "    'correct_call_percent':release_pos_y_percents\n",
    "    })\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=release_pos_y_stats, x='release_pos_y', y='correct_call_percent')\n",
    "plt.plot([53.76, 53.76], [0.65, 1], color='red', linewidth=2)\n",
    "plt.plot([54.06, 54.06], [0.65, 1], color='black', linewidth=2)\n",
    "plt.plot([54.37, 54.37], [0.65, 1], color='red', linewidth=2)\n",
    "plt.text(53.33, 0.98, '25%', color='red', fontsize='x-large')\n",
    "plt.text(54.08, 1.01, '50%', color='black', fontsize='x-large')\n",
    "plt.text(54.44, 0.98, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([50.75, 57.5], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(56.05, 0.922, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1122a8f5",
   "metadata": {},
   "source": [
    "Note that 50% of all pitches occur with a vertical release position between 53.76 and 54.37, so we zoom in on that region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad4786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=release_pos_y_stats[\n",
    "    (53.2 < release_pos_y_stats['release_pos_y']) &\n",
    "    (release_pos_y_stats['release_pos_y'] < 55)\n",
    "    ],\n",
    "    x='release_pos_y',\n",
    "    y='correct_call_percent')\n",
    "plt.plot([53.76, 53.76], [0.9135, 0.9225], color='red', linewidth=2)\n",
    "plt.plot([54.06, 54.06], [0.9135, 0.9225], color='black', linewidth=2)\n",
    "plt.plot([54.37, 54.37], [0.9135, 0.9225], color='red', linewidth=2)\n",
    "plt.text(53.66, 0.9215, '25%', color='red', fontsize='x-large')\n",
    "plt.text(54.08, 0.9215, '50%', color='black', fontsize='x-large')\n",
    "plt.text(54.28, 0.9215, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([53.25, 54.95], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(54.51, 0.9167, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cffa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For summary statistics, run the following:\n",
    "# all_features_df.release_pos_y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24afdbc",
   "metadata": {},
   "source": [
    "<a id='3.1.3.5'></a>\n",
    "#### 3.1.3.5 - `release_spin_rate`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb2b667",
   "metadata": {},
   "source": [
    "We split our data into buckets with a constant width of 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98fd56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_spin_rate_percents = []\n",
    "release_spin_rate_index = []\n",
    "\n",
    "for index in range(16,3531,50):\n",
    "    temp_list = all_features_df[\n",
    "        (index <= all_features_df['release_spin_rate']) &\n",
    "        (all_features_df['release_spin_rate'] < index+50)\n",
    "        ].correct_call.value_counts(normalize=True).to_list()\n",
    "    if temp_list != []:\n",
    "        release_spin_rate_percents.append(temp_list[0])\n",
    "        release_spin_rate_index.append(index+25)\n",
    "    \n",
    "release_spin_rate_stats = pd.DataFrame({\n",
    "    'release_spin_rate':release_spin_rate_index,\n",
    "    'correct_call_percent':release_spin_rate_percents\n",
    "    })\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=release_spin_rate_stats, x='release_spin_rate', y='correct_call_percent')\n",
    "plt.plot([2102, 2102], [0.5, 1], color='red', linewidth=2)\n",
    "plt.plot([2274, 2274], [0.5, 1], color='black', linewidth=2)\n",
    "plt.plot([2444, 2444], [0.5, 1], color='red', linewidth=2)\n",
    "plt.text(1930, 0.98, '25%', color='red', fontsize='x-large')\n",
    "plt.text(2274, 1.005, '50%', color='black', fontsize='x-large')\n",
    "plt.text(2470, 0.98, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([15, 3550], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(1050, 0.88, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abccdf0",
   "metadata": {},
   "source": [
    "Note that 50% of all pitches occur with a release spin rate between 2102 and 2444, so we zoom in on that region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a8af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=release_spin_rate_stats[\n",
    "    (1850 < release_spin_rate_stats['release_spin_rate']) &\n",
    "    (release_spin_rate_stats['release_spin_rate'] < 2650)\n",
    "    ],\n",
    "    x='release_spin_rate',\n",
    "    y='correct_call_percent')\n",
    "plt.plot([2102, 2102], [0.909, 0.924], color='red', linewidth=2)\n",
    "plt.plot([2274, 2274], [0.909, 0.924], color='black', linewidth=2)\n",
    "plt.plot([2444, 2444], [0.909, 0.924], color='red', linewidth=2)\n",
    "plt.text(2060, 0.923, '25%', color='red', fontsize='x-large')\n",
    "plt.text(2235, 0.923, '50%', color='black', fontsize='x-large')\n",
    "plt.text(2450, 0.923, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([1890, 2640], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(2505, 0.91625, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e5efdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For summary statistics, run the following:\n",
    "# all_features_df.release_spin_rate.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47f8abe",
   "metadata": {},
   "source": [
    "<a id='3.1.4'></a>\n",
    "### 3.1.4 - Plate Appearance\n",
    "\n",
    "<a id='3.1.4.1'></a>\n",
    "#### 3.1.4.1 - `pitch_number`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b23154",
   "metadata": {},
   "source": [
    "We note that 99.9% of all pitches in this data frame occur as a 9th pitch in an at-bat or earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789584c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_number_percents = []\n",
    "pitch_number_index = []\n",
    "\n",
    "for index in range(1,15):\n",
    "    temp_list = all_features_df[all_features_df['pitch_number']==index].correct_call.value_counts(normalize=True).to_list()\n",
    "    pitch_number_percents.append(temp_list[0])\n",
    "    pitch_number_index.append(index)\n",
    "    \n",
    "pitch_number_stats = pd.DataFrame({'pitch_number':pitch_number_index, 'correct_call_percent':pitch_number_percents})\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.lineplot(data=pitch_number_stats, x='pitch_number', y='correct_call_percent').set_xticks(range(1,15))\n",
    "plt.plot([9, 9], [0.82, 0.96], color='red', linewidth=2)\n",
    "plt.text(8.05, 0.955, '99.9%', color='red', fontsize='x-large')\n",
    "plt.plot([1, 14], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(3.1, 0.9125, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73c9ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.lineplot(data=pitch_number_stats[\n",
    "    pitch_number_stats['pitch_number'] <= 9\n",
    "    ],\n",
    "    x='pitch_number',\n",
    "    y='correct_call_percent'\n",
    "    ).set_xticks(range(1,15))\n",
    "plt.plot([9, 9], [0.9, 0.935], color='red', linewidth=2)\n",
    "plt.text(8.4, 0.931, '99.9%', color='red', fontsize='x-large')\n",
    "plt.plot([1, 9], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(4.05, 0.918, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8771a99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code produces a visualization of number of pitches with given pitch number\n",
    "\n",
    "#pitch_number_count = []\n",
    "# uses pitch_number_index from previous cell\n",
    "\n",
    "#for index in range(1,15):\n",
    "#    pitch_number_count.append(all_features_df[all_features_df['pitch_number']==index].correct_call.count())\n",
    "\n",
    "#pitch_number_count_stats = pd.DataFrame({\n",
    "#    'pitch_number':pitch_number_index,\n",
    "#    'occurrences':pitch_number_count\n",
    "#    })\n",
    "\n",
    "#up_to_9_pitch_number = all_features_df[all_features_df['pitch_number'] <= 9].correct_call.count()\n",
    "#over_9_pitch_number = all_features_df[all_features_df['pitch_number'] > 9].correct_call.count()\n",
    "\n",
    "#percent_9_pitch_percent = up_to_9_pitch_number / (up_to_9_pitch_number + over_9_pitch_number)\n",
    "\n",
    "#plt.figure(figsize=(12,6))\n",
    "#sns.lineplot(data=pitch_number_count_stats, x='pitch_number', y='occurrences').set_xticks(range(1,15))\n",
    "#plt.plot([9, 9], [0, 125000], color='red', linewidth=2)\n",
    "#plt.text(7.9, 121000, str(round(percent_9_pitch_percent, 3))+'%', color='red', fontsize='x-large')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b27f85",
   "metadata": {},
   "source": [
    "<a id='3.1.4.2'></a>\n",
    "#### 3.1.4.2 - Count (`balls` and `strikes`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057334e2",
   "metadata": {},
   "source": [
    "Instead of investigating `balls` and `strikes` independently, we instead combine them into the count for that pitch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b4508",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_percents = []\n",
    "balls_index = []\n",
    "strikes_index = []\n",
    "\n",
    "for ball_index in range(0,4):\n",
    "    for strike_index in range(0,3):\n",
    "        temp_list = all_features_df[(all_features_df['balls'] == ball_index)\n",
    "                                   & (all_features_df['strikes'] == strike_index)\n",
    "                                   ].correct_call.value_counts(normalize=True).to_list()\n",
    "        count_percents.append(round(temp_list[0],4))\n",
    "        balls_index.append(str(ball_index))\n",
    "        strikes_index.append(str(strike_index))\n",
    "    \n",
    "count_stats = pd.DataFrame({'balls':balls_index, 'strikes':strikes_index, 'correct_call_percent':count_percents})\n",
    "\n",
    "count_stats['strikes'] = pd.Categorical(count_stats['strikes'], ['2', '1', '0'])\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "ax = sns.histplot(data=count_stats, x='balls', y='strikes', hue='correct_call_percent',\n",
    "                  palette=sns.light_palette('seagreen', as_cmap=True))\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e540eae",
   "metadata": {},
   "source": [
    "We also provide a visualization for how often a given count occurs. Understandably, the most common count by far is 0-0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ddfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_pas = []\n",
    "balls_index = []\n",
    "strikes_index = []\n",
    "\n",
    "for ball_index in range(0,4):\n",
    "    for strike_index in range(0,3):\n",
    "        count_pas.append(all_features_df[(all_features_df['balls'] == ball_index)\n",
    "                                   & (all_features_df['strikes'] == strike_index)\n",
    "                                   ].correct_call.count())\n",
    "        balls_index.append(str(ball_index))\n",
    "        strikes_index.append(str(strike_index))\n",
    "\n",
    "count_pa_stats = pd.DataFrame({'balls':balls_index, 'strikes':strikes_index, 'plate_apps':count_pas})\n",
    "\n",
    "count_pa_stats['strikes'] = pd.Categorical(count_stats['strikes'], ['2', '1', '0'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "ax = sns.histplot(data=count_pa_stats, x='balls', y='strikes', hue='plate_apps',\n",
    "                  palette=sns.light_palette('seagreen', as_cmap=True))\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4b2ff5",
   "metadata": {},
   "source": [
    "<a id='3.1.5'></a>\n",
    "### 3.1.5 - Game State\n",
    "\n",
    "<a id='3.1.5.1'></a>\n",
    "#### 3.1.5.1 - Place in Game - `inning` and `outs_when_up`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f0efff",
   "metadata": {},
   "source": [
    "We begin by examining pitches by `inning` and `outs_when_up` independently and then jointly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8a6913",
   "metadata": {},
   "outputs": [],
   "source": [
    "inning_percents = []\n",
    "inning_index = []\n",
    "\n",
    "for index in range(1,10):\n",
    "    temp_list = all_features_df[all_features_df['inning']==index].correct_call.value_counts(normalize=True).to_list()\n",
    "    inning_percents.append(temp_list[0])\n",
    "    inning_index.append(index)\n",
    "\n",
    "inning_stats = pd.DataFrame({'inning':inning_index, 'correct_call_percent':inning_percents})\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.lineplot(data=inning_stats, x='inning', y='correct_call_percent')\n",
    "plt.plot([1, 9], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(7.35, 0.9173, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ceff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_when_up_percents = []\n",
    "outs_when_up_index = []\n",
    "\n",
    "for index in range(0,3):\n",
    "    temp_list = all_features_df[all_features_df['outs_when_up']==index].correct_call.value_counts(normalize=True).to_list()\n",
    "    outs_when_up_percents.append(temp_list[0])\n",
    "    outs_when_up_index.append(index)\n",
    "\n",
    "outs_when_up_stats = pd.DataFrame({'outs_when_up':outs_when_up_index, 'correct_call_percent':outs_when_up_percents})\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.lineplot(data=outs_when_up_stats, x='outs_when_up', y='correct_call_percent').set_xticks(range(3))\n",
    "plt.plot([0, 2], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(0.1, 0.91707, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412591a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that inning_index and outs_when_up_index replace lists from above two cells, but create the same list\n",
    "# additionally, lists are not needed outside of any individual cell\n",
    "\n",
    "game_state_percents = []\n",
    "inning_index = []\n",
    "outs_when_up_index = []\n",
    "\n",
    "for inning_counter in range(1,10):\n",
    "    for outs_when_up_counter in range(0,3):\n",
    "        temp_list = all_features_df[\n",
    "            (all_features_df['inning'] == inning_counter) &\n",
    "            (all_features_df['outs_when_up'] == outs_when_up_counter)\n",
    "            ].correct_call.value_counts(normalize=True).to_list()\n",
    "        game_state_percents.append(round(temp_list[0],4))\n",
    "        inning_index.append(str(inning_counter))\n",
    "        outs_when_up_index.append(str(outs_when_up_counter))\n",
    "    \n",
    "game_state_stats = pd.DataFrame({\n",
    "    'inning':inning_index,\n",
    "    'outs_when_up':outs_when_up_index,\n",
    "    'correct_call_percent':game_state_percents\n",
    "    })\n",
    "\n",
    "#game_state_stats['outs_when_up'] = pd.Categorical(count_stats['outs_when_up'], ['2', '1', '0'])\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "ax = sns.histplot(\n",
    "    data=game_state_stats,\n",
    "    x='inning',\n",
    "    y='outs_when_up',\n",
    "    hue='correct_call_percent',\n",
    "    palette=sns.light_palette('seagreen', as_cmap=True)\n",
    "    )\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb11c3b",
   "metadata": {},
   "source": [
    "<a id='3.1.5.2'></a>\n",
    "#### 3.1.5.2 - `at_bat_number`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44508d76",
   "metadata": {},
   "source": [
    "Note that 99.8% of pitches occur within the first 90 plate appearances of a game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7963b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "at_bat_number_percents = []\n",
    "at_bat_number_index = []\n",
    "\n",
    "for index in range(1,113):\n",
    "    temp_list = all_features_df[all_features_df['at_bat_number']==index].correct_call.value_counts(normalize=True).to_list()\n",
    "    at_bat_number_percents.append(temp_list[0])\n",
    "    at_bat_number_index.append(index)\n",
    "\n",
    "at_bat_number_stats = pd.DataFrame({'at_bat_number':at_bat_number_index, 'correct_call_percent':at_bat_number_percents})\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=at_bat_number_stats, x='at_bat_number', y='correct_call_percent').set_xticks(range(0,120,10))\n",
    "plt.plot([90, 90], [0.5, 1], color='red', linewidth=2)\n",
    "plt.text(82, 0.97, '99.8%', color='red', fontsize='x-large')\n",
    "plt.plot([1, 112], [0.9172, 0.9172], color='purple', linewidth=0.8)\n",
    "plt.text(1, 0.87, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7fa559",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=at_bat_number_stats[at_bat_number_stats['at_bat_number'] < 91],\n",
    "             x='at_bat_number',\n",
    "             y='correct_call_percent').set_xticks(range(0,120,10))\n",
    "plt.plot([90, 90], [0.885, 0.94], color='red', linewidth=2)\n",
    "plt.text(91.1, 0.935, '99.8%', color='red', fontsize='x-large')\n",
    "plt.plot([1, 93], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(1, 0.9115, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa8c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#at_bat_number_count = []\n",
    "## uses at_bat_number_index from previous cell\n",
    "\n",
    "#for index in range(1,113):\n",
    "#    at_bat_number_count.append(all_features_df[all_features_df['at_bat_number']==index].correct_call.count())\n",
    "\n",
    "#at_bat_number_count_stats = pd.DataFrame({\n",
    "#    'at_bat_number':at_bat_number_index,\n",
    "#    'occurrences':at_bat_number_count\n",
    "#    })\n",
    "\n",
    "#up_to_90_at_bats = all_features_df[all_features_df['at_bat_number'] <= 90].correct_call.count()\n",
    "#over_90_at_bats = all_features_df[all_features_df['at_bat_number'] > 90].correct_call.count()\n",
    "\n",
    "#percent_90_at_bats = up_to_90_at_bats / (up_to_90_at_bats + over_90_at_bats)\n",
    "\n",
    "#plt.figure(figsize=(12,6))\n",
    "#sns.lineplot(data=at_bat_number_count_stats, x='at_bat_number', y='occurrences').set_xticks(range(0,120,10))\n",
    "#plt.plot([90, 90], [0, 5000], color='red', linewidth=2)\n",
    "#plt.text(80.5, 4700, str(round(percent_90_at_bats, 3))+'%', color='red', fontsize='x-large')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28957ab1",
   "metadata": {},
   "source": [
    "<a id='3.1.5.3'></a>\n",
    "#### 3.1.5.3 - Score Difference (`home_score` - `away_score`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39d63d8",
   "metadata": {},
   "source": [
    "Instead of considering each team's score individually, we instead consider the relative game score by looking at `home_score`-`away_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fceb17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_difference_percents1 = []\n",
    "score_difference_index1 = []\n",
    "\n",
    "score_difference_percents2 = []\n",
    "score_difference_index2 = []\n",
    "\n",
    "score_difference_percents3 = []\n",
    "score_difference_index3 = []\n",
    "\n",
    "for index in range(-25,-22):\n",
    "    temp_list = all_features_df[\n",
    "        all_features_df['home_score']-all_features_df['away_score'] == index\n",
    "        ].correct_call.value_counts(normalize=True).to_list()\n",
    "    score_difference_percents1.append(temp_list[0])\n",
    "    score_difference_index1.append(index)\n",
    "\n",
    "for index in range(-20,15):\n",
    "    temp_list = all_features_df[\n",
    "        all_features_df['home_score']-all_features_df['away_score'] == index\n",
    "        ].correct_call.value_counts(normalize=True).to_list()\n",
    "    score_difference_percents2.append(temp_list[0])\n",
    "    score_difference_index2.append(index)\n",
    "\n",
    "\n",
    "for index in range(17,18):\n",
    "    temp_list = all_features_df[\n",
    "        all_features_df['home_score']-all_features_df['away_score'] == index\n",
    "        ].correct_call.value_counts(normalize=True).to_list()\n",
    "    score_difference_percents3.append(temp_list[0])\n",
    "    score_difference_index3.append(index)\n",
    "    \n",
    "score_difference_stats1 = pd.DataFrame({\n",
    "    'score_difference':score_difference_index1,\n",
    "    'correct_call_percent':score_difference_percents1\n",
    "    })\n",
    "\n",
    "score_difference_stats2 = pd.DataFrame({\n",
    "    'score_difference':score_difference_index2,\n",
    "    'correct_call_percent':score_difference_percents2\n",
    "    })\n",
    "\n",
    "score_difference_stats3 = pd.DataFrame({\n",
    "    'score_difference':score_difference_index3,\n",
    "    'correct_call_percent':score_difference_percents3\n",
    "    })\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=score_difference_stats1, x='score_difference', y='correct_call_percent').set_xticks((range(-30,25,5)))\n",
    "sns.lineplot(data=score_difference_stats2, x='score_difference', y='correct_call_percent')\n",
    "sns.scatterplot(data=score_difference_stats3, x='score_difference', y='correct_call_percent')\n",
    "plt.plot([-25, 17], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(-9, 0.935, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc622a9",
   "metadata": {},
   "source": [
    "We now look at how many pitches occur with a given score difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f0cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_difference_counts_index = []\n",
    "score_difference_counts_pitches = []\n",
    "\n",
    "for index in range(-25,18):\n",
    "    score_difference_counts_pitches.append(all_features_df[\n",
    "        all_features_df['home_score']-all_features_df['away_score'] == index\n",
    "        ].binary_bs.count()\n",
    "        )\n",
    "    score_difference_counts_index.append(index)\n",
    "    \n",
    "score_difference_counts_stats = pd.DataFrame({\n",
    "    'score_difference':score_difference_counts_index,\n",
    "    'pitches':score_difference_counts_pitches\n",
    "    })\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=score_difference_counts_stats, x='score_difference', y='pitches').set_xticks((range(-30,25,5)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f455e78",
   "metadata": {},
   "source": [
    "Consequently, we focus on pitches with a score difference between -5 and 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0802b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(\n",
    "    data=score_difference_stats2[\n",
    "        (-6 < score_difference_stats2['score_difference']) &\n",
    "        (score_difference_stats2['score_difference'] < 6)\n",
    "    ],\n",
    "    x='score_difference',\n",
    "    y='correct_call_percent'\n",
    "    ).set_xticks((range(-5,6,1)))\n",
    "plt.plot([-5, 5], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(-1.9, 0.9167, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b778f94",
   "metadata": {},
   "source": [
    "<a id='3.1.6'></a>\n",
    "### 3.1.6 - Movement\n",
    "\n",
    "<a id='3.1.6.1'></a>\n",
    "#### 3.1.6.1 - `pfx_x`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230ddea1",
   "metadata": {},
   "source": [
    "We split our data into buckets with a constant width of 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b13bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfx_x_percents = []\n",
    "pfx_x_index = []\n",
    "\n",
    "for index in range(-240,237,10):\n",
    "    temp_list = all_features_df[\n",
    "        (index*0.01 <= all_features_df['pfx_x']) &\n",
    "        (all_features_df['pfx_x'] < (index*0.01)+0.1)\n",
    "        ].correct_call.value_counts(normalize=True).to_list()\n",
    "    if temp_list != []:\n",
    "        pfx_x_percents.append(temp_list[0])\n",
    "        pfx_x_index.append(index*0.01+0.05)\n",
    "\n",
    "pfx_x_stats = pd.DataFrame({'pfx_x':pfx_x_index, 'correct_call_percent':pfx_x_percents})\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=pfx_x_stats, x='pfx_x', y='correct_call_percent')\n",
    "plt.plot([-0.89, -0.89], [0.8, 1], color='red', linewidth=2)\n",
    "plt.plot([-0.19, -0.19], [0.8, 1], color='black', linewidth=2)\n",
    "plt.plot([0.59, 0.59], [0.8, 1], color='red', linewidth=2)\n",
    "plt.text(-0.85, 0.99, '25%', color='red', fontsize='x-large')\n",
    "plt.text(-0.43, 0.99, '50%', color='black', fontsize='x-large')\n",
    "plt.text(0.35, 0.99, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([-2.4, 2.4], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(-1.9, 0.89, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05aadfb",
   "metadata": {},
   "source": [
    "Note that 50% of all pitches occur with a horizontal movement between -0.89 and 0.59, so we zoom in on that region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e50703",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=pfx_x_stats[\n",
    "    (-1.7 < pfx_x_stats['pfx_x']) &\n",
    "    (pfx_x_stats['pfx_x'] < 1.5)\n",
    "    ],\n",
    "    x='pfx_x',\n",
    "    y='correct_call_percent'\n",
    "    )\n",
    "plt.plot([-0.89, -0.89], [0.905, 0.925], color='red', linewidth=2)\n",
    "plt.plot([-0.19, -0.19], [0.905, 0.925], color='black', linewidth=2)\n",
    "plt.plot([0.59, 0.59], [0.905, 0.925], color='red', linewidth=2)\n",
    "plt.text(-0.85, 0.9238, '25%', color='red', fontsize='x-large')\n",
    "plt.text(-0.35, 0.9238, '50%', color='black', fontsize='x-large')\n",
    "plt.text(0.625, 0.9238, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([-1.65, 1.45], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(-0.8, 0.914, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdb2ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For summary statistics, run the following:\n",
    "# all_features_df.pfx_x.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41effe10",
   "metadata": {},
   "source": [
    "<a id='3.1.6.2'></a>\n",
    "#### 3.1.6.2 - `pfx_z`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336455b7",
   "metadata": {},
   "source": [
    "We split our data into buckets with a constant width of 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ecd3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfx_z_percents = []\n",
    "pfx_z_index = []\n",
    "\n",
    "for index in range(-220,284,10):\n",
    "    temp_list = all_features_df[\n",
    "        (index*0.01 <= all_features_df['pfx_z']) &\n",
    "        (all_features_df['pfx_z'] < (index*0.01)+0.1)\n",
    "        ].correct_call.value_counts(normalize=True).to_list()\n",
    "    if temp_list != []:\n",
    "        pfx_z_percents.append(temp_list[0])\n",
    "        pfx_z_index.append(index*0.01+0.05)\n",
    "\n",
    "pfx_z_stats = pd.DataFrame({'pfx_z':pfx_z_index, 'correct_call_percent':pfx_z_percents})\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=pfx_z_stats, x='pfx_z', y='correct_call_percent')\n",
    "plt.plot([0.15, 0.15], [0.8, 1], color='red', linewidth=2)\n",
    "plt.plot([0.66, 0.66], [0.8, 1], color='black', linewidth=2)\n",
    "plt.plot([1.21, 1.21], [0.8, 1], color='red', linewidth=2)\n",
    "plt.text(0.2, 0.99, '25%', color='red', fontsize='x-large')\n",
    "plt.text(0.71, 0.99, '50%', color='black', fontsize='x-large')\n",
    "plt.text(1.25, 0.99, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([-2.15, 2.85], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(-0.9, 0.905, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecf36e2",
   "metadata": {},
   "source": [
    "Note that 50% of all pitches occur with a vertical movement between 0.15 and 1.21, so we zoom in on that region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46f6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=pfx_z_stats[\n",
    "    (-0.6 < pfx_z_stats['pfx_z']) &\n",
    "    (pfx_z_stats['pfx_z'] < 2.1)\n",
    "    ],\n",
    "    x='pfx_z',\n",
    "    y='correct_call_percent'\n",
    "    )\n",
    "plt.plot([0.15, 0.15], [0.87, 0.93], color='red', linewidth=2)\n",
    "plt.plot([0.66, 0.66], [0.87, 0.93], color='black', linewidth=2)\n",
    "plt.plot([1.21, 1.21], [0.87, 0.93], color='red', linewidth=2)\n",
    "plt.text(0.2, 0.927, '25%', color='red', fontsize='x-large')\n",
    "plt.text(0.71, 0.927, '50%', color='black', fontsize='x-large')\n",
    "plt.text(1.25, 0.927, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([-0.55, 2.05], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(-0.47, 0.913, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b1b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For summary statistics, run the following:\n",
    "# all_features_df.pfx_z.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35268d73",
   "metadata": {},
   "source": [
    "<a id='3.1.7'></a>\n",
    "### 3.1.7- Velocity\n",
    "\n",
    "<a id='3.1.'></a>\n",
    "#### 3.1.7.1 - `vx0`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88401b4d",
   "metadata": {},
   "source": [
    "We split our data into buckets with a constant width of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6108d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vx0_percents = []\n",
    "vx0_index = []\n",
    "\n",
    "for index in range(-210,215,10):\n",
    "    temp_list = all_features_df[\n",
    "        (index*0.1 <= all_features_df['vx0']) &\n",
    "        (all_features_df['vx0'] < (index*0.1)+1)\n",
    "        ].correct_call.value_counts(normalize=True).to_list()\n",
    "    if temp_list != []:\n",
    "        vx0_percents.append(temp_list[0])\n",
    "        vx0_index.append(index*0.1+0.5)\n",
    "\n",
    "vx0_stats = pd.DataFrame({'vx0':vx0_index, 'correct_call_percent':vx0_percents})\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=vx0_stats, x='vx0', y='correct_call_percent')\n",
    "plt.plot([-1.28, -1.28], [0.88, 1], color='red', linewidth=2)\n",
    "plt.plot([3.98, 3.98], [0.88, 1], color='black', linewidth=2)\n",
    "plt.plot([6.85, 6.85], [0.88, 1], color='red', linewidth=2)\n",
    "plt.text(-3.5, 0.99, '25%', color='red', fontsize='x-large')\n",
    "plt.text(4.3, 0.99, '50%', color='black', fontsize='x-large')\n",
    "plt.text(7.3, 0.99, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([-20.5, 21.5], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(-9, 0.905, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e646f61e",
   "metadata": {},
   "source": [
    "Note that 50% of all pitches occur with a horizontal velocity between -1.28 and 6.85, so we zoom in on that region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484a875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=vx0_stats[\n",
    "    (-7 < vx0_stats['vx0']) &\n",
    "    (vx0_stats['vx0'] < 12)\n",
    "    ],\n",
    "    x='vx0',\n",
    "    y='correct_call_percent'\n",
    "    )\n",
    "plt.plot([-1.28, -1.28], [0.91, 0.9275], color='red', linewidth=2)\n",
    "plt.plot([3.98, 3.98], [0.91, 0.9275], color='black', linewidth=2)\n",
    "plt.plot([6.85, 6.85], [0.91, 0.9275], color='red', linewidth=2)\n",
    "plt.text(-2.25, 0.9265, '25%', color='red', fontsize='x-large')\n",
    "plt.text(2.95, 0.9265, '50%', color='black', fontsize='x-large')\n",
    "plt.text(5.9, 0.9265, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([-6.5, 11.5], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(-6.3, 0.9178, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82037921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For summary statistics, run the following:\n",
    "# all_features_df.vx0.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f1a26b",
   "metadata": {},
   "source": [
    "<a id='3.1.7.2'></a>\n",
    "#### 3.1.7.2 - `vy0`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f633e2c",
   "metadata": {},
   "source": [
    "We split our data into buckets with a constant width of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beba7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vy0_percents = []\n",
    "vy0_index = []\n",
    "\n",
    "for index in range(-152,-44,1):\n",
    "    temp_list = all_features_df[\n",
    "        (index <= all_features_df['vy0']) &\n",
    "        (all_features_df['vy0'] < index+1)\n",
    "        ].correct_call.value_counts(normalize=True).to_list()\n",
    "    if temp_list != []:\n",
    "        vy0_percents.append(temp_list[0])\n",
    "        vy0_index.append(index+2.5)\n",
    "\n",
    "vy0_stats = pd.DataFrame({'vy0':vy0_index, 'correct_call_percent':vy0_percents})\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=vy0_stats, x='vy0', y='correct_call_percent')\n",
    "plt.plot([-136.6, -136.6], [0.56, 1], color='red', linewidth=2)\n",
    "plt.plot([-131, -131], [0.56, 1], color='black', linewidth=2)\n",
    "plt.plot([-123.1, -123.1], [0.56, 1], color='red', linewidth=2)\n",
    "plt.text(-136.2, 0.98, '25%', color='red', fontsize='x-large')\n",
    "plt.text(-130.2, 0.98, '50%', color='black', fontsize='x-large')\n",
    "plt.text(-122.4, 0.98, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([-149.5, -45], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(-119, 0.87, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb688a",
   "metadata": {},
   "source": [
    "Note that 50% of all pitches occur with a depth velocity between -136.6 and -123.1, so we zoom in on that region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa73791",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=vy0_stats[\n",
    "    (-148 < vy0_stats['vy0']) &\n",
    "    (vy0_stats['vy0'] < -116)\n",
    "    ],\n",
    "    x='vy0',\n",
    "    y='correct_call_percent'\n",
    "    )\n",
    "plt.plot([-136.6, -136.6], [0.89, 0.93], color='red', linewidth=2)\n",
    "plt.plot([-131, -131], [0.89, 0.93], color='black', linewidth=2)\n",
    "plt.plot([-123.1, -123.1], [0.89, 0.93], color='red', linewidth=2)\n",
    "plt.text(-138.3, 0.9275, '25%', color='red', fontsize='x-large')\n",
    "plt.text(-132.6, 0.9275, '50%', color='black', fontsize='x-large')\n",
    "plt.text(-124.7, 0.9275, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([-145, -119.5], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(-136.45, 0.918, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69136681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For summary statistics, run the following:\n",
    "# all_features_df.vy0.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f616354c",
   "metadata": {},
   "source": [
    "<a id='3.1.7.3'></a>\n",
    "#### 3.1.7.3 - `vz0`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3666d505",
   "metadata": {},
   "source": [
    "We split our data into buckets with a constant width of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c489746",
   "metadata": {},
   "outputs": [],
   "source": [
    "vz0_percents = []\n",
    "vz0_index = []\n",
    "\n",
    "for index in range(-21,16,1):\n",
    "    temp_list = all_features_df[\n",
    "        (index <= all_features_df['vz0']) &\n",
    "        (all_features_df['vz0'] < index+1)\n",
    "        ].correct_call.value_counts(normalize=True).to_list()\n",
    "    if temp_list != []:\n",
    "        vz0_percents.append(temp_list[0])\n",
    "        vz0_index.append(index+0.5)\n",
    "\n",
    "vz0_stats = pd.DataFrame({'vz0':vz0_index, 'correct_call_percent':vz0_percents})\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=vz0_stats, x='vz0', y='correct_call_percent')\n",
    "plt.plot([-6.1, -6.1], [0.78, 1], color='red', linewidth=2)\n",
    "plt.plot([-3.8, -3.8], [0.78, 1], color='black', linewidth=2)\n",
    "plt.plot([-1.5, -1.5], [0.78, 1], color='red', linewidth=2)\n",
    "plt.text(-8.0, 0.985, '25%', color='red', fontsize='x-large')\n",
    "plt.text(-3.55, 0.985, '50%', color='black', fontsize='x-large')\n",
    "plt.text(-1.25, 0.985, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([-20.5, 15.5], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(-19.8, 0.922, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d57b956",
   "metadata": {},
   "source": [
    "Note that 50% of all pitches occur with a vertical velocity between -6.1 and -1.5, so we zoom in on that region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9823ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=vz0_stats[\n",
    "    (-10 < vz0_stats['vz0']) &\n",
    "    (vz0_stats['vz0'] < 3)\n",
    "    ],\n",
    "    x='vz0',\n",
    "    y='correct_call_percent'\n",
    "    )\n",
    "plt.plot([-6.1, -6.1], [0.9075, 0.922], color='red', linewidth=2)\n",
    "plt.plot([-3.8, -3.8], [0.9075, 0.922], color='black', linewidth=2)\n",
    "plt.plot([-1.5, -1.5], [0.9075, 0.922], color='red', linewidth=2)\n",
    "plt.text(-6.75, 0.92125, '25%', color='red', fontsize='x-large')\n",
    "plt.text(-3.75, 0.92125, '50%', color='black', fontsize='x-large')\n",
    "plt.text(-1.35, 0.92125, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([-9.5, 2.5], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(-9.4, 0.9165, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5cf3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For summary statistics, run the following:\n",
    "# all_features_df.vz0.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac7b7d3",
   "metadata": {},
   "source": [
    "<a id='3.1.8'></a>\n",
    "### 3.1.8 - Acceleration\n",
    "\n",
    "<a id='3.1.8.1'></a>\n",
    "#### 3.1.8.1 - `ax`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13689b03",
   "metadata": {},
   "source": [
    "We split our data into buckets with a constant width of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae3b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_percents = []\n",
    "ax_index = []\n",
    "\n",
    "for index in range(-31,32,1):\n",
    "    temp_list = all_features_df[\n",
    "        (index <= all_features_df['ax']) &\n",
    "        (all_features_df['ax'] < index+1)\n",
    "        ].correct_call.value_counts(normalize=True).to_list()\n",
    "    if temp_list != []:\n",
    "        ax_percents.append(temp_list[0])\n",
    "        ax_index.append(index+0.5)\n",
    "\n",
    "ax_stats = pd.DataFrame({'ax':ax_index, 'correct_call_percent':ax_percents})\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=ax_stats, x='ax', y='correct_call_percent')\n",
    "plt.plot([-11.6, -11.6], [0.85, 1], color='red', linewidth=2)\n",
    "plt.plot([-2.1, -2.4], [0.85, 1], color='black', linewidth=2)\n",
    "plt.plot([6.2, 6.1], [0.85, 1], color='red', linewidth=2)\n",
    "plt.text(-14.9, 0.99, '25%', color='red', fontsize='x-large')\n",
    "plt.text(-2.2, 0.99, '50%', color='black', fontsize='x-large')\n",
    "plt.text(6.45, 0.99, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([-30.5, 31.5], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(-28, 0.922, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4488b56",
   "metadata": {},
   "source": [
    "Note that 50% of all pitches occur with a release spin rate between -11.6 and 6.2, so we zoom in on that region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41a78ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=ax_stats[\n",
    "    (-24 < ax_stats['ax']) &\n",
    "    (ax_stats['ax'] < 20)\n",
    "    ],\n",
    "    x='ax',\n",
    "    y='correct_call_percent'\n",
    "    )\n",
    "plt.plot([-11.6, -11.6], [0.887, 0.926], color='red', linewidth=2)\n",
    "plt.plot([-2.1, -2.4], [0.887, 0.926], color='black', linewidth=2)\n",
    "plt.plot([6.2, 6.1], [0.887, 0.926], color='red', linewidth=2)\n",
    "plt.text(-13.9, 0.923, '25%', color='red', fontsize='x-large')\n",
    "plt.text(-4.7, 0.923, '50%', color='black', fontsize='x-large')\n",
    "plt.text(6.45, 0.923, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([-23.5, 19.5], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(-23, 0.922, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6a8dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For summary statistics, run the following:\n",
    "# all_features_df.ax.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecbd254",
   "metadata": {},
   "source": [
    "<a id='3.1.8.2'></a>\n",
    "#### 3.1.8.2 - `ay`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d0ac63",
   "metadata": {},
   "source": [
    "We split our data into buckets with a constant width of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a84db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ay_percents = []\n",
    "ay_index = []\n",
    "\n",
    "for index in range(-17,45,1):\n",
    "    temp_list = all_features_df[\n",
    "        (index <= all_features_df['ay']) &\n",
    "        (all_features_df['ay'] < index+1)\n",
    "        ].correct_call.value_counts(normalize=True).to_list()\n",
    "    if temp_list != []:\n",
    "        ay_percents.append(temp_list[0])\n",
    "        ay_index.append(index+1)\n",
    "\n",
    "ay_stats = pd.DataFrame({'ay':ay_index, 'correct_call_percent':ay_percents})\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=ay_stats, x='ay', y='correct_call_percent')\n",
    "plt.plot([23.9, 23.9], [0.66, 1], color='red', linewidth=2)\n",
    "plt.plot([26.8, 26.8], [0.66, 1], color='black', linewidth=2)\n",
    "plt.plot([29.8, 29.8], [0.66, 1], color='red', linewidth=2)\n",
    "plt.text(20.8, 0.985, '25%', color='red', fontsize='x-large')\n",
    "plt.text(27, 0.985, '50%', color='black', fontsize='x-large')\n",
    "plt.text(30.3, 0.985, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([-16.5, 44.5], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(-15.5, 0.922, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4a5ce5",
   "metadata": {},
   "source": [
    "Note that 50% of all pitches occur depth acceleration between 23.9 and 29.8, so we zoom in on that region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e23c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=ay_stats[\n",
    "    (19 < ay_stats['ay']) &\n",
    "    (ay_stats['ay'] < 35)\n",
    "    ],\n",
    "    x='ay',\n",
    "    y='correct_call_percent'\n",
    "    )\n",
    "plt.plot([23.9, 23.9], [0.912, 0.922], color='red', linewidth=2)\n",
    "plt.plot([26.8, 26.8], [0.912, 0.922], color='black', linewidth=2)\n",
    "plt.plot([29.8, 29.8], [0.912, 0.922], color='red', linewidth=2)\n",
    "plt.text(23.1, 0.9215, '25%', color='red', fontsize='x-large')\n",
    "plt.text(26.89, 0.9215, '50%', color='black', fontsize='x-large')\n",
    "plt.text(29.0, 0.9215, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([19.5, 34.5], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(20.8, 0.9167, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e57d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For summary statistics, run the following:\n",
    "# all_features_df.ay.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce898f79",
   "metadata": {},
   "source": [
    "<a id='3.1.8.3'></a>\n",
    "#### 3.1.8.3 - `az`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5754090",
   "metadata": {},
   "source": [
    "We split our data into buckets with a constant width of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd5c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "az_percents = []\n",
    "az_index = []\n",
    "\n",
    "for index in range(-51,3,2):\n",
    "    temp_list = all_features_df[\n",
    "        (index <= all_features_df['az']) &\n",
    "        (all_features_df['az'] < index+1)\n",
    "        ].correct_call.value_counts(normalize=True).to_list()\n",
    "    if temp_list != []:\n",
    "        az_percents.append(temp_list[0])\n",
    "        az_index.append(index+1)\n",
    "\n",
    "az_stats = pd.DataFrame({'az':az_index, 'correct_call_percent':az_percents})\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=az_stats, x='az', y='correct_call_percent')\n",
    "plt.plot([-30.3, -30.3], [0.87, 1], color='red', linewidth=2)\n",
    "plt.plot([-24, -24], [0.87, 1], color='black', linewidth=2)\n",
    "plt.plot([-16.4, -16.4], [0.87, 1], color='red', linewidth=2)\n",
    "plt.text(-33, 0.993, '25%', color='red', fontsize='x-large')\n",
    "plt.text(-23.5, 0.993, '50%', color='black', fontsize='x-large')\n",
    "plt.text(-16, 0.993, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([-50, 2], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(-43, 0.911, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661e6772",
   "metadata": {},
   "source": [
    "Note that 50% of all pitches occur with a vertical acceleration between -30.3 and -16.4, so we zoom in on that region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01dbbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=az_stats[\n",
    "    (-42 < az_stats['az']) &\n",
    "    (az_stats['az'] < -6)\n",
    "    ],\n",
    "    x='az',\n",
    "    y='correct_call_percent'\n",
    "    )\n",
    "plt.plot([-30.3, -30.3], [0.9075, 0.925], color='red', linewidth=2)\n",
    "plt.plot([-24, -24], [0.9075, 0.925], color='black', linewidth=2)\n",
    "plt.plot([-16.4, -16.4], [0.9075, 0.925], color='red', linewidth=2)\n",
    "plt.text(-32.1, 0.924, '25%', color='red', fontsize='x-large')\n",
    "plt.text(-23.7, 0.924, '50%', color='black', fontsize='x-large')\n",
    "plt.text(-18.1, 0.924, '75%', color='red', fontsize='x-large')\n",
    "plt.plot([-40, -8], [0.9172, 0.9172], color='purple', linewidth=2)\n",
    "plt.text(-39, 0.916, 'mean correct call %', color='purple', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a655c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For summary statistics, run the following:\n",
    "# all_features_df.az.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bd1b70",
   "metadata": {},
   "source": [
    "<a id='3.2'></a>\n",
    "## 3.2 - Feature Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0820bf68",
   "metadata": {},
   "source": [
    "After examining each feature in `Subsection 3.1`, it seems that the most important non-location features for correctly predicting balls and strikes will be a subset of\n",
    "\n",
    "* `sz_top`,\n",
    "* `effective_speed`,\n",
    "* `release_spin_rate`,\n",
    "* `count`,\n",
    "* `pfx_z`,\n",
    "* `vx0`,\n",
    "* `vy0`,\n",
    "* `vz0`, and\n",
    "* `ay`.\n",
    "\n",
    "While it is a location-based feature, we will also include `zone` at some points, for completeness.  \n",
    "  \n",
    "  \n",
    "Next, we will restrict our data frame to the aforementioned features and remove any pitches with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1bf24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_of_all_features_df_for_refined_df = [\n",
    "    'binary_bs',\n",
    "    'correct_call',\n",
    "    'zone',\n",
    "    'sz_top',\n",
    "    'effective_speed',\n",
    "    'release_spin_rate',\n",
    "    'balls',\n",
    "    'strikes',\n",
    "    'pfx_z',\n",
    "    'vx0',\n",
    "    'vy0',\n",
    "    'vz0',\n",
    "    'ay'\n",
    "]\n",
    "\n",
    "refined_df = all_features_df[cols_of_all_features_df_for_refined_df]\n",
    "\n",
    "refined_df = refined_df[\n",
    "    (refined_df['binary_bs'].isna() == False) &\n",
    "    (refined_df['zone'].isna() == False) &\n",
    "    (refined_df['sz_top'].isna() == False) &\n",
    "    (refined_df['effective_speed'].isna() == False) &\n",
    "    (refined_df['release_spin_rate'].isna() == False) &\n",
    "    (refined_df['balls'].isna() == False) &\n",
    "    (refined_df['strikes'].isna() == False) &\n",
    "    (refined_df['pfx_z'].isna() == False) &\n",
    "    (refined_df['vx0'].isna() == False) &\n",
    "    (refined_df['vy0'].isna() == False) &\n",
    "    (refined_df['vz0'].isna() == False) &\n",
    "    (refined_df['ay'].isna() == False)\n",
    "]\n",
    "\n",
    "refined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a816f4",
   "metadata": {},
   "source": [
    "We now create a `pitch_count` feature, instead of using `balls` and `strikes` separately. There are three pitches with a pitch count of either 4-1 or 4-2; we remove those here as well.  \n",
    "  \n",
    "Additionally, we create a binary version of `correct_call`, which we denote by `binary_cc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59738193",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_count_list = []\n",
    "binary_cc_list = []\n",
    "\n",
    "for index in refined_df.index:\n",
    "    balls = refined_df.at[index, 'balls']\n",
    "    strikes = refined_df.at[index, 'strikes']\n",
    "    correct_call = refined_df.at[index, 'correct_call']\n",
    "    pitch_count_list.append(str(balls)+'-'+str(strikes))\n",
    "    if correct_call == 'correct_call':\n",
    "        binary_cc_list.append(0)\n",
    "    else:\n",
    "        binary_cc_list.append(1)\n",
    "\n",
    "refined_df = refined_df.assign(\n",
    "    pitch_count=pitch_count_list,\n",
    "    binary_cc=binary_cc_list\n",
    ")\n",
    "\n",
    "refined_df = refined_df[\n",
    "    (refined_df['pitch_count'] != '4-1') &\n",
    "    (refined_df['pitch_count'] != '4-2')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc76719f",
   "metadata": {},
   "source": [
    "<a id='3.3'></a>\n",
    "## 3.3 - Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb90a2e",
   "metadata": {},
   "source": [
    "For our forward feature selection, we need a baseline model for comparison.  \n",
    "  \n",
    "When predicting ball/strike calls, we will use a baseline model that randomly predicts balls and strikes at a rate corresponding to the number of balls and strikes present in the entire data frame.\n",
    "\n",
    "When predicting correct calls, we will use a baseline model that randomly predicts correct calls at a rate corresponding to the number of correct calls present in the entire data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b41ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_df.binary_bs.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b66f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_bs_baseline_accs = []\n",
    "\n",
    "np.random.seed(129)\n",
    "\n",
    "for obs in range(1000):\n",
    "    rand_draw = np.random.binomial(n=1, p=0.33, size=len(refined_df))\n",
    "    feature_selection_bs_baseline_accs.append( accuracy_score(refined_df.binary_bs.values, rand_draw) )\n",
    "\n",
    "feature_selection_bs_baseline_stats = pd.DataFrame(data={\n",
    "    'feature_selection_bs_baseline_accuracy':feature_selection_bs_baseline_accs\n",
    "})\n",
    "\n",
    "feature_selection_bs_baseline_stats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50a3348",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_df.binary_cc.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f785b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_cc_baseline_accs = []\n",
    "\n",
    "np.random.seed(129)\n",
    "\n",
    "for obs in range(1000):\n",
    "    rand_draw = np.random.binomial(n=1, p=0.08, size=len(refined_df))\n",
    "    feature_selection_cc_baseline_accs.append( accuracy_score(refined_df.binary_bs.values, rand_draw) )\n",
    "\n",
    "feature_selection_cc_baseline_stats = pd.DataFrame(data={\n",
    "    'feature_selection_cc_baseline_accuracy':feature_selection_cc_baseline_accs\n",
    "})\n",
    "\n",
    "feature_selection_cc_baseline_stats.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8d2e84",
   "metadata": {},
   "source": [
    "<a id='3.4'></a>\n",
    "## 3.4 - Feature Selection via Forward Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712ea304",
   "metadata": {},
   "source": [
    "Feature selection by forward selection is a process for determining the most important features in a model, which we summarize below:\n",
    "\n",
    "* Step 0: Create a baseline model for comparison\n",
    "* Step 1: For each available feature, create a new model by adding only that feature to the baseline model and record how that models performs\n",
    "* Step 2: Pick the feature with the model that performs best\n",
    "* Step 3: If the best performing model does not improve on the baseline model, the features of your baseline model are your most important features. If the best performing model does improve on the baseline model, add your best feature to the baseline model and go back to step 1 with this new baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9112660",
   "metadata": {},
   "source": [
    "We now define functions that will which allow us to procede with forward feature selection.\n",
    "\n",
    "* The `create_preprocessor` function takes in a list of model features and creates a preprocessor for a model using those features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876b5066",
   "metadata": {},
   "source": [
    "* The `forward_selection_round` function takes in  \n",
    "    ** a list of features that have already been selected (`current_features`) that will be present in each model,  \n",
    "    ** a list of features that will be tested one at a time (`remaining_features`), and  \n",
    "    ** a random state for repeatability.  \n",
    "  \n",
    "This function iterates through the list of remaining features and returns a dictionary whose keys are entries in `remaining features` and whose values are the mean accuracy of running a 10-fold cross validation on a model with the current features and the new feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4980ba",
   "metadata": {},
   "source": [
    "* The `forward_selection` function takes in  \n",
    "    ** a list of all possible features (`all_features`), and  \n",
    "    ** a baseline accuracy (`baseline_accuracy`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf6b66b",
   "metadata": {},
   "source": [
    "This function begins by running `forward_selection_round` with `current_features=[]`, `remaining_features=all_features`, and `state=101`.  \n",
    "  \n",
    "After the dictionary is returned, it iterates through to find the feature with the highest mean accuracy. If none of the features beat the baseline model, `forward_selection` returns an empty list. Otherwise, it runs `forward_selection_round` with `current_features` updated to include the feature with the highest mean accuracy from the previous run of `forward_selection_round`, `remaining_features` has the feature added to `current_features` removed, `state` is increased by 17, and the accuracy threshold is updated to the highest mean accuracy from the previous run of `forward_selection_round`.  \n",
    "  \n",
    "This process repeats until none of the values in the returned dictionary are higher than the current accuracy threshold. At that point, `forward_selection` returns the list of selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac89f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprocessor(features:list):\n",
    "    cat_feats = []\n",
    "    cont_feats = []\n",
    "    for feat in features:\n",
    "        if feat in ['pitch_count', 'zone']:\n",
    "            cat_feats.append(feat)\n",
    "        else:\n",
    "            cont_feats.append(feat)\n",
    "    if (cont_feats != []) and (cat_feats != []):\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('categorical', OneHotEncoder(handle_unknown='ignore'), cat_feats),\n",
    "                ('continuous', StandardScaler(), cont_feats)\n",
    "            ],\n",
    "            remainder='passthrough'\n",
    "        )\n",
    "    elif (cont_feats != []):\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('continuous', StandardScaler(), cont_feats)\n",
    "            ],\n",
    "            remainder='passthrough'\n",
    "        )\n",
    "    else:\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('categorical', OneHotEncoder(handle_unknown='ignore'), cat_feats),\n",
    "            ],\n",
    "            remainder='passthrough'\n",
    "        )\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "def forward_selection_round(current_features:list, remaining_features:list, state:int):\n",
    "    mean_acc_dict = {}\n",
    "    cur_feats = current_features.copy()\n",
    "    for feat in remaining_features:\n",
    "        test_features = cur_feats.copy()\n",
    "        test_features.append(feat)\n",
    "        accs = []\n",
    "        preprocessor = create_preprocessor(test_features)\n",
    "        kfold = StratifiedKFold(10, shuffle=True, random_state=state)\n",
    "        for train_index, test_index in kfold.split(refined_df, refined_df.binary_bs):\n",
    "            # Splitting data\n",
    "            split_train = refined_df.iloc[train_index]\n",
    "            split_test = refined_df.iloc[test_index]\n",
    "            \n",
    "            # Normalization pipeline\n",
    "            pipeline = Pipeline([\n",
    "                ('log_reg_preprocessor', preprocessor),\n",
    "                ('log_reg', LogisticRegression(penalty=None, max_iter=5000))\n",
    "            ])\n",
    "            \n",
    "            # Fitting\n",
    "            pipeline.fit(split_train[test_features], split_train.binary_bs)\n",
    "            \n",
    "            # Predictions\n",
    "            split_pred = pipeline.predict(split_test[test_features])\n",
    "            \n",
    "            # Evaluation\n",
    "            accs.append( accuracy_score(split_test.binary_bs, split_pred) )\n",
    "        acc_total = 0\n",
    "        for acc in accs:\n",
    "            acc_total += acc\n",
    "        mean_acc = round(acc_total / len(accs), 4)\n",
    "        mean_acc_dict[feat] = mean_acc\n",
    "    return mean_acc_dict\n",
    "        \n",
    "        \n",
    "def forward_selection(all_features:list, baseline_accuracy):\n",
    "    current_features = []\n",
    "    remaining_features = all_features.copy()\n",
    "    current_acc = baseline_accuracy\n",
    "    improving = True\n",
    "    state = 101\n",
    "    selection_round = 1\n",
    "    while improving == True:\n",
    "        print(\"Round \" + str(selection_round) + \" of feature selection is occurring\")\n",
    "        new_accs = forward_selection_round(current_features, remaining_features, state)\n",
    "        new_feat = 'None'\n",
    "        for key in new_accs.keys():\n",
    "            if new_accs[key] > current_acc:\n",
    "                new_feat = key\n",
    "                current_acc = new_accs[key]\n",
    "        if new_feat == 'None':\n",
    "            improving = False\n",
    "        else:\n",
    "            current_features.append(new_feat)\n",
    "            remaining_features.remove(new_feat)\n",
    "            state += 17\n",
    "            selection_round += 1\n",
    "    print(' ')\n",
    "    return current_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db1e85a",
   "metadata": {},
   "source": [
    "<a id='3.4.1'></a>\n",
    "### 3.4.1 - Predicting Ball/Strike Calls, Including `zone` Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f032e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_selection_list = [\n",
    "    'pitch_count',\n",
    "    'zone',\n",
    "    'sz_top',\n",
    "    'effective_speed',\n",
    "    'release_spin_rate',\n",
    "    'pfx_z',\n",
    "    'vx0',\n",
    "    'vy0',\n",
    "    'vz0',\n",
    "    'ay'\n",
    "]\n",
    "\n",
    "print('The possible features which can be picked in this forward selection are')\n",
    "for feat in forward_selection_list:\n",
    "    print('-) ' + feat)\n",
    "\n",
    "print(' ')\n",
    "\n",
    "forward_selected_features = forward_selection(forward_selection_list, 0.5582)\n",
    "\n",
    "print(\"The features selected by forward selection are:\")\n",
    "for index in range(len(forward_selected_features)):\n",
    "    print('#' + str(index+1) + '. ' + forward_selected_features[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3413d80",
   "metadata": {},
   "source": [
    "<a id='3.4.2'></a>\n",
    "### 3.4.2 - Predicting Ball/Strike Calls, Not Including `zone` Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e39d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_selection_list = [\n",
    "    'pitch_count',\n",
    "    'sz_top',\n",
    "    'effective_speed',\n",
    "    'release_spin_rate',\n",
    "    'pfx_z',\n",
    "    'vx0',\n",
    "    'vy0',\n",
    "    'vz0',\n",
    "    'ay'\n",
    "]\n",
    "\n",
    "print('The possible features which can be picked in this forward selection are')\n",
    "for feat in forward_selection_list:\n",
    "    print('-) ' + feat)\n",
    "\n",
    "print(' ')\n",
    "\n",
    "forward_selected_features = forward_selection(forward_selection_list, 0.5582)\n",
    "\n",
    "print(\"The features selected by forward selection are:\")\n",
    "for index in range(len(forward_selected_features)):\n",
    "    print('#' + str(index+1) + '. ' + forward_selected_features[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ed3c6d",
   "metadata": {},
   "source": [
    "<a id='3.4.3'></a>\n",
    "### 3.4.3 - Baseline Model for Predicting Correct Calls  and Updating `forward_selection_round`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baad09e",
   "metadata": {},
   "source": [
    "Our original `forward_selection_round` was defined to predict ball/strike calls. We now update it to predict correct calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b42a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection_round(current_features:list, remaining_features:list, state:int):\n",
    "    mean_acc_dict = {}\n",
    "    cur_feats = current_features.copy()\n",
    "    for feat in remaining_features:\n",
    "        test_features = cur_feats.copy()\n",
    "        test_features.append(feat)\n",
    "        accs = []\n",
    "        preprocessor = create_preprocessor(test_features)\n",
    "        kfold = StratifiedKFold(10, shuffle=True, random_state=state)\n",
    "        for train_index, test_index in kfold.split(refined_df, refined_df.binary_cc):\n",
    "            # Splitting data\n",
    "            split_train = refined_df.iloc[train_index]\n",
    "            split_test = refined_df.iloc[test_index]\n",
    "            \n",
    "            # Normalization pipeline\n",
    "            pipeline = Pipeline([\n",
    "                ('log_reg_preprocessor', preprocessor),\n",
    "                ('log_reg', LogisticRegression(penalty=None, max_iter=5000))\n",
    "            ])\n",
    "            \n",
    "            # Fitting\n",
    "            pipeline.fit(split_train[test_features], split_train.binary_cc)\n",
    "            \n",
    "            # Predictions\n",
    "            split_pred = pipeline.predict(split_test[test_features])\n",
    "            \n",
    "            # Evaluation\n",
    "            accs.append( accuracy_score(split_test.binary_cc, split_pred) )\n",
    "        acc_total = 0\n",
    "        for acc in accs:\n",
    "            acc_total += acc\n",
    "        mean_acc = round(acc_total / len(accs), 4)\n",
    "        mean_acc_dict[feat] = mean_acc\n",
    "    return mean_acc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c824b4",
   "metadata": {},
   "source": [
    "<a id='3.4.4'></a>\n",
    "### 3.4.4 - Predicting Correct Calls, Including `zone` Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e36030",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_selection_list = [\n",
    "    'pitch_count',\n",
    "    'zone',\n",
    "    'sz_top',\n",
    "    'effective_speed',\n",
    "    'release_spin_rate',\n",
    "    'pfx_z',\n",
    "    'vx0',\n",
    "    'vy0',\n",
    "    'vz0',\n",
    "    'ay'\n",
    "]\n",
    "\n",
    "print('The possible features which can be picked in this forward selection are')\n",
    "for feat in forward_selection_list:\n",
    "    print('-) ' + feat)\n",
    "\n",
    "print(' ')\n",
    "\n",
    "forward_selected_features = forward_selection(forward_selection_list, 0.6437)\n",
    "\n",
    "print(\"The features selected by forward selection are:\")\n",
    "for index in range(len(forward_selected_features)):\n",
    "    print('#' + str(index+1) + '. ' + forward_selected_features[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae654c9a",
   "metadata": {},
   "source": [
    "<a id='3.4.5'></a>\n",
    "### 3.4.5 - Predicting Correct Calls, Not Including `zone` Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3780a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_selection_list = [\n",
    "    'pitch_count',\n",
    "    'sz_top',\n",
    "    'effective_speed',\n",
    "    'release_spin_rate',\n",
    "    'pfx_z',\n",
    "    'vx0',\n",
    "    'vy0',\n",
    "    'vz0',\n",
    "    'ay'\n",
    "]\n",
    "\n",
    "print('The possible features which can be picked in this forward selection are')\n",
    "for feat in forward_selection_list:\n",
    "    print('-) ' + feat)\n",
    "\n",
    "print(' ')\n",
    "\n",
    "forward_selected_features = forward_selection(forward_selection_list, 0.6437)\n",
    "\n",
    "print(\"The features selected by forward selection are:\")\n",
    "for index in range(len(forward_selected_features)):\n",
    "    print('#' + str(index+1) + '. ' + forward_selected_features[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c640e532",
   "metadata": {},
   "source": [
    "<a id='3.4.6'></a>\n",
    "### 3.4.6 - Summary\n",
    "\n",
    "According to forward feature selection, we see that `pitch_count` is the most important non-positional feature for predicting both umpire ball/strike calls and for predicting whether an umpire makes a correct call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9821efce",
   "metadata": {},
   "source": [
    "<a id='3.5'></a>\n",
    "## 3.5 - Feature Selection via L^1 Regularization\n",
    "\n",
    "When using logistic regression with an L^1 penalty, we can decrease the hyperparameter `C` to increase the regularization strength. Doing so will force the the coefficients in our model towards 0, with the coefficients on the least important features going towards 0 faster. As such, we can look at how small we must make `C` for each of our coefficients to become 0 as a way of determining which features are most important.\n",
    "\n",
    "We will use this approach both for trying to predict ball/strike calls and for trying to predict correct umpire calls.\n",
    "\n",
    "We do not include the `zone` feature at all in this subsection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a384afc4",
   "metadata": {},
   "source": [
    "<a id='3.5.1'></a>\n",
    "### 3.5.1 - Predicting Ball/Strike Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be26e0ad",
   "metadata": {},
   "source": [
    "We begin my creating models for all of our different `C` values and recording the coefficients for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1170b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_C_values = [\n",
    "    0.00007,\n",
    "    0.00008,\n",
    "    0.00009,\n",
    "    0.0001,\n",
    "    0.0002,\n",
    "    0.0003,\n",
    "    0.0004,\n",
    "    0.0005,\n",
    "    0.0006,\n",
    "    0.0007,\n",
    "    0.0008,\n",
    "    0.0009,\n",
    "    0.001,\n",
    "    0.01,\n",
    "    0.1,\n",
    "    1,\n",
    "    10,\n",
    "    100,\n",
    "    1000\n",
    "]\n",
    "\n",
    "regularization_features = [\n",
    "    'pitch_count',\n",
    "    'sz_top',\n",
    "    'effective_speed',\n",
    "    'release_spin_rate',\n",
    "    'pfx_z',\n",
    "    'vx0',\n",
    "    'vy0',\n",
    "    'vz0',\n",
    "    'ay'\n",
    "]\n",
    "\n",
    "bs_regularization_coefficients = np.zeros((10*len(bs_C_values), 20))\n",
    "bs_regularization_features_from_model = []\n",
    "\n",
    "regularization_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('categorical', OneHotEncoder(handle_unknown='ignore'), ['pitch_count']),\n",
    "        ('continuous', StandardScaler(), [\n",
    "            'sz_top',\n",
    "            'effective_speed',\n",
    "            'release_spin_rate',\n",
    "            'pfx_z',\n",
    "            'vx0',\n",
    "            'vy0',\n",
    "            'vz0',\n",
    "            'ay'\n",
    "        ])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "bs_regularization_kfold = StratifiedKFold(10, shuffle=True, random_state=943)\n",
    "\n",
    "for index in range(len(bs_C_values)):\n",
    "    c_val = bs_C_values[index]\n",
    "    counter = 10*(index)\n",
    "    print('Current C Value: ' + str(bs_C_values[index]))\n",
    "    for train_index, test_index in bs_regularization_kfold.split(refined_df, refined_df.binary_bs):\n",
    "        # Splitting data\n",
    "        split_train = refined_df.iloc[train_index]\n",
    "        split_test = refined_df.iloc[test_index]\n",
    "                \n",
    "        # Normalization pipeline\n",
    "        bs_regularization_pipeline = Pipeline([\n",
    "            ('log_reg_preprocessor', regularization_preprocessor),\n",
    "            ('log_reg', LogisticRegression(C=c_val, penalty=\"l1\", max_iter=5000, solver=\"saga\"))\n",
    "        ])\n",
    "                \n",
    "        # Fitting\n",
    "        bs_regularization_pipeline.fit(split_train[regularization_features], split_train.binary_bs)\n",
    "                \n",
    "        # Coefficients\n",
    "        bs_regularization_coefficients[counter,:] = bs_regularization_pipeline['log_reg'].coef_\n",
    "        counter += 1\n",
    "        bs_regularization_features_from_model.append(bs_regularization_pipeline[:-1].get_feature_names_out())\n",
    "\n",
    "print(' ')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25792a1d",
   "metadata": {},
   "source": [
    "Next, we create a data frame with the coefficients for each model created. Note that we run a 10-fold cross validation for each value of `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d447b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_regularization_df_indices = []\n",
    "\n",
    "for index in range(len(bs_C_values)):\n",
    "    for counter in range(10):\n",
    "        bs_regularization_df_indices.append(bs_C_values[index])\n",
    "\n",
    "bs_regularization_df = pd.DataFrame(\n",
    "    bs_regularization_coefficients,\n",
    "    columns=bs_regularization_features_from_model[0],\n",
    "    index=bs_regularization_df_indices\n",
    ")\n",
    "\n",
    "bs_regularization_df = bs_regularization_df.rename(columns={\n",
    "    'categorical__pitch_count_0-0':'0-0',\n",
    "    'categorical__pitch_count_0-1':'0-1',\n",
    "    'categorical__pitch_count_0-2':'0-2',\n",
    "    'categorical__pitch_count_1-0':'1-0',\n",
    "    'categorical__pitch_count_1-1':'1-1',\n",
    "    'categorical__pitch_count_1-2':'1-2',\n",
    "    'categorical__pitch_count_2-0':'2-0',\n",
    "    'categorical__pitch_count_2-1':'2-1',\n",
    "    'categorical__pitch_count_2-2':'2-2',\n",
    "    'categorical__pitch_count_3-0':'3-0',\n",
    "    'categorical__pitch_count_3-1':'3-1',\n",
    "    'categorical__pitch_count_3-2':'3-2',\n",
    "    'continuous__sz_top':'sz_top',\n",
    "    'continuous__effective_speed':'effective_speed',\n",
    "    'continuous__release_spin_rate':'release_spin_rate',\n",
    "    'continuous__pfx_z':'pfx_z',\n",
    "    'continuous__vx0':'vx0',\n",
    "    'continuous__vy0':'vy0',\n",
    "    'continuous__vz0':'vz0',\n",
    "    'continuous__ay':'ay'\n",
    "    }\n",
    ")\n",
    "\n",
    "bs_regularization_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3bd971",
   "metadata": {},
   "source": [
    "Finally, we create a new data frame where each value of `C` occurs only once; we do this by taking the average of each coefficient over the 10 models coming from cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2683b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_regularization_coefficients_means = bs_regularization_coefficients = np.zeros((len(bs_C_values), 20))\n",
    "\n",
    "for row in range(len(bs_C_values)):\n",
    "    for col in range(len(bs_regularization_df.columns)):\n",
    "        bs_regularization_coefficients_means[row:col] = round(bs_regularization_df.loc[bs_C_values[row]].mean(),4)\n",
    "        \n",
    "bs_regularization_means_df = pd.DataFrame(\n",
    "    bs_regularization_coefficients_means,\n",
    "    columns=bs_regularization_df.columns.to_list(),\n",
    "    index=bs_C_values\n",
    ")\n",
    "\n",
    "bs_regularization_means_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d4db31",
   "metadata": {},
   "source": [
    "Note the smallest value of C where each coefficient is non-zero:\n",
    "\n",
    "0.00008: `0-0`   \n",
    "0.00009:   \n",
    "0.0001:    \n",
    "0.0002: `release_spin_rate`   \n",
    "0.0003: `0-2`, `1-0`, `1-2`, `vy0`   \n",
    "0.0004:   \n",
    "0.0005: `0-1`, `2-0`, `2-2`, `3-0`, `effective_speed`,   \n",
    "0.0006:   \n",
    "0.0007: `vx0`, `vz0`   \n",
    "0.0008:   \n",
    "0.0009:    \n",
    "0.001:    \n",
    "0.01: `1-1`, `2-1`, `3-1`, `3-2`, `sz_top`, `pfx_z`, `ay`   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514f40c5",
   "metadata": {},
   "source": [
    "<a id='3.5.2'></a>\n",
    "### 3.5.2 - Predicting Correct Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1f6541",
   "metadata": {},
   "source": [
    "We begin my creating models for all of our different `C` values and recording the coefficients for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d5acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_C_values = [\n",
    "    0.0001,\n",
    "    0.0002,\n",
    "    0.0003,\n",
    "    0.0004,\n",
    "    0.0005,\n",
    "    0.0006,\n",
    "    0.0007,\n",
    "    0.0008,\n",
    "    0.0009,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.003,\n",
    "    0.004,\n",
    "    0.005,\n",
    "    0.006,\n",
    "    0.007,\n",
    "    0.008,\n",
    "    0.009,\n",
    "    0.01,\n",
    "    0.1,\n",
    "    1,\n",
    "    10,\n",
    "    100,\n",
    "    1000\n",
    "]\n",
    "\n",
    "regularization_features = [\n",
    "    'pitch_count',\n",
    "    'sz_top',\n",
    "    'effective_speed',\n",
    "    'release_spin_rate',\n",
    "    'pfx_z',\n",
    "    'vx0',\n",
    "    'vy0',\n",
    "    'vz0',\n",
    "    'ay'\n",
    "]\n",
    "\n",
    "cc_regularization_coefficients = np.zeros((10*len(cc_C_values), 20))\n",
    "cc_regularization_features_from_model = []\n",
    "\n",
    "regularization_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('categorical', OneHotEncoder(handle_unknown='ignore'), ['pitch_count']),\n",
    "        ('continuous', StandardScaler(), [\n",
    "            'sz_top',\n",
    "            'effective_speed',\n",
    "            'release_spin_rate',\n",
    "            'pfx_z',\n",
    "            'vx0',\n",
    "            'vy0',\n",
    "            'vz0',\n",
    "            'ay'\n",
    "        ])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "cc_regularization_kfold = StratifiedKFold(10, shuffle=True, random_state=943)\n",
    "\n",
    "for index in range(len(cc_C_values)):\n",
    "    c_val = cc_C_values[index]\n",
    "    counter = 10*(index)\n",
    "    print('Current C Value: ' + str(cc_C_values[index]))\n",
    "    for train_index, test_index in cc_regularization_kfold.split(refined_df, refined_df.binary_cc):\n",
    "        # Splitting data\n",
    "        split_train = refined_df.iloc[train_index]\n",
    "        split_test = refined_df.iloc[test_index]\n",
    "                \n",
    "        # Normalization pipeline\n",
    "        cc_regularization_pipeline = Pipeline([\n",
    "            ('log_reg_preprocessor', regularization_preprocessor),\n",
    "            ('log_reg', LogisticRegression(C=c_val, penalty=\"l1\", max_iter=5000, solver=\"saga\"))\n",
    "        ])\n",
    "                \n",
    "        # Fitting\n",
    "        cc_regularization_pipeline.fit(split_train[regularization_features], split_train.binary_cc)\n",
    "                \n",
    "        # Coefficients\n",
    "        cc_regularization_coefficients[counter,:] = cc_regularization_pipeline['log_reg'].coef_\n",
    "        counter += 1\n",
    "        cc_regularization_features_from_model.append(cc_regularization_pipeline[:-1].get_feature_names_out())\n",
    "\n",
    "print(' ')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c05a3c2",
   "metadata": {},
   "source": [
    "Next, we create a data frame with the coefficients for each model created. Note that we run a 10-fold cross validation for each value of `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf769b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_regularization_df_indices = []\n",
    "\n",
    "for index in range(len(cc_C_values)):\n",
    "    for counter in range(10):\n",
    "        cc_regularization_df_indices.append(cc_C_values[index])\n",
    "\n",
    "cc_regularization_df = pd.DataFrame(\n",
    "    cc_regularization_coefficients,\n",
    "    columns=cc_regularization_features_from_model[0],\n",
    "    index=cc_regularization_df_indices\n",
    ")\n",
    "\n",
    "cc_regularization_df = cc_regularization_df.rename(columns={\n",
    "    'categorical__pitch_count_0-0':'0-0',\n",
    "    'categorical__pitch_count_0-1':'0-1',\n",
    "    'categorical__pitch_count_0-2':'0-2',\n",
    "    'categorical__pitch_count_1-0':'1-0',\n",
    "    'categorical__pitch_count_1-1':'1-1',\n",
    "    'categorical__pitch_count_1-2':'1-2',\n",
    "    'categorical__pitch_count_2-0':'2-0',\n",
    "    'categorical__pitch_count_2-1':'2-1',\n",
    "    'categorical__pitch_count_2-2':'2-2',\n",
    "    'categorical__pitch_count_3-0':'3-0',\n",
    "    'categorical__pitch_count_3-1':'3-1',\n",
    "    'categorical__pitch_count_3-2':'3-2',\n",
    "    'continuous__sz_top':'sz_top',\n",
    "    'continuous__effective_speed':'effective_speed',\n",
    "    'continuous__release_spin_rate':'release_spin_rate',\n",
    "    'continuous__pfx_z':'pfx_z',\n",
    "    'continuous__vx0':'vx0',\n",
    "    'continuous__vy0':'vy0',\n",
    "    'continuous__vz0':'vz0',\n",
    "    'continuous__ay':'ay'\n",
    "    }\n",
    ")\n",
    "\n",
    "cc_regularization_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04399463",
   "metadata": {},
   "source": [
    "Finally, we create a new data frame where each value of `C` occurs only once; we do this by taking the average of each coefficient over the 10 models coming from cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dad4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_regularization_coefficients_means = cc_regularization_coefficients = np.zeros((len(cc_C_values), 20))\n",
    "\n",
    "for row in range(len(cc_C_values)):\n",
    "    for col in range(len(cc_regularization_df.columns)):\n",
    "        cc_regularization_coefficients_means[row:col] = round(cc_regularization_df.loc[cc_C_values[row]].mean(),4)\n",
    "        \n",
    "cc_regularization_means_df = pd.DataFrame(\n",
    "    cc_regularization_coefficients_means,\n",
    "    columns=cc_regularization_df.columns.to_list(),\n",
    "    index=cc_C_values\n",
    ")\n",
    "\n",
    "cc_regularization_means_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbb2196",
   "metadata": {},
   "source": [
    "Note the smallest value of C where each coefficient is non-zero:\n",
    "\n",
    "  \n",
    "0.0001:   \n",
    "0.0002:  \n",
    "0.0003:  \n",
    "0.0004:  \n",
    "0.0005: `sz_top`  \n",
    "0.0006: `0-0`  \n",
    "0.0007:  \n",
    "0.0008:  \n",
    "0.0009:  \n",
    "0.001:   \n",
    "0.002: `0-2`, `1-0`, `1-2`, `effective_speed`, `pfx_z`  \n",
    "0.003: `0-1`, `2-2`, `release_spin_rate`  \n",
    "0.004: `2-0`, `ay`  \n",
    "0.005: `vy0`  \n",
    "0.006: `1-1`, `vz0`  \n",
    "0.007:  \n",
    "0.008: `vx0`  \n",
    "0.009: `3-1`  \n",
    "0.01:  \n",
    "0.1:  \n",
    "\n",
    "Always zero `2-1`, `3-0`, `3-2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae5a44d",
   "metadata": {},
   "source": [
    "<a id='3.5.3'></a>\n",
    "### 3.5.3 - Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a397e2b6",
   "metadata": {},
   "source": [
    "We note that `count` was an important feature when using L^1 regularization for both predicting ball/strike calls and for predicting correct umpire calls.  \n",
    "\n",
    "For predicting balls/strikes, `release_spin_rate` and `vy0` were the next most important features according to L^1 regularization.  \n",
    "  \n",
    "For predicting correct umpire calls, `sz_top` was our most important feature according to L^1 regularization. The next set of features worth considering would be `effective_speed` and `pfx_z`.  \n",
    "  \n",
    "It is understandable `sz_top` is very important for predicting correct umpire calls; the top and bottom of the zone change from batter to batter, whereas the left and right sides of the zone do not. Furthermore, there is greater variation in `sz_top` than `sz_bot` (with respective standard deviations of 0.205 and 0.122 in `all_features_df`), despite being correlated.  \n",
    "  \n",
    "Furthermore, `effective_speed` (release speed adjusted by release extension) and `pfx_z` (vertical movement) are conventionally expected predictors of correct calls. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9962c3d8",
   "metadata": {},
   "source": [
    "<a id='A'></a>\n",
    "## Appendix A - Data Collection,  Cleaning, and Processing\n",
    "\n",
    "In this appendix, we describe how the data for this project was obtained, cleaned, and processed across three notebooks.\n",
    "\n",
    "<a id='A.1'></a>\n",
    "### A.1 - Accessing Raw Pitch Data\n",
    "\n",
    "In the notebook `2023 MLB Pitch Data - Month by Month Queries using Pybaseball`, we install the [pybaseball](https://github.com/jldbc/pybaseball) package and use it to download Statcast data from [Baseball Savant](https://baseballsavant.mlb.com/statcast_search). Given the amount of data we requested, we split the request into six queries. More specifically, we request Statcast data from\n",
    "* 20 Mar 2023 through 30 Apr 2023, which we export as `month1.csv`;\n",
    "* 01 May 2023 through 31 May 2023, which we export as `month2.csv`;\n",
    "* 01 Jun 2023 through 30 Jun 2023, which we export as `month3.csv`;\n",
    "* 01 Jul 2023 through 31 Jul 2023, which we export as `month4.csv`;\n",
    "* 01 Aug 2023 through 31 Aug 2023, which we export as `month5.csv`;\n",
    "* 01 Sep 2023 through 01 Oct 2023, which we export as `month6.csv`.\n",
    "\n",
    "<a id='A.2'></a>\n",
    "### A.2 - Merging, Cleaning, and Processing Pitch Data I\n",
    "\n",
    "In the notebook `2023 MLB Pitch Data - Merging, Cleaning, and Processing`, we begin by reading in `month1.csv`, `month2.csv`, `month3.csv`, `month4.csv`, `month5.csv`, and `month6.csv` as data frames, which we then merge together. Next, we restrict to pitches which were either balls or called strikes; pitches where an umpire has to actively make a ball/strike call. We then restrict to Statcast features which will either be considered in our project or remain necessary for further preprocessing.\n",
    "\n",
    "We will soon join this data frame with umpire data, so we now describe obtaining the umpire data.\n",
    "\n",
    "<a id='A.3'></a>\n",
    "### A.3 - Accessing Umpire Data I\n",
    "\n",
    "In the notebook `2023 MLB Umpire Data`, we use `BeautifulSoup` from the `bs4` package to obtain home plate umpire data from [Baseball Reference](https://www.baseball-reference.com). We begin by defining three functions:\n",
    "* `get_umpire_info_from_url()` which takes in the URL of a box score from baseball reference and returns the home plate umpire's name as a string;\n",
    "* `get_umpire_info_from_request()` which takes in a request from a URL of a box score from baseball reference and returns the home plate umpire's name as a string; and\n",
    "* `get_team_info()` which takes in a three letter team abbreviation (e.g. 'BOS'), iterates through possible URLs for box scores with that team as the home team, records the necessary information for each box score, and exports the umpire information as a CSV (e.g. `BOS_umpire.csv`).\n",
    "\n",
    "After defining these functions, there is code in place to scrape the information for each team (although this code is currently commented out, as the data has already been scraped).  \n",
    "\n",
    "Next, we read in the umpire information for each team as a separate data frame, merge these data frames together, and export this single data frame as `umpires.csv`. \n",
    "\n",
    "<a id='A.4'></a>\n",
    "### A.4 - Merging, Cleaning, and Processing Pitch Data II\n",
    "\n",
    "Switching back to `2023 MLB Pitch Data - Merging, Cleaning, and Processing`, we read in `umpires.csv` left join it with our pitch data. However, there are still pitches with missing umpire information, as games which are part of a doubleheader (when two teams play two games on the same day) are given a different URL formatting on Baseball Reference.  \n",
    "\n",
    "As such, we create a data frame of pitches with missing umpire information and export the necessary information as `missing_umpires.csv`.\n",
    "\n",
    "<a id='A.5'></a>\n",
    "### A.5 - Accessing Umpire Data II\n",
    "\n",
    "Going back to `2023 MLB Umpire Data`, we read in the `missing_umpires.csv` and see that all but one game with missing umpire is a doubleheader. Now that we have the date and home team for each doubleheader, we scrape the home plate umpire for each of these games (as well as the one exception), create a data frame with the umpire data, and export the data frame as `missing_umpires_return.csv`.\n",
    "\n",
    "<a id='A.6'></a>\n",
    "### A.6 - Merging, Cleaning, and Processing Pitch Data III\n",
    "\n",
    "We again go back to `2023 MLB Pitch Data - Merging, Cleaning, and Processing`, where we read in `missing_umpires_return.csv` and join it to our data frame, which completes the joining of umpire information.  \n",
    "\n",
    "Next, we proceed to feature engineering, where we create\n",
    "* `binary_bs`, a binary version of ball/strike calls;\n",
    "* `hscw`, which determines if the pitch was in the heart, shadow, chase, or waste portion of the zone;\n",
    "* `true_ball/strike`, which determines if the pitch was actually a ball or strike;\n",
    "* `correct_call`, which determines if the umpire's call (`ball/strike`) matches with `true_ball/strike`;\n",
    "* `plate_x_mag` and `plate_x_dir`, which respectively record the magnitude and sign of `plate_x`.  \n",
    "\n",
    "We then create a data frame with all the features outlined in `Sections 2,3`, which we then export as `large_model_data.csv`.  \n",
    "\n",
    "Finally, we create a data frame with only the features outlined in `Section 2`, which we then export as `small_model_data.csv`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
